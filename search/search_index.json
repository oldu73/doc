{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to doc Hello, doc ;)","title":"Home"},{"location":"#welcome-to-doc","text":"Hello, doc ;)","title":"Welcome to doc"},{"location":"agilemethodology/1-agilemethodology-misc/","text":"Agile Methodology - 01 - Misc Agile Guide M\u00e9thode agile scrum, exemple Definitions A Complete Guide to Agile Epics User story A single request Epic A group of user stories Initiative A group of epics Theme A label for organizational goals Story How to Create User Stories \u201cwho,\u201d \u201cwhat,\u201d and \u201cwhy\u201d of a particular requirement. Who wants something? What do they want? Why do they want it? Common template: \u201cAs [persona], I want to [action], so that I can [benefit].\u201d Cut a Story (US = User Story) D\u00e9couper une user Story ECRIRE ET D\u00c9COUPER SES USERS STORIES COMME UN NINJA Appendix Product Do Product as Unicorns do IoT Explorez le panorama des objets connect\u00e9s Swisscom et Feldschl\u00f6sschen mettent la bi\u00e8re en r\u00e9seau","title":"Agile Methodology - 01 - Misc"},{"location":"agilemethodology/1-agilemethodology-misc/#agile-methodology-01-misc","text":"Agile Guide M\u00e9thode agile scrum, exemple","title":"Agile Methodology - 01 - Misc"},{"location":"agilemethodology/1-agilemethodology-misc/#definitions","text":"A Complete Guide to Agile Epics User story A single request Epic A group of user stories Initiative A group of epics Theme A label for organizational goals","title":"Definitions"},{"location":"agilemethodology/1-agilemethodology-misc/#story","text":"How to Create User Stories \u201cwho,\u201d \u201cwhat,\u201d and \u201cwhy\u201d of a particular requirement. Who wants something? What do they want? Why do they want it? Common template: \u201cAs [persona], I want to [action], so that I can [benefit].\u201d","title":"Story"},{"location":"agilemethodology/1-agilemethodology-misc/#cut-a-story-us-user-story","text":"D\u00e9couper une user Story ECRIRE ET D\u00c9COUPER SES USERS STORIES COMME UN NINJA","title":"Cut a Story (US = User Story)"},{"location":"agilemethodology/1-agilemethodology-misc/#appendix","text":"","title":"Appendix"},{"location":"agilemethodology/1-agilemethodology-misc/#product","text":"Do Product as Unicorns do","title":"Product"},{"location":"agilemethodology/1-agilemethodology-misc/#iot","text":"Explorez le panorama des objets connect\u00e9s Swisscom et Feldschl\u00f6sschen mettent la bi\u00e8re en r\u00e9seau","title":"IoT"},{"location":"docker/1-docker-misc/","text":"Docker - 01 - Misc Maven, Java Mainly for Maven projects but maybe easily adapted for standard Java project. Project From IntelliJ Java (Maven) project to a container hosted on a Raspberry. Deployment process: (IntelliJ) maven <project> package Dockerfile-arm64v8 build image (terminal) docker login docker push oldu73/msc:<project>_arm64v8_latest (raspberry) maybe stop/remove previous existing <project> container instance docker login sudo docker pull oldu73/msc:<project>_arm64v8_latest sudo docker run -d -p <port>:<port> --name <container_name> oldu73/msc:<project>_arm64v8_latest sudo docker container ps -a sudo docker exec -it <container_name> sh (container) tail -1000f /var/log/<file>.log Dockerfile-arm64v8: FROM arm64v8/openjdk:8-oraclelinux7 COPY ./target/project.jar /tmp WORKDIR /tmp EXPOSE <port> ENTRYPOINT [\"java\", \"-jar\", \"project.jar\"] Debug, HotSwap (IntelliJ) maven <project> package Dockerfile run image // bind port 8080 Dockerfile: FROM openjdk:8 COPY ./target/<project>.jar /tmp WORKDIR /tmp EXPOSE 8080 ENTRYPOINT [\"java\", \"-jar\", \"-agentlib:jdwp=transport=dt_socket,address=8080,server=y,suspend=n\", \"<project>.jar\"] IntelliJ, Remote JVM Debug, configuration: Debugger mode: Attach to remote JVM Transport: Socket Host: localhost Port: 8080 Command line arguments for remote JVM: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8080 Run IntelliJ remote debug configuration. Modify code, set breakpoint and then reload changed class. By adding some system out you may observe live changes in container log console. Disk usage docker system df Docker reclaim unused image space: docker image prune -a Docker container size: docker ps --size","title":"Docker - 01 - Misc"},{"location":"docker/1-docker-misc/#docker-01-misc","text":"","title":"Docker - 01 - Misc"},{"location":"docker/1-docker-misc/#maven-java","text":"Mainly for Maven projects but maybe easily adapted for standard Java project.","title":"Maven, Java"},{"location":"docker/1-docker-misc/#project","text":"From IntelliJ Java (Maven) project to a container hosted on a Raspberry. Deployment process: (IntelliJ) maven <project> package Dockerfile-arm64v8 build image (terminal) docker login docker push oldu73/msc:<project>_arm64v8_latest (raspberry) maybe stop/remove previous existing <project> container instance docker login sudo docker pull oldu73/msc:<project>_arm64v8_latest sudo docker run -d -p <port>:<port> --name <container_name> oldu73/msc:<project>_arm64v8_latest sudo docker container ps -a sudo docker exec -it <container_name> sh (container) tail -1000f /var/log/<file>.log Dockerfile-arm64v8: FROM arm64v8/openjdk:8-oraclelinux7 COPY ./target/project.jar /tmp WORKDIR /tmp EXPOSE <port> ENTRYPOINT [\"java\", \"-jar\", \"project.jar\"]","title":"Project"},{"location":"docker/1-docker-misc/#debug-hotswap","text":"(IntelliJ) maven <project> package Dockerfile run image // bind port 8080 Dockerfile: FROM openjdk:8 COPY ./target/<project>.jar /tmp WORKDIR /tmp EXPOSE 8080 ENTRYPOINT [\"java\", \"-jar\", \"-agentlib:jdwp=transport=dt_socket,address=8080,server=y,suspend=n\", \"<project>.jar\"] IntelliJ, Remote JVM Debug, configuration: Debugger mode: Attach to remote JVM Transport: Socket Host: localhost Port: 8080 Command line arguments for remote JVM: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8080 Run IntelliJ remote debug configuration. Modify code, set breakpoint and then reload changed class. By adding some system out you may observe live changes in container log console.","title":"Debug, HotSwap"},{"location":"docker/1-docker-misc/#disk-usage","text":"docker system df Docker reclaim unused image space: docker image prune -a Docker container size: docker ps --size","title":"Disk usage"},{"location":"docker/10-compose-services/","text":"Compose - 10 - Services Docker Compose - Services Use of Docker Compose with many services. In this chapter we setup a complete development/production environnement close to what we may found in real life projects, scalable and so on. Project architecture Introduction to project architecture: React (Application), could be Vue.js or Angular, would be the same. NGINX (Http request). Node.js (API). MongoDB (database). Development NGINX as reverse proxy follow requests: != /api + == /sockjs-node (websocket for live reload feature) -> React. == /api -> Node.js -> MongoDB. Production NGINX as reverse proxy (on big application may also be used as a load balancer) follow requests: != /api -> another NGINX that handle React production build output ('build' folder). == /api -> Node.js -> MongoDB. Setup mkdir fullstack cd fullstack React application: mkdir client Node.js application: mkdir api MongoDB database: mkdir db NGINX as a reverse proxy, in charge of dispatching http requests: mkdir reverse-proxy Docker Compose: touch docker-compose.dev.yml touch docker-compose.prod.yml Client configuration Setting up the client configuration cd client npx create-react-app client mv client/* . rm -rf client rm -rf node_modules touch Dockerfile.dev /fullstack/client/Dockerfile.dev: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] /fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 From 'fullstack' folder, we'll let '--build' option to ensure building images before starting containers: code . docker-compose -f docker-compose.dev.yml up --build Test by browsing at localhost:3000 We add a function to '/fullstack/client/src/App.js' file in order to get a counter from api (not ready yet but we prepare here the application in advance). /fullstack/client/src/App.js: import logo from './logo.svg'; import './App.css'; import { useState, useEffect } from 'react'; function App() { const [count, setCount] = useState(); useEffect(() => { async function fetchCount() { try { const response = await fetch('/api/count') if (response.ok) { setCount(await response.json()); } } catch (e) { console.log(e); } } fetchCount(); }, []); return ( <div className=\"App\"> <header className=\"App-header\"> <img src={logo} className=\"App-logo\" alt=\"logo\" /> <p> Edit <code>src/App.js</code> and save to reload. </p> <p> Count : { count } </p> <a className=\"App-link\" href=\"https://reactjs.org\" target=\"_blank\" rel=\"noopener noreferrer\" > Learn React </a> </header> </div> ); } export default App; In Docker Compose logs we may observe successful compilation: . . client_1 | webpack 5.65.0 compiled successfully in 191 ms Test again by browsing at localhost:3000 Stop/remove stack: docker-compose -f docker-compose.dev.yml down Note: - webpack is exclusively devoted for development. Set up Node.js API From project root folder: - .../fullstack cd api npm init -y npm i express nodemon mongodb mkdir src cd src touch index.js index.js (from previous node server project) const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); .../fullstack/docker-compose.dev.yml version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 ../fullstack/api touch Dockerfile .../fullstack/api/Dockerfile FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [\"npm\", \"start\"] .../fullstack/api/package.json { \"name\": \"api\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"start\": \"nodemon ./src/index.js\", \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.2\", \"mongodb\": \"^4.3.0\", \"nodemon\": \"^2.0.15\" } } Test API in a terminal from .../fullstack/ folder code . docker-compose -f docker-compose.dev.yml run api Set up database service Add db service to Docker Compose configuration file. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db volumes: dbtest: Initialize database container. From '.../fullstack' folder: docker-compose -f docker-compose.dev.yml run db Now it should be launch and we connect on it in a second terminal: docker container exec -it fullstack_db_run_c97d6cfbd602 sh mongo use test db.count.insertOne({ count: 0 }) exit exit Now it's OK, we may close second terminal and 'Ctrl+c' database container. We may test application with (from '.../fullstack' folder): (code . // it's always better to have VS Code started from application root folder) docker-compose -f docker-compose.dev.yml up Test application by browsing to http://localhost:3001/api/count We may also observe that React is running by browsing to http://localhost:3000/ Then 'Ctrl-c' to stop stack. Set up the NGINX reverse proxy From '.../fullstack/reverse-proxy' folder: mkdir conf touch conf/dev.conf touch Dockerfile.dev .../fullstack/reverse-proxy/Dockerfile.dev: FROM nginx:latest COPY ./conf/dev.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/dev.conf: server { listen 80; location / { proxy_pass http://client:3000; } location /api { proxy_pass http://api; } location /sockjs-node { proxy_pass http://client:3000; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } } No need to specify port for api because inside stack (network), not from a host point of view, it's listening on default http port ('80'). Among HTTP standards, by default some 'headers' called 'hop-by-hop' aren't passed by proxy to server and then avoid live reload to work. To fix this, the 'sockjs-node' is a needed technical part to make live reload works. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.dev ports: - 80:80 depends_on: - api - db volumes: dbtest: Test, everything is supposed to work: docker-compose -f docker-compose.dev.yml up --build In a second terminal: docker-compose -f docker-compose.dev.yml ps NAME COMMAND SERVICE STATUS PORTS fullstack_api_1 \"docker-entrypoint.s\u2026\" api running 0.0.0.0:3001->80/tcp fullstack_client_1 \"docker-entrypoint.s\u2026\" client running 0.0.0.0:3000->3000/tcp fullstack_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp fullstack_reverse-proxy_1 \"/docker-entrypoint.\u2026\" reverse-proxy running 0.0.0.0:80->80/tcp We may observe then the 4 components composing our application are running. And test by browsing to http://localhost/ , note that there's not need to specify port this time thanks to NGINX that do his job as a reverse proxy by distributing requests through our application by listening on default http port ('80'). By refreshing the page, you also may observe counter increasing. To test live reload edit file '.../fullstack/client/src/App.js' and observe live changes in browser window (even without refreshing the page). We now have a full functional development stack that maybe up with only one command: docker-compose -f docker-compose.dev.yml up Set up production configuration Reset Docker environnement (if needed): docker system prune -a docker volume prune Client From folder '.../fullstack/client': touch Dockerfile.prod .../fullstack/client/Dockerfile.prod FROM node:alpine as build WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . RUN npm run build FROM nginx:latest COPY --from=build /app/build /usr/share/nginx/html EXPOSE 80 ! Be aware of RUN npm run build, NOT CMD! .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped Start VS Code in '.../fullstack' folder with 'code .' command and then: docker-compose -f docker-compose.prod.yml run -p 80:80 client Browse to http://localhost/ to validate React application is running. API In '.../fullstack/api/src/index.js' notice mongodb connection URL with MONGO_USERNAME and MONGO_PWD credentials that comes from process (production) environnement: const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); In '.../fullstack/api' folder: touch .env .../fullstack/api/.env: MONGO_USERNAME=paul MONGO_PWD=123 We don't want that secret information to be copied in container: touch .dockerignore .../fullstack/api/.dockerignore: .env .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped Test API with (tanks to \"console.log(process.env)\" in \".../fullstack/api/src/index.js\" we may observe environment variables): docker-compose -f docker-compose.prod.yml run api { . . . MONGO_USERNAME: 'paul', . . MONGO_PWD: '123', . NODE_ENV: 'production', . . } Hit 'Ctrl+c' to stop. DB Secure the database by providing root username and password through an environment file. From folder '.../fullstack/db': touch .env Get credential syntax from 'Environment Variables' section in Mongo image on Docker Hub . In file '.../fullstack/db/.env' add credentials: MONGO_INITDB_ROOT_USERNAME=admin MONGO_INITDB_ROOT_PASSWORD=password Provide environment file (for root user credentials) and external volume for db service in docker compose configuration file. Set up db service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Create volume 'dbprod': docker volume create dbprod Run 'db' container in detached mode from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml run -d db Initialize database by connecting to it with root user credentials. docker container exec -it fullstack_db_run_e9fa9328e2b8 sh mongo use admin db.auth({ user: 'admin', pwd: 'password' }) Create the needed user for API access, the one described in '.env' environnement file that reside in '.../fullstack/api' folder. db.createUser({ user: 'paul', pwd: '123', roles: [{ role: 'readWrite', db: 'test' }] }) Setup collection for 'count'. use test db.count.insertOne({ count: 0 }) exit exit docker stop fullstack_db_run_e9fa9328e2b8 Now db is ready and API may communicate with it. To test, launch complete stack with port 80 open for 'api' service (only for testing, because after, in this production context, this is the reverse proxy role to communicate on port 80). .../fullstack/docker-compose.prod.yml: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped ports: - 80:80 db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Launch full stack: docker-compose -f docker-compose.prod.yml up (--build) Browse to localhost/api/count and refresh page to observe counter incrementing. Hit 'Ctrl+c' to stop. Remove port 80 for 'api' service in 'docker-compose.prod.yml' file. Reverse proxy Production configuration file in '.../fullstack/reverse-proxy/conf' folder: touch prod.conf Production Docker file in '.../fullstack/reverse-proxy' folder: touch Dockerfile.prod .../fullstack/reverse-proxy/Dockerfile.prod: FROM nginx:latest COPY ./conf/prod.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/prod.conf: server { listen 80; location / { proxy_pass http://client; } location /api { proxy_pass http://api; } } Add 'reverse-proxy' service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Test, from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml down -v docker-compose -f docker-compose.prod.yml up --build Browse to localhost and refresh page to observe counter incrementing.","title":"Compose - 10 - Services"},{"location":"docker/10-compose-services/#compose-10-services","text":"Docker Compose - Services Use of Docker Compose with many services. In this chapter we setup a complete development/production environnement close to what we may found in real life projects, scalable and so on.","title":"Compose - 10 - Services"},{"location":"docker/10-compose-services/#project-architecture","text":"Introduction to project architecture: React (Application), could be Vue.js or Angular, would be the same. NGINX (Http request). Node.js (API). MongoDB (database).","title":"Project architecture"},{"location":"docker/10-compose-services/#development","text":"NGINX as reverse proxy follow requests: != /api + == /sockjs-node (websocket for live reload feature) -> React. == /api -> Node.js -> MongoDB.","title":"Development"},{"location":"docker/10-compose-services/#production","text":"NGINX as reverse proxy (on big application may also be used as a load balancer) follow requests: != /api -> another NGINX that handle React production build output ('build' folder). == /api -> Node.js -> MongoDB.","title":"Production"},{"location":"docker/10-compose-services/#setup","text":"mkdir fullstack cd fullstack React application: mkdir client Node.js application: mkdir api MongoDB database: mkdir db NGINX as a reverse proxy, in charge of dispatching http requests: mkdir reverse-proxy Docker Compose: touch docker-compose.dev.yml touch docker-compose.prod.yml","title":"Setup"},{"location":"docker/10-compose-services/#client-configuration","text":"Setting up the client configuration cd client npx create-react-app client mv client/* . rm -rf client rm -rf node_modules touch Dockerfile.dev /fullstack/client/Dockerfile.dev: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] /fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 From 'fullstack' folder, we'll let '--build' option to ensure building images before starting containers: code . docker-compose -f docker-compose.dev.yml up --build Test by browsing at localhost:3000 We add a function to '/fullstack/client/src/App.js' file in order to get a counter from api (not ready yet but we prepare here the application in advance). /fullstack/client/src/App.js: import logo from './logo.svg'; import './App.css'; import { useState, useEffect } from 'react'; function App() { const [count, setCount] = useState(); useEffect(() => { async function fetchCount() { try { const response = await fetch('/api/count') if (response.ok) { setCount(await response.json()); } } catch (e) { console.log(e); } } fetchCount(); }, []); return ( <div className=\"App\"> <header className=\"App-header\"> <img src={logo} className=\"App-logo\" alt=\"logo\" /> <p> Edit <code>src/App.js</code> and save to reload. </p> <p> Count : { count } </p> <a className=\"App-link\" href=\"https://reactjs.org\" target=\"_blank\" rel=\"noopener noreferrer\" > Learn React </a> </header> </div> ); } export default App; In Docker Compose logs we may observe successful compilation: . . client_1 | webpack 5.65.0 compiled successfully in 191 ms Test again by browsing at localhost:3000 Stop/remove stack: docker-compose -f docker-compose.dev.yml down Note: - webpack is exclusively devoted for development.","title":"Client configuration"},{"location":"docker/10-compose-services/#set-up-nodejs-api","text":"From project root folder: - .../fullstack cd api npm init -y npm i express nodemon mongodb mkdir src cd src touch index.js index.js (from previous node server project) const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); .../fullstack/docker-compose.dev.yml version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 ../fullstack/api touch Dockerfile .../fullstack/api/Dockerfile FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [\"npm\", \"start\"] .../fullstack/api/package.json { \"name\": \"api\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"start\": \"nodemon ./src/index.js\", \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.2\", \"mongodb\": \"^4.3.0\", \"nodemon\": \"^2.0.15\" } } Test API in a terminal from .../fullstack/ folder code . docker-compose -f docker-compose.dev.yml run api","title":"Set up Node.js API"},{"location":"docker/10-compose-services/#set-up-database-service","text":"Add db service to Docker Compose configuration file. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db volumes: dbtest: Initialize database container. From '.../fullstack' folder: docker-compose -f docker-compose.dev.yml run db Now it should be launch and we connect on it in a second terminal: docker container exec -it fullstack_db_run_c97d6cfbd602 sh mongo use test db.count.insertOne({ count: 0 }) exit exit Now it's OK, we may close second terminal and 'Ctrl+c' database container. We may test application with (from '.../fullstack' folder): (code . // it's always better to have VS Code started from application root folder) docker-compose -f docker-compose.dev.yml up Test application by browsing to http://localhost:3001/api/count We may also observe that React is running by browsing to http://localhost:3000/ Then 'Ctrl-c' to stop stack.","title":"Set up database service"},{"location":"docker/10-compose-services/#set-up-the-nginx-reverse-proxy","text":"From '.../fullstack/reverse-proxy' folder: mkdir conf touch conf/dev.conf touch Dockerfile.dev .../fullstack/reverse-proxy/Dockerfile.dev: FROM nginx:latest COPY ./conf/dev.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/dev.conf: server { listen 80; location / { proxy_pass http://client:3000; } location /api { proxy_pass http://api; } location /sockjs-node { proxy_pass http://client:3000; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } } No need to specify port for api because inside stack (network), not from a host point of view, it's listening on default http port ('80'). Among HTTP standards, by default some 'headers' called 'hop-by-hop' aren't passed by proxy to server and then avoid live reload to work. To fix this, the 'sockjs-node' is a needed technical part to make live reload works. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.dev ports: - 80:80 depends_on: - api - db volumes: dbtest: Test, everything is supposed to work: docker-compose -f docker-compose.dev.yml up --build In a second terminal: docker-compose -f docker-compose.dev.yml ps NAME COMMAND SERVICE STATUS PORTS fullstack_api_1 \"docker-entrypoint.s\u2026\" api running 0.0.0.0:3001->80/tcp fullstack_client_1 \"docker-entrypoint.s\u2026\" client running 0.0.0.0:3000->3000/tcp fullstack_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp fullstack_reverse-proxy_1 \"/docker-entrypoint.\u2026\" reverse-proxy running 0.0.0.0:80->80/tcp We may observe then the 4 components composing our application are running. And test by browsing to http://localhost/ , note that there's not need to specify port this time thanks to NGINX that do his job as a reverse proxy by distributing requests through our application by listening on default http port ('80'). By refreshing the page, you also may observe counter increasing. To test live reload edit file '.../fullstack/client/src/App.js' and observe live changes in browser window (even without refreshing the page). We now have a full functional development stack that maybe up with only one command: docker-compose -f docker-compose.dev.yml up","title":"Set up the NGINX reverse proxy"},{"location":"docker/10-compose-services/#set-up-production-configuration","text":"Reset Docker environnement (if needed): docker system prune -a docker volume prune","title":"Set up production configuration"},{"location":"docker/10-compose-services/#client","text":"From folder '.../fullstack/client': touch Dockerfile.prod .../fullstack/client/Dockerfile.prod FROM node:alpine as build WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . RUN npm run build FROM nginx:latest COPY --from=build /app/build /usr/share/nginx/html EXPOSE 80 ! Be aware of RUN npm run build, NOT CMD! .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped Start VS Code in '.../fullstack' folder with 'code .' command and then: docker-compose -f docker-compose.prod.yml run -p 80:80 client Browse to http://localhost/ to validate React application is running.","title":"Client"},{"location":"docker/10-compose-services/#api","text":"In '.../fullstack/api/src/index.js' notice mongodb connection URL with MONGO_USERNAME and MONGO_PWD credentials that comes from process (production) environnement: const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); In '.../fullstack/api' folder: touch .env .../fullstack/api/.env: MONGO_USERNAME=paul MONGO_PWD=123 We don't want that secret information to be copied in container: touch .dockerignore .../fullstack/api/.dockerignore: .env .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped Test API with (tanks to \"console.log(process.env)\" in \".../fullstack/api/src/index.js\" we may observe environment variables): docker-compose -f docker-compose.prod.yml run api { . . . MONGO_USERNAME: 'paul', . . MONGO_PWD: '123', . NODE_ENV: 'production', . . } Hit 'Ctrl+c' to stop.","title":"API"},{"location":"docker/10-compose-services/#db","text":"Secure the database by providing root username and password through an environment file. From folder '.../fullstack/db': touch .env Get credential syntax from 'Environment Variables' section in Mongo image on Docker Hub . In file '.../fullstack/db/.env' add credentials: MONGO_INITDB_ROOT_USERNAME=admin MONGO_INITDB_ROOT_PASSWORD=password Provide environment file (for root user credentials) and external volume for db service in docker compose configuration file. Set up db service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Create volume 'dbprod': docker volume create dbprod Run 'db' container in detached mode from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml run -d db Initialize database by connecting to it with root user credentials. docker container exec -it fullstack_db_run_e9fa9328e2b8 sh mongo use admin db.auth({ user: 'admin', pwd: 'password' }) Create the needed user for API access, the one described in '.env' environnement file that reside in '.../fullstack/api' folder. db.createUser({ user: 'paul', pwd: '123', roles: [{ role: 'readWrite', db: 'test' }] }) Setup collection for 'count'. use test db.count.insertOne({ count: 0 }) exit exit docker stop fullstack_db_run_e9fa9328e2b8 Now db is ready and API may communicate with it. To test, launch complete stack with port 80 open for 'api' service (only for testing, because after, in this production context, this is the reverse proxy role to communicate on port 80). .../fullstack/docker-compose.prod.yml: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped ports: - 80:80 db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Launch full stack: docker-compose -f docker-compose.prod.yml up (--build) Browse to localhost/api/count and refresh page to observe counter incrementing. Hit 'Ctrl+c' to stop. Remove port 80 for 'api' service in 'docker-compose.prod.yml' file.","title":"DB"},{"location":"docker/10-compose-services/#reverse-proxy","text":"Production configuration file in '.../fullstack/reverse-proxy/conf' folder: touch prod.conf Production Docker file in '.../fullstack/reverse-proxy' folder: touch Dockerfile.prod .../fullstack/reverse-proxy/Dockerfile.prod: FROM nginx:latest COPY ./conf/prod.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/prod.conf: server { listen 80; location / { proxy_pass http://client; } location /api { proxy_pass http://api; } } Add 'reverse-proxy' service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Test, from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml down -v docker-compose -f docker-compose.prod.yml up --build Browse to localhost and refresh page to observe counter incrementing.","title":"Reverse proxy"},{"location":"docker/11-compose-production/","text":"Compose - 11 - Production Docker Compose - Production Introduction Almost same components as the ones presented/used in preceding chapter Docker Compose - Services . For this note (Compose - 11 - Production), we refer to folder architecture and contained files from chapter Docker Compose - Services . This time all those component are going to be set to work in production, on a real server. Project components Introduction to project components: Certbot , to get your site on https:// (encrypted communications) with TLS certificate (little lock before address in Internet browser). NGINX (Http request and reverse proxy). React (Application), could be Vue.js or Angular, would be the same. PM2 , process manager (load balancer) for Node.js. Node.js (API), to get better performance it's advised to get one running instance of Node.js by CPU core (on host server). MongoDB (database), only one instance here (scale is out of scope here). OVHcloud (VPS, virtual private server and DNS). GitLab , code hosting. Project architecture Below is a detailed schema of proposed architecture, obviously, everything in dedicated Docker containers: React (build) / / NGINX / / !=/api / --Certbot--NGINX--/ \\ ==/api \\ \\ PM2 \\ --------------- | --------------------- | | | Node.js Node.js Node.js \u2191 \u2191 \u2191 \u2193 \u2193 \u2193 --------------------- | MongoDB | --------------------- Real scalable and performing architecture for single physical server. For huge application running on multiple physical server, see Docker Swarm . SIGINT SIGINT: - A signal sent to a process in order to cause it to be interrupted properly (graceful shutdown). This is a bit off topic, but here we will properly handle the Node.js application (API) interrupt signal. In file '.../fullstack/api/src/index.js': const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); process.addListener('SIGINT', () => { console.log('Received interruption signal!'); }) In a terminal: docker-compose -f docker-compose.dev.yml build api docker-compose -f docker-compose.dev.yml run api CTRL + C ^CReceived interruption signal! npm ERR! path /app npm ERR! command failed npm ERR! signal SIGINT npm ERR! command sh -c nodemon ./src/index.js It was just to observe in logs that process correctly receive interruption signal and then there are some red error messages. Below is correct management of process interruption by closing database connection and server that return 1 on exit error. In file '.../fullstack/api/src/index.js': const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let clientDb; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); clientDb = client; count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); const server = app.listen(80); process.addListener('SIGINT', () => { console.log('Received interruption signal!'); server.close((err) => { if (err) { process.exit(1); } else { if (clientDb) { clientDb.close((err) => process.exit(err ? 1 : 0)); } else { process.exit(0); } } }) }) In production we also use LTS (Long-term support) version of alpine node image. In '.../fullstack/api/Dockerfile' file: FROM node:lts-alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [\"npm\", \"start\"] In a terminal (from '.../fullstack' folder), to tests if it's running well. docker-compose -f docker-compose.dev.yml build api docker-compose -f docker-compose.dev.yml run api CTRL + C Still experiment some red error messages in logs after SIGINT received by the process, maybe due to no database connection for now (let's see further on this chapter notes). PM2 One Node.js instance by CPU available threads. Cluster module. In fullstack/api folder, rename Dockerfile as Dockerfile.dev and create new Dockerfile.prod for production: mv Dockerfile Dockerfile.dev touch Dockerfile.prod Edit docker-compose.dev.yml accordingly to use Dockerfile.dev for api service: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile.dev volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.dev ports: - 80:80 depends_on: - api - db volumes: dbtest: Dockerfile.prod: FROM node:lts-alpine WORKDIR /app COPY package.json . RUN npm install RUN npm i pm2 -g # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [ \"npm\", \"run\", \"prod\" ] package.json: { \"name\": \"api\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"start\": \"nodemon ./src/index.js\", \"prod\": \"pm2-runtime ecosystem.config.js\", \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.2\", \"mongodb\": \"^4.3.0\", \"nodemon\": \"^2.0.15\" } } Still in fullstack/api folder create ecosystem.config.js file: ```console touch ecosystem.config.js ecosystem.config.js: module.exports = [ { script: 'src/index.js', name: 'api', exec_mode: 'cluster', instances: 'max' } ] In fullstack folder, edit docker-compose.prod.yml accordingly (for now, db dependency of api service is commented): version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped #depends_on: # - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true JS application is also commented, for now, to avoid issue trying db connection, .../fullstack/api/src/index.js: console.log('Hi, PM2!'); /* const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let clientDb; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); clientDb = client; count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); const server = app.listen(80); process.addListener('SIGINT', () => { console.log('Received interruption signal!'); server.close((err) => { if (err) { process.exit(1); } else { if (clientDb) { clientDb.close((err) => process.exit(err ? 1 : 0)); } else { process.exit(0); } } }) }) */ In fullstack folder, build, run production api (maybe dbprod volume is missing, so recreate it): docker volume create dbprod docker-compose -f docker-compose.prod.yml build api docker-compose -f docker-compose.prod.yml run api > api@1.0.0 prod > pm2-runtime ecosystem.config.js 2022-02-11T16:19:52: PM2 log: Launching in no daemon mode 2022-02-11T16:19:52: PM2 log: App [api:0] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:0] online 2022-02-11T16:19:52: PM2 log: App [api:1] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:1] online 2022-02-11T16:19:52: PM2 log: App [api:2] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:2] online 2022-02-11T16:19:52: PM2 log: App [api:3] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:3] online 2022-02-11T16:19:52: PM2 log: App [api:4] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:4] online 2022-02-11T16:19:52: PM2 log: App [api:5] starting in -cluster mode- Hi, PM2! Hi, PM2! 2022-02-11T16:19:52: PM2 log: App [api:5] online 2022-02-11T16:19:52: PM2 log: App [api:6] starting in -cluster mode- Hi, PM2! 2022-02-11T16:19:52: PM2 log: App [api:6] online 2022-02-11T16:19:52: PM2 log: App [api:7] starting in -cluster mode- Hi, PM2! 2022-02-11T16:19:52: PM2 log: App [api:7] online Hi, PM2! Hi, PM2! Hi, PM2! Hi, PM2! Have a look to Quick Start page of PM2 In a second terminal exec a container sh session and list PM2 processes: docker exec -it fullstack_api_run_d97c9b2061d1 sh pm2 ls \u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 id \u2502 name \u2502 mode \u2502 \u21ba \u2502 status \u2502 cpu \u2502 memory \u2502 \u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 0 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.4mb \u2502 \u2502 1 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.0mb \u2502 \u2502 2 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.9mb \u2502 \u2502 3 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.5mb \u2502 \u2502 4 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.0mb \u2502 \u2502 5 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.2mb \u2502 \u2502 6 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.3mb \u2502 \u2502 7 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.7mb \u2502 \u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Production Environment Remove references to .env file for api and db service. Values contained in those files (admin and user credentials) will be entered at server start. .../fullstack/docker-compose.prod.yml: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod environment: - MONGO_USERNAME - MONGO_PWD - NODE_ENV=production restart: unless-stopped #depends_on: # - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Add a .dockerignore file in .../fullstack/api folder: touch .dockerignore Add in .dockerignore file '.env' entry to not copy it in container. ../fullstack/api/.dockerignore: .env Test api with passing credentials at run from command line, from .../fullstack folder: MONGO_PWD=123 MONGO_USERNAME=paul docker-compose -f docker-compose.prod.yml run api In a second terminal: docker exec -it fullstack_api_run_16a3f881761e sh env NODE_VERSION=16.14.0 HOSTNAME=65742617b66a YARN_VERSION=1.22.17 SHLVL=1 HOME=/root TERM=xterm MONGO_USERNAME=paul PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app MONGO_PWD=123 NODE_ENV=production Gitlab, Placing the project on Browse to Gitlab and create a new blank project called 'docker-production'. Edit Gitlab user settings to add public SSH Key from local machine, '~/.ssh' folder: cat id_rsa.pub Copy-paste result to \"Add key\" form entry in Gitlab. Back to 'docker-production' project's page, click on clone button and select \"Open in your IDE - Visual Studio Code (SSH)\" and choose a new local folder (e.g. .../docker-production). From new VS Code project (docker-production) root folder, in a terminal, copy all files from '.../fullstack' folder: cp -R ~/.../.../fullstack/* . In .../docker-production folder: touch .gitignore And following entries to .../docker-production/.gitignore file: .env **/node_modules By clicking on 'Source Control' plugin in VS Code, observe that there's no '.env' file in the list. Finalize git folder initialization: git config user.email \"john@doe.com\" git config user.name \"John Doe\" First commit: git add . git commit -m \"first commit\" git push VPS Setup a Virtual Private Server on OVHcloud or on a Raspberry. Connect to remote server through SSH: ssh user@host Create a new user and add it to sudo group and switch to newly created user: adduser jean usermod -aG sudo jean su jean - Back to host machine, set it up to easily connect to remote through SSH: nano ~/.ssh/config config: Host dockerprod Hostname <ip address> User jean Port 22 Add ssh key to remote server to connect to it without the need to enter the password: ssh-copy-id jean@<remote server ip address> Now simply connect to remote server with: ssh dockerprod Secure configuration of SSH on the server Connected on remote server through SSH, edit SSH demon configuration for minimal safety: sudo nano /etc/ssh/sshd_config Edit entries in sshd_config file as follow: PasswordAuthentication no X11Forwarding no PermitRootLogin no Protocol 2 Reload SSH demon: systemctl reload sshd Now the only way to connect on remote server through SSH is with your own computer with the created user. Finally change permission on home folder for more safety: sudo chmod 700 ~ Domain name Order a domain name. In DNS Zone, edit type \"A\" entry with your remote server IP address. TLS Certificate Let's Encrypt is a certification authority that allow to get free X509 certificate for using TLS protocol. They develop ACME protocol to automate certificates management. Certbot is official client from Let's Encrypt using ACME protocol in an automated manner. Certbot Install Connect to remote server through SSH, then: sudo snap install certbot --classic or sudo apt install certbot Create certificate with certbot, \"domain\" should exactly match your root URL (with and/or without \"www\"): sudo certbot certonly -d DOMAIN1 -d DOMAIN2 -d DOMAIN3 Select 'standalone' option, port 80 should be available. Follow instructions to create a letsencrypt account. Now, certificates should be available in folder '/etc/letsencrypt/live/DOMAIN_NAME'. To use TLS certificate edit compose file as follow by opening port 443 for HTTP and HTTP2 for reverse proxy service, docker-compose.prod.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod environment: - MONGO_USERNAME - MONGO_PWD - NODE_ENV=production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 - 443:443 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Edit reverse-proxy/conf/prod.conf to use HTTP2 with nginx: server { listen 80; return 301 https://sandbox-dyma.ovh$request_uri; } server { listen 443 ssl http2; ssl_certificate /etc/letsencrypt/live/www.sandbox-dyma.ovh/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.sandbox-dyma.ovh/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/www.sandbox-dyma.ovh/chain.pem; ssl_protocols TLSv1.2 TLSv1.3; location / { proxy_pass http://client; } location /api { proxy_pass http://api; } } We force the redirection of requests on port 80 (HTTP requests) on port 443 (HTTPS / HTTP2). For the virtual server listening on port 443, we use the certificates created to be able to use HTTP2 (which uses TLS). To allow reverse proxy to access TLS certificate, create a bind mount with modifying docker-compose.prod.yml file as follow: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod environment: - MONGO_USERNAME - MONGO_PWD - NODE_ENV=production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 - 443:443 volumes: - type: bind source: /etc/letsencrypt target: /etc/letsencrypt restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true We simply mount the /etc/letsencrypt folder which contains our letsencrypt certificates. Launch production From local machine. Git add/commit/push all changes: git add * git commit -m \"prod ready\" git push origin Clone from server Connect to your server through SSH. Get link (https) to clone from GitLab repository. Copy paste link to terminal in your server: git clone https://gitlab.com/... Maybe clone PROD project to /root (sudo -i) instead of /home/paul, for cron certbot renew certificate and also ease docker command (no need to sudo each time). Docker installation On Ubuntu server simply type: sudo snap install docker Check installation: sudo docker DB setup On server, create volume: sudo docker volume create dbprod Initialize db service: sudo MONGO_INITDB_ROOT_PASSWORD=password MONGO_INITDB_ROOT_USERNAME=root docker-compose -f docker-compose.prod.yml run -d db Specify user admin root credential, this user is allowed to everything. Connect to MongoDB client in container: sudo docker-compose exec -it db mongo Authenticate in console: use admin db.auth({user: 'root', pwd: 'password'}) Return '1', means it's OK. Create user used to connect from API to DB: db.createUser({user: 'jean', pwd: '123', roles:[{role: 'readWrite', db: 'test'}]}) Initialize collection in test db: use test db.count.insertOne({count: 0}); DB is now ready and we may quit: sudo docker-compose -f docker-compose.prod.yml down Launch application We just have to launch our application: sudo MONGO_USERNAME=jean MONGO_PWD=123 docker-compose -f docker-compose.prod.yml up -d --build We check that everything is well launched: sudo docker-compose -f docker-compose.prod.yml logs -f You can also access the URL in an Internet browser to test the entire application. TLS Certificate, automatic renewal A letsencrypt certificate is valid 90 days. In this chapter we show you how to automate renewal through a cron job. Test renewal command The pre/post hook are there to free port 80, needed by certbot to renew certificate. \"Manual\" with --force-renewal option to check: sudo certbot --standalone renew --force-renewal --pre-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml stop reverseproxy\" --post-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml restart reverseproxy\" This command should be adapted to your \"/docker-production\" folder and check where is installed Docker Compose with 'which docker-compose'. Add cron task We add cron task: crontab -e Add: 0 0 * * * certbot --standalone renew --pre-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml stop reverseproxy\" --post-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml restart reverseproxy\" We save and we leave the editor: the certificate will be renewed at the right time by certbot automatically. You will have a downtime of a few seconds one day per month approximately every 3 months. Example code You can also find the project code on Github . Quick Reference PM2 commands PM2 metrics : pm2 ls pm2 monit pm2 monitor // start pm2 unmonitor api // stop MongoDB commands Free online monitoring, from MongoDB console: // enable db.enableFreeMonitoring() // disable db.disableFreeMonitoring() List collection: mongo show dbs use test // db show collections db.count.find()","title":"Compose - 11 - Production"},{"location":"docker/11-compose-production/#compose-11-production","text":"Docker Compose - Production","title":"Compose - 11 - Production"},{"location":"docker/11-compose-production/#introduction","text":"Almost same components as the ones presented/used in preceding chapter Docker Compose - Services . For this note (Compose - 11 - Production), we refer to folder architecture and contained files from chapter Docker Compose - Services . This time all those component are going to be set to work in production, on a real server.","title":"Introduction"},{"location":"docker/11-compose-production/#project-components","text":"Introduction to project components: Certbot , to get your site on https:// (encrypted communications) with TLS certificate (little lock before address in Internet browser). NGINX (Http request and reverse proxy). React (Application), could be Vue.js or Angular, would be the same. PM2 , process manager (load balancer) for Node.js. Node.js (API), to get better performance it's advised to get one running instance of Node.js by CPU core (on host server). MongoDB (database), only one instance here (scale is out of scope here). OVHcloud (VPS, virtual private server and DNS). GitLab , code hosting.","title":"Project components"},{"location":"docker/11-compose-production/#project-architecture","text":"Below is a detailed schema of proposed architecture, obviously, everything in dedicated Docker containers: React (build) / / NGINX / / !=/api / --Certbot--NGINX--/ \\ ==/api \\ \\ PM2 \\ --------------- | --------------------- | | | Node.js Node.js Node.js \u2191 \u2191 \u2191 \u2193 \u2193 \u2193 --------------------- | MongoDB | --------------------- Real scalable and performing architecture for single physical server. For huge application running on multiple physical server, see Docker Swarm .","title":"Project architecture"},{"location":"docker/11-compose-production/#sigint","text":"SIGINT: - A signal sent to a process in order to cause it to be interrupted properly (graceful shutdown). This is a bit off topic, but here we will properly handle the Node.js application (API) interrupt signal. In file '.../fullstack/api/src/index.js': const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); process.addListener('SIGINT', () => { console.log('Received interruption signal!'); }) In a terminal: docker-compose -f docker-compose.dev.yml build api docker-compose -f docker-compose.dev.yml run api CTRL + C ^CReceived interruption signal! npm ERR! path /app npm ERR! command failed npm ERR! signal SIGINT npm ERR! command sh -c nodemon ./src/index.js It was just to observe in logs that process correctly receive interruption signal and then there are some red error messages. Below is correct management of process interruption by closing database connection and server that return 1 on exit error. In file '.../fullstack/api/src/index.js': const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let clientDb; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); clientDb = client; count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); const server = app.listen(80); process.addListener('SIGINT', () => { console.log('Received interruption signal!'); server.close((err) => { if (err) { process.exit(1); } else { if (clientDb) { clientDb.close((err) => process.exit(err ? 1 : 0)); } else { process.exit(0); } } }) }) In production we also use LTS (Long-term support) version of alpine node image. In '.../fullstack/api/Dockerfile' file: FROM node:lts-alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [\"npm\", \"start\"] In a terminal (from '.../fullstack' folder), to tests if it's running well. docker-compose -f docker-compose.dev.yml build api docker-compose -f docker-compose.dev.yml run api CTRL + C Still experiment some red error messages in logs after SIGINT received by the process, maybe due to no database connection for now (let's see further on this chapter notes).","title":"SIGINT"},{"location":"docker/11-compose-production/#pm2","text":"One Node.js instance by CPU available threads. Cluster module. In fullstack/api folder, rename Dockerfile as Dockerfile.dev and create new Dockerfile.prod for production: mv Dockerfile Dockerfile.dev touch Dockerfile.prod Edit docker-compose.dev.yml accordingly to use Dockerfile.dev for api service: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile.dev volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.dev ports: - 80:80 depends_on: - api - db volumes: dbtest: Dockerfile.prod: FROM node:lts-alpine WORKDIR /app COPY package.json . RUN npm install RUN npm i pm2 -g # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [ \"npm\", \"run\", \"prod\" ] package.json: { \"name\": \"api\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"start\": \"nodemon ./src/index.js\", \"prod\": \"pm2-runtime ecosystem.config.js\", \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.2\", \"mongodb\": \"^4.3.0\", \"nodemon\": \"^2.0.15\" } } Still in fullstack/api folder create ecosystem.config.js file: ```console touch ecosystem.config.js ecosystem.config.js: module.exports = [ { script: 'src/index.js', name: 'api', exec_mode: 'cluster', instances: 'max' } ] In fullstack folder, edit docker-compose.prod.yml accordingly (for now, db dependency of api service is commented): version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped #depends_on: # - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true JS application is also commented, for now, to avoid issue trying db connection, .../fullstack/api/src/index.js: console.log('Hi, PM2!'); /* const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let clientDb; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); clientDb = client; count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); const server = app.listen(80); process.addListener('SIGINT', () => { console.log('Received interruption signal!'); server.close((err) => { if (err) { process.exit(1); } else { if (clientDb) { clientDb.close((err) => process.exit(err ? 1 : 0)); } else { process.exit(0); } } }) }) */ In fullstack folder, build, run production api (maybe dbprod volume is missing, so recreate it): docker volume create dbprod docker-compose -f docker-compose.prod.yml build api docker-compose -f docker-compose.prod.yml run api > api@1.0.0 prod > pm2-runtime ecosystem.config.js 2022-02-11T16:19:52: PM2 log: Launching in no daemon mode 2022-02-11T16:19:52: PM2 log: App [api:0] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:0] online 2022-02-11T16:19:52: PM2 log: App [api:1] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:1] online 2022-02-11T16:19:52: PM2 log: App [api:2] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:2] online 2022-02-11T16:19:52: PM2 log: App [api:3] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:3] online 2022-02-11T16:19:52: PM2 log: App [api:4] starting in -cluster mode- 2022-02-11T16:19:52: PM2 log: App [api:4] online 2022-02-11T16:19:52: PM2 log: App [api:5] starting in -cluster mode- Hi, PM2! Hi, PM2! 2022-02-11T16:19:52: PM2 log: App [api:5] online 2022-02-11T16:19:52: PM2 log: App [api:6] starting in -cluster mode- Hi, PM2! 2022-02-11T16:19:52: PM2 log: App [api:6] online 2022-02-11T16:19:52: PM2 log: App [api:7] starting in -cluster mode- Hi, PM2! 2022-02-11T16:19:52: PM2 log: App [api:7] online Hi, PM2! Hi, PM2! Hi, PM2! Hi, PM2! Have a look to Quick Start page of PM2 In a second terminal exec a container sh session and list PM2 processes: docker exec -it fullstack_api_run_d97c9b2061d1 sh pm2 ls \u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 id \u2502 name \u2502 mode \u2502 \u21ba \u2502 status \u2502 cpu \u2502 memory \u2502 \u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 0 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.4mb \u2502 \u2502 1 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.0mb \u2502 \u2502 2 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.9mb \u2502 \u2502 3 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.5mb \u2502 \u2502 4 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.0mb \u2502 \u2502 5 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.2mb \u2502 \u2502 6 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 45.3mb \u2502 \u2502 7 \u2502 api \u2502 cluster \u2502 0 \u2502 online \u2502 0% \u2502 44.7mb \u2502 \u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"PM2"},{"location":"docker/11-compose-production/#production-environment","text":"Remove references to .env file for api and db service. Values contained in those files (admin and user credentials) will be entered at server start. .../fullstack/docker-compose.prod.yml: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod environment: - MONGO_USERNAME - MONGO_PWD - NODE_ENV=production restart: unless-stopped #depends_on: # - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Add a .dockerignore file in .../fullstack/api folder: touch .dockerignore Add in .dockerignore file '.env' entry to not copy it in container. ../fullstack/api/.dockerignore: .env Test api with passing credentials at run from command line, from .../fullstack folder: MONGO_PWD=123 MONGO_USERNAME=paul docker-compose -f docker-compose.prod.yml run api In a second terminal: docker exec -it fullstack_api_run_16a3f881761e sh env NODE_VERSION=16.14.0 HOSTNAME=65742617b66a YARN_VERSION=1.22.17 SHLVL=1 HOME=/root TERM=xterm MONGO_USERNAME=paul PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app MONGO_PWD=123 NODE_ENV=production","title":"Production Environment"},{"location":"docker/11-compose-production/#gitlab-placing-the-project-on","text":"Browse to Gitlab and create a new blank project called 'docker-production'. Edit Gitlab user settings to add public SSH Key from local machine, '~/.ssh' folder: cat id_rsa.pub Copy-paste result to \"Add key\" form entry in Gitlab. Back to 'docker-production' project's page, click on clone button and select \"Open in your IDE - Visual Studio Code (SSH)\" and choose a new local folder (e.g. .../docker-production). From new VS Code project (docker-production) root folder, in a terminal, copy all files from '.../fullstack' folder: cp -R ~/.../.../fullstack/* . In .../docker-production folder: touch .gitignore And following entries to .../docker-production/.gitignore file: .env **/node_modules By clicking on 'Source Control' plugin in VS Code, observe that there's no '.env' file in the list. Finalize git folder initialization: git config user.email \"john@doe.com\" git config user.name \"John Doe\" First commit: git add . git commit -m \"first commit\" git push","title":"Gitlab, Placing the project on"},{"location":"docker/11-compose-production/#vps","text":"Setup a Virtual Private Server on OVHcloud or on a Raspberry. Connect to remote server through SSH: ssh user@host Create a new user and add it to sudo group and switch to newly created user: adduser jean usermod -aG sudo jean su jean - Back to host machine, set it up to easily connect to remote through SSH: nano ~/.ssh/config config: Host dockerprod Hostname <ip address> User jean Port 22 Add ssh key to remote server to connect to it without the need to enter the password: ssh-copy-id jean@<remote server ip address> Now simply connect to remote server with: ssh dockerprod","title":"VPS"},{"location":"docker/11-compose-production/#secure-configuration-of-ssh-on-the-server","text":"Connected on remote server through SSH, edit SSH demon configuration for minimal safety: sudo nano /etc/ssh/sshd_config Edit entries in sshd_config file as follow: PasswordAuthentication no X11Forwarding no PermitRootLogin no Protocol 2 Reload SSH demon: systemctl reload sshd Now the only way to connect on remote server through SSH is with your own computer with the created user. Finally change permission on home folder for more safety: sudo chmod 700 ~","title":"Secure configuration of SSH on the server"},{"location":"docker/11-compose-production/#domain-name","text":"Order a domain name. In DNS Zone, edit type \"A\" entry with your remote server IP address.","title":"Domain name"},{"location":"docker/11-compose-production/#tls-certificate","text":"Let's Encrypt is a certification authority that allow to get free X509 certificate for using TLS protocol. They develop ACME protocol to automate certificates management. Certbot is official client from Let's Encrypt using ACME protocol in an automated manner.","title":"TLS Certificate"},{"location":"docker/11-compose-production/#certbot-install","text":"Connect to remote server through SSH, then: sudo snap install certbot --classic or sudo apt install certbot Create certificate with certbot, \"domain\" should exactly match your root URL (with and/or without \"www\"): sudo certbot certonly -d DOMAIN1 -d DOMAIN2 -d DOMAIN3 Select 'standalone' option, port 80 should be available. Follow instructions to create a letsencrypt account. Now, certificates should be available in folder '/etc/letsencrypt/live/DOMAIN_NAME'. To use TLS certificate edit compose file as follow by opening port 443 for HTTP and HTTP2 for reverse proxy service, docker-compose.prod.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod environment: - MONGO_USERNAME - MONGO_PWD - NODE_ENV=production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 - 443:443 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Edit reverse-proxy/conf/prod.conf to use HTTP2 with nginx: server { listen 80; return 301 https://sandbox-dyma.ovh$request_uri; } server { listen 443 ssl http2; ssl_certificate /etc/letsencrypt/live/www.sandbox-dyma.ovh/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.sandbox-dyma.ovh/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/www.sandbox-dyma.ovh/chain.pem; ssl_protocols TLSv1.2 TLSv1.3; location / { proxy_pass http://client; } location /api { proxy_pass http://api; } } We force the redirection of requests on port 80 (HTTP requests) on port 443 (HTTPS / HTTP2). For the virtual server listening on port 443, we use the certificates created to be able to use HTTP2 (which uses TLS). To allow reverse proxy to access TLS certificate, create a bind mount with modifying docker-compose.prod.yml file as follow: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile.prod environment: - MONGO_USERNAME - MONGO_PWD - NODE_ENV=production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 - 443:443 volumes: - type: bind source: /etc/letsencrypt target: /etc/letsencrypt restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true We simply mount the /etc/letsencrypt folder which contains our letsencrypt certificates.","title":"Certbot Install"},{"location":"docker/11-compose-production/#launch-production","text":"From local machine. Git add/commit/push all changes: git add * git commit -m \"prod ready\" git push origin","title":"Launch production"},{"location":"docker/11-compose-production/#clone-from-server","text":"Connect to your server through SSH. Get link (https) to clone from GitLab repository. Copy paste link to terminal in your server: git clone https://gitlab.com/... Maybe clone PROD project to /root (sudo -i) instead of /home/paul, for cron certbot renew certificate and also ease docker command (no need to sudo each time).","title":"Clone from server"},{"location":"docker/11-compose-production/#docker-installation","text":"On Ubuntu server simply type: sudo snap install docker Check installation: sudo docker","title":"Docker installation"},{"location":"docker/11-compose-production/#db-setup","text":"On server, create volume: sudo docker volume create dbprod Initialize db service: sudo MONGO_INITDB_ROOT_PASSWORD=password MONGO_INITDB_ROOT_USERNAME=root docker-compose -f docker-compose.prod.yml run -d db Specify user admin root credential, this user is allowed to everything. Connect to MongoDB client in container: sudo docker-compose exec -it db mongo Authenticate in console: use admin db.auth({user: 'root', pwd: 'password'}) Return '1', means it's OK. Create user used to connect from API to DB: db.createUser({user: 'jean', pwd: '123', roles:[{role: 'readWrite', db: 'test'}]}) Initialize collection in test db: use test db.count.insertOne({count: 0}); DB is now ready and we may quit: sudo docker-compose -f docker-compose.prod.yml down","title":"DB setup"},{"location":"docker/11-compose-production/#launch-application","text":"We just have to launch our application: sudo MONGO_USERNAME=jean MONGO_PWD=123 docker-compose -f docker-compose.prod.yml up -d --build We check that everything is well launched: sudo docker-compose -f docker-compose.prod.yml logs -f You can also access the URL in an Internet browser to test the entire application.","title":"Launch application"},{"location":"docker/11-compose-production/#tls-certificate-automatic-renewal","text":"A letsencrypt certificate is valid 90 days. In this chapter we show you how to automate renewal through a cron job.","title":"TLS Certificate, automatic renewal"},{"location":"docker/11-compose-production/#test-renewal-command","text":"The pre/post hook are there to free port 80, needed by certbot to renew certificate. \"Manual\" with --force-renewal option to check: sudo certbot --standalone renew --force-renewal --pre-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml stop reverseproxy\" --post-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml restart reverseproxy\" This command should be adapted to your \"/docker-production\" folder and check where is installed Docker Compose with 'which docker-compose'.","title":"Test renewal command"},{"location":"docker/11-compose-production/#add-cron-task","text":"We add cron task: crontab -e Add: 0 0 * * * certbot --standalone renew --pre-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml stop reverseproxy\" --post-hook \"/snap/bin/docker-compose -f ~/docker-production/docker-compose.prod.yml restart reverseproxy\" We save and we leave the editor: the certificate will be renewed at the right time by certbot automatically. You will have a downtime of a few seconds one day per month approximately every 3 months.","title":"Add cron task"},{"location":"docker/11-compose-production/#example-code","text":"You can also find the project code on Github .","title":"Example code"},{"location":"docker/11-compose-production/#quick-reference","text":"","title":"Quick Reference"},{"location":"docker/11-compose-production/#pm2-commands","text":"PM2 metrics : pm2 ls pm2 monit pm2 monitor // start pm2 unmonitor api // stop","title":"PM2 commands"},{"location":"docker/11-compose-production/#mongodb-commands","text":"Free online monitoring, from MongoDB console: // enable db.enableFreeMonitoring() // disable db.disableFreeMonitoring() List collection: mongo show dbs use test // db show collections db.count.find()","title":"MongoDB commands"},{"location":"docker/2-docker-basis/","text":"Docker - 02 - Basis Node Command to launch node with app.js in folder app CMD [\"node\", \"app/app.js\"] Then from terminal, build command with -t argument to name:tag image . to mention path of Dockerfile in current directory: $ docker build -t node-test-001:latest . To check: $ docker images (or $ docker image ls) To test: $ docker run node-test-001 Hello, world! To auto delete container after execution, use \u2013rm option: $ docker run --rm node-test-001 Hello, world! Check if node is installed on host machine: $ node --version v14.16.1 Test app.js on host machine (if node is installed): $ node app.js Hello, world! VS Code VS Code install Microsoft Docker extension Docker file in short My image -> Docker file =: Base image Modification Action Add Alpine package Add/del Alpine package A base image (e.g. Alpine) is not based on any other image. Add or del package in Alpine $c apk update $c apk add grep $c apk del grep Running container Running container as a running process To demonstrate running container is just a running process on host machine $ docker run -d redis In contrary of a virtual machine (VM) a container is \"just\" a running process sharing Linux kernel on host machine. SRC: - https://stackoverflow.com/questions/64787125/why-doesnt-htop-show-my-docker-processes-using-wsl2 To see running process on WSL use command prompt (would be \"$ sudo ps -ef | grep redis\" on a Linux machine): C:\\> wsl -d docker-desktop top (or C:\\> wsl -d docker-desktop ps -ef) If you want htop, you need to install it first: C:\\> wsl -d docker-desktop apk update C:\\> wsl -d docker-desktop apk add htop ... 0% redis-server *:6379 To kill a process on host machine, WSL: C:\\> wsl -d docker-desktop killall redis-server To kill a process on host machine, Linux: $ sudo killall redis-server Running: C:\\> wsl -d docker-desktop htop See that container isn't running anymore: $ docker container ls Disk usage Show docker disk usage $ docker system df Show detailed information on space usage, -v, --verbose docker system df -v Consumed resource to see live consuming resources of running containers: $ docker container stats Inspect to inspect all configuration of a container $ docker container inspect alpinetest001 Running process Show running process in a container from host $ docker container top alpinetest001 See the difference from inside the container $ docker attach alpine001 update $c apk update add bash $c apk add bash test bash $c bash $c echo $0 bash ctrl+p+q $ docker exec -it alpinetest001 bash if ps not present, install it with: $c apk update && apk add procps then: $c ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 16:15 pts/0 00:00:00 /bin/sh root 16 1 0 16:27 pts/0 00:00:00 bash root 17 0 0 16:28 pts/1 00:00:00 bash root 31 17 0 16:33 pts/1 00:00:00 ps -ef sh and bash does not have parent process ID (PPID) = '0' because of container isolation, container does not see running processes of host machine neither the ones belonging to other containers. Modified file Show modified file in a container: A = added, D = deleted, C = modified $ docker container diff alpinetest001 A /test A /test/test1.txt A /test/test2.txt C /root A /root/.ash_history Copy file copy file from host to container, docker cp path container:path docker cp test1.txt alpinetest001:test copy file from container to host, docker cp container:path path docker cp alpinetest001:test/test2.txt . Execute command in container Execute a command in a container without using terminal $ docker container exec alpine001 mkdir testdir $ docker container exec alpine001 touch /testdir/hello.txt other e.g. $ docker run -d --name redis001 redis $ docker exec -it redis001 redis-cli redis command: set cle 42 get cle exit Get shell in container Get a shell, in a no matter which running container it is: $ docker exec -it redis001 bash $c echo $0 bash if bash not installed in container (e.g. with alpine) you may use sh instead: (if both presents, both works (e.g. redis) $ docker exec -it redis001 sh $c echo $0 sh $ docker run -it -d --name alpine001 alpine $ docker exec -it alpine001 bash OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \"bash\": executable file not found in $PATH: unknown $ docker exec -it alpine001 sh $c echo $0 sh Pause/unpause a container $ docker container start -ai alpine001 $ docker container pause alpine001 $ docker container unpause alpine001 Rename a container rename a container named \"beautiful_leakey\" $ docker container rename beautiful_leakey alpine001 not allowed to rename image Postgres with environnement variable $ docker run -d --name mongo mongo $ docker run -d --name redis redis $ docker run -d --name postgres postgres $ docker logs postgres Error: ... $ docker container rm postgres $ docker container run --name postgres -d -e POSTGRES_HOST_AUTH_METHOD=trust postgres Stop container Stop all running container at once docker stop $(docker ps -aq) Suppress all !Suppress all not used (stopped container(s) and not used for the rest)! $ docker system prune -a Remove image $ docker image rm NAME_OR_ID remove unused images (dangling = image is not tagged and no other image depends on it) $ docker image prune -a Remove container try to remove a running container Launch a background test named redis container with: $ docker run --name test -d redis then try to remove it with: $ docker container rm test Error - Stop the container before attempting removal or force remove Force remove running container: $ docker container rm -f test $ docker run --name test1 -d redis $ docker run --name test2 -d redis $ docker run --name test3 -d redis $ docker container rm -f test1 test2 test3 remove all stopped container $ docker container prune Image, images $ docker images $ docker image ls redis Help to get help, simply type: $ docker help on a command: $ docker ps --help Redis $ docker run redis $ docker run -d redis Alpine $ docker run alpine -i, interactive mode $ docker run -i alpine $c ls . . dev etc home . . . exit -t, terminal -> prompt $ docker run -it alpine (= docker run -it alpine sh) $c echo $0 // check which shell (/bin/sh) $c apk update $c apk add bash $c bash $c echo $0 // check which shell (bash) start in foreground mode $ docker run alpine ping google.ch $ docker run alpine echo hello start in background mode (-d = detach (!= daemon)) $ docker run -d alpine ping google.fr 3593... docker logs 3593... $ docker logs 8e86... --follow Available image show available image(s) $ docker images None running container check none running container with (-a show all containers (default shows just running)): $ docker container ls -a Ubuntu $ docker run -it ubuntu bash $c cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"20.04.3 LTS (Focal Fossa)\" ... to exit container and stop it $c ctrl + d then to start/stop it again, e.g container name is 'trusting_yalow' $ docker start trusting_yalow $ docker stop trusting_yalow then to bash into it $ docker attach trusting_yalow to detach from a docker container without stopping it $c ctrl + p + q Hello, world! $ docker run hello-world Info $ docker info","title":"Docker - 02 - Basis"},{"location":"docker/2-docker-basis/#docker-02-basis","text":"","title":"Docker - 02 - Basis"},{"location":"docker/2-docker-basis/#node","text":"Command to launch node with app.js in folder app CMD [\"node\", \"app/app.js\"] Then from terminal, build command with -t argument to name:tag image . to mention path of Dockerfile in current directory: $ docker build -t node-test-001:latest . To check: $ docker images (or $ docker image ls) To test: $ docker run node-test-001 Hello, world! To auto delete container after execution, use \u2013rm option: $ docker run --rm node-test-001 Hello, world! Check if node is installed on host machine: $ node --version v14.16.1 Test app.js on host machine (if node is installed): $ node app.js Hello, world!","title":"Node"},{"location":"docker/2-docker-basis/#vs-code","text":"VS Code install Microsoft Docker extension","title":"VS Code"},{"location":"docker/2-docker-basis/#docker-file-in-short","text":"My image -> Docker file =: Base image Modification Action","title":"Docker file in short"},{"location":"docker/2-docker-basis/#add-alpine-package","text":"Add/del Alpine package A base image (e.g. Alpine) is not based on any other image. Add or del package in Alpine $c apk update $c apk add grep $c apk del grep","title":"Add Alpine package"},{"location":"docker/2-docker-basis/#running-container","text":"Running container as a running process To demonstrate running container is just a running process on host machine $ docker run -d redis In contrary of a virtual machine (VM) a container is \"just\" a running process sharing Linux kernel on host machine. SRC: - https://stackoverflow.com/questions/64787125/why-doesnt-htop-show-my-docker-processes-using-wsl2 To see running process on WSL use command prompt (would be \"$ sudo ps -ef | grep redis\" on a Linux machine): C:\\> wsl -d docker-desktop top (or C:\\> wsl -d docker-desktop ps -ef) If you want htop, you need to install it first: C:\\> wsl -d docker-desktop apk update C:\\> wsl -d docker-desktop apk add htop ... 0% redis-server *:6379 To kill a process on host machine, WSL: C:\\> wsl -d docker-desktop killall redis-server To kill a process on host machine, Linux: $ sudo killall redis-server Running: C:\\> wsl -d docker-desktop htop See that container isn't running anymore: $ docker container ls","title":"Running container"},{"location":"docker/2-docker-basis/#disk-usage","text":"Show docker disk usage $ docker system df Show detailed information on space usage, -v, --verbose docker system df -v","title":"Disk usage"},{"location":"docker/2-docker-basis/#consumed-resource","text":"to see live consuming resources of running containers: $ docker container stats","title":"Consumed resource"},{"location":"docker/2-docker-basis/#inspect","text":"to inspect all configuration of a container $ docker container inspect alpinetest001","title":"Inspect"},{"location":"docker/2-docker-basis/#running-process","text":"Show running process in a container from host $ docker container top alpinetest001 See the difference from inside the container $ docker attach alpine001 update $c apk update add bash $c apk add bash test bash $c bash $c echo $0 bash ctrl+p+q $ docker exec -it alpinetest001 bash if ps not present, install it with: $c apk update && apk add procps then: $c ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 16:15 pts/0 00:00:00 /bin/sh root 16 1 0 16:27 pts/0 00:00:00 bash root 17 0 0 16:28 pts/1 00:00:00 bash root 31 17 0 16:33 pts/1 00:00:00 ps -ef sh and bash does not have parent process ID (PPID) = '0' because of container isolation, container does not see running processes of host machine neither the ones belonging to other containers.","title":"Running process"},{"location":"docker/2-docker-basis/#modified-file","text":"Show modified file in a container: A = added, D = deleted, C = modified $ docker container diff alpinetest001 A /test A /test/test1.txt A /test/test2.txt C /root A /root/.ash_history","title":"Modified file"},{"location":"docker/2-docker-basis/#copy-file","text":"copy file from host to container, docker cp path container:path docker cp test1.txt alpinetest001:test copy file from container to host, docker cp container:path path docker cp alpinetest001:test/test2.txt .","title":"Copy file"},{"location":"docker/2-docker-basis/#execute-command-in-container","text":"Execute a command in a container without using terminal $ docker container exec alpine001 mkdir testdir $ docker container exec alpine001 touch /testdir/hello.txt other e.g. $ docker run -d --name redis001 redis $ docker exec -it redis001 redis-cli redis command: set cle 42 get cle exit","title":"Execute command in container"},{"location":"docker/2-docker-basis/#get-shell-in-container","text":"Get a shell, in a no matter which running container it is: $ docker exec -it redis001 bash $c echo $0 bash if bash not installed in container (e.g. with alpine) you may use sh instead: (if both presents, both works (e.g. redis) $ docker exec -it redis001 sh $c echo $0 sh $ docker run -it -d --name alpine001 alpine $ docker exec -it alpine001 bash OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \"bash\": executable file not found in $PATH: unknown $ docker exec -it alpine001 sh $c echo $0 sh","title":"Get shell in container"},{"location":"docker/2-docker-basis/#pauseunpause-a-container","text":"$ docker container start -ai alpine001 $ docker container pause alpine001 $ docker container unpause alpine001","title":"Pause/unpause a container"},{"location":"docker/2-docker-basis/#rename-a-container","text":"rename a container named \"beautiful_leakey\" $ docker container rename beautiful_leakey alpine001 not allowed to rename image","title":"Rename a container"},{"location":"docker/2-docker-basis/#postgres-with-environnement-variable","text":"$ docker run -d --name mongo mongo $ docker run -d --name redis redis $ docker run -d --name postgres postgres $ docker logs postgres Error: ... $ docker container rm postgres $ docker container run --name postgres -d -e POSTGRES_HOST_AUTH_METHOD=trust postgres","title":"Postgres with environnement variable"},{"location":"docker/2-docker-basis/#stop-container","text":"Stop all running container at once docker stop $(docker ps -aq)","title":"Stop container"},{"location":"docker/2-docker-basis/#suppress-all","text":"!Suppress all not used (stopped container(s) and not used for the rest)! $ docker system prune -a","title":"Suppress all"},{"location":"docker/2-docker-basis/#remove-image","text":"$ docker image rm NAME_OR_ID remove unused images (dangling = image is not tagged and no other image depends on it) $ docker image prune -a","title":"Remove image"},{"location":"docker/2-docker-basis/#remove-container","text":"try to remove a running container Launch a background test named redis container with: $ docker run --name test -d redis then try to remove it with: $ docker container rm test Error - Stop the container before attempting removal or force remove Force remove running container: $ docker container rm -f test $ docker run --name test1 -d redis $ docker run --name test2 -d redis $ docker run --name test3 -d redis $ docker container rm -f test1 test2 test3 remove all stopped container $ docker container prune","title":"Remove container"},{"location":"docker/2-docker-basis/#image-images","text":"$ docker images $ docker image ls redis","title":"Image, images"},{"location":"docker/2-docker-basis/#help","text":"to get help, simply type: $ docker help on a command: $ docker ps --help","title":"Help"},{"location":"docker/2-docker-basis/#redis","text":"$ docker run redis $ docker run -d redis","title":"Redis"},{"location":"docker/2-docker-basis/#alpine","text":"$ docker run alpine -i, interactive mode $ docker run -i alpine $c ls . . dev etc home . . . exit -t, terminal -> prompt $ docker run -it alpine (= docker run -it alpine sh) $c echo $0 // check which shell (/bin/sh) $c apk update $c apk add bash $c bash $c echo $0 // check which shell (bash) start in foreground mode $ docker run alpine ping google.ch $ docker run alpine echo hello start in background mode (-d = detach (!= daemon)) $ docker run -d alpine ping google.fr 3593... docker logs 3593... $ docker logs 8e86... --follow","title":"Alpine"},{"location":"docker/2-docker-basis/#available-image","text":"show available image(s) $ docker images","title":"Available image"},{"location":"docker/2-docker-basis/#none-running-container","text":"check none running container with (-a show all containers (default shows just running)): $ docker container ls -a","title":"None running container"},{"location":"docker/2-docker-basis/#ubuntu","text":"$ docker run -it ubuntu bash $c cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"20.04.3 LTS (Focal Fossa)\" ... to exit container and stop it $c ctrl + d then to start/stop it again, e.g container name is 'trusting_yalow' $ docker start trusting_yalow $ docker stop trusting_yalow then to bash into it $ docker attach trusting_yalow to detach from a docker container without stopping it $c ctrl + p + q","title":"Ubuntu"},{"location":"docker/2-docker-basis/#hello-world","text":"$ docker run hello-world","title":"Hello, world!"},{"location":"docker/2-docker-basis/#info","text":"$ docker info","title":"Info"},{"location":"docker/3-docker-dockerfile/","text":"Docker - 03 - Docker File Image Variants $ docker pull node:slim node:latest = 992MB VS node:slim = 242MB tag tag to tag image after build $ docker image tag mynode:latest mynode:1.0 history Show the history of an image $ docker history mynode:latest IMAGE CREATED CREATED BY SIZE COMMENT 1a8f184ef896 8 minutes ago sh 42.4MB 14119a10abf4 2 months ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 2 months ago /bin/sh -c #(nop) ADD file:aad4290d27580cc1a\u2026 5.6MB logs $ docker container logs redis-4.0-001 -f to follow -t timestamp COMMIT Snapshot a container to image $ docker run -it alpine sh # mkdir app open a new terminal to copy app.js \"manually\" to app folder $ docker container cp app.js ed6:/app/ then from inside container install node.js $c apk add --update nodejs then quit container and from host terminal $ docker container commit -c 'CMD [\"node\", \"/app/app.js\"]' ed6 mynode $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode latest 1a8f184ef896 6 seconds ago 48MB .. $ docker run --rm mynode hello node-test-010 LABEL LABEL to add meta information LABEL MAINTAINER=oldu73@gmail.com LABEL version=1.0 $ docker build -t node10 . $ docker image inspect node10:latest | less /oldu .. \"MAINTAINER\": \"oldu73@gmail.com\", \"version\": \"1.0\" } .. ENV key value Usable in container, available as environment variable: ENV environment=production $ docker build -t node10 . $ docker run -it node10 sh /app $c env HOSTNAME=ac68969910b7 SHLVL=1 HOME=/root environment=production TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app ARG Argument available at build time only: ARG folder ARG file then WORKDIR $folder COPY $file . then $ docker build --build-arg folder=/app --build-arg file=app.js -t node-test-008 . then if you try to retriev ARGs by typing env inside the container you do not retrieve it because they are available only at build time: $ docker run --rm -it node-test-008 sh /app # env HOSTNAME=22cc31c49889 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app You may also put a default value: ARG folder=/app then $ docker build --build-arg file=app.js -t node-test-008 . Override entry point You can still override the entry point with the --entrypoint option: $ docker run --rm --entrypoint=\"echo\" node:test \"Hi, earth ;)\" or $ docker run -it --entrypoint=\"/bin/sh\" node:test Docker default entry point By default, Docker has a default entry point which is \"/bin/sh -c\" but does not have a default command. $ man sh -> /-c -c Read commands from the command_string operand instead of from the standard input. Special parameter 0 will be set from the command_name operand and the positional parameters ($1, $2, etc.) set from the remaining argument operands. ENTRYPOINT and CMD May have ENTRYPOINT and CMD: ENTRYPOINT [\"echo\"] CMD [\"hello\"] $ docker run --rm node:test hello then you may override hello in run parameter: $ docker run --rm node:test world world exec form [] exec form -> recommended .. shell form, like you would type the command in a terminal ENTRYPOINT instead CMD ENTRYPOINT instead CMD avoid availability for end user to replace Dockerfile CMD by typing one at the end of run terminal command: ENTRYPOINT [\"node\", \"app.js\"] in Dockerfile, then: $ docker run --rm node:test Bonjour or $ docker run --rm node:test echo test Bonjour same same ;-), echo test at the end is not taking under consideration Command at the end of run Typing a command at the end of the run command replace the one in Dockerfile: $ docker run --rm node:test echo test test even if \"CMD [\"node\", \"app.js\"]\" in Dockerfile Remove dangling images Remove dangling ( ) images: $ docker image prune For removing dangling and ununsed images: $ docker image prune -a Docker build no output Docker build not showing any output from commands(Dockerfile RUN): Dockerfile .. RUN echo hello Don't show anything in console at build. Use legacy mode by adding 'DOCKER_BUILDKIT=0' in front of docker build: $ DOCKER_BUILDKIT=0 docker build -t test:latest . .. Step 2/2 : RUN echo hello ---> Running in 3d9c96daa522 hello or (new fashion) with \"--progress=plain --no-cache\" after build command: $ docker build --progress=plain --no-cache -t node-test-007:latest . [3/5] RUN echo \"Hello, world!\" sha256:54040767d950b92027e2e377a0938fd42b89a34fa5d76e3ce281deacda0f1959 0.281 Hello, world! DONE 0.3s List only container names To list only names of all containers: $ docker ps -a --format='{{.Names}}' ENV 'ENV', environment variable: Dockerfile: - Base image - Test environment variable FROM alpine ENV DIR=/app WORKDIR ${DIR}/back then.. $ docker build -t node-test-006:latest . then.. $ docker run -it node-test-006 sh $c pwd /app/back RUN RUN exist in 'exec' and 'shell' mode (which is 'sh' by default). exec: RUN [\"/bin/bash\", \"-c\", \"echo Bonjour !\"] shell: RUN echo \"Bonjour !\" CMD Remove CMD line to test container in interactive mode, then build: $ docker build -t node-test-005:test . Launch a container in interactive mode with sh as shell. Don't forget to mention image tag after ':' as long as it ain't 'latest', and to mention the shell at the end, 'sh': $ docker run -it node-test-005:test sh /app $c As we can see, we are directly in 'app' folder. And by typing 'echo $0' to check shell is indeed, 'sh': $c echo $0 sh And check 'node' version: $c node --version v14.18.1 And test 'app.js' (in app.js -> console.log('Hi test 005');): $c node app.js Hi test 005 WORKDIR WORKDIR define working directory in image: WORKDIR /app Then, for COPY command, no need to specify destination directory: COPY ./app.js . Also for CMD: CMD [\"node\", \"app.js\"] WORKDIR can be changed during the Dockerfile by being filled in again. WORKDIR can create folders if they do not exist (this saves us a mkdir). FROM Only one FROM command by Dockerfile VS Code Dockerfile command VS Code, in a Dockerfile, hit ctrl+space to get a list of available commands. Shortcut available due to Docker Microsoft extension installed in VS Code. ADD source destination ADD source destination, similar to COPY but from URL or compressed file. If it's a compressed file it will be automatically uncompressed. Copy context Dockerfile context is current folder. Could not COPY file from parent folder. Remove image with pattern Remove all images that contain a pattern: $ docker image rm $(docker images --format \"{{.Repository}}\" | grep node-test-00) Optimize cache Optimizing cache. Only the RUN, COPY, and ADD instructions create new layers and increase the size of an image. It is therefore necessary to avoid multiplying the RUN commands, and try to group all the necessary commands in a single RUN instruction (multi-line separator '\\'): FROM ubuntu ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update && apt-get install -y \\ git \\ nodejs \\ && rm -rf /var/lib/apt/lists/* It's recommended to put one installation by line, alphabetically sorted. !! It is mandatory to put apt-get update and apt-get install in the same RUN statement. Otherwise you will have serious cache problems.!! For images using Ubuntu or Debian, it is recommended to remove /var/lib/apt/ lists which contains the APT cache with all available packages in order to reduce the size of the image. ENV DEBIAN_FRONTEND=noninteractive allows us to specify to the Debian Package Manager (APT) that we are in a non-interactive environment for the installation. This avoids the prompts requested by some programs during installation (eg Git). Invalidate cache !Important! Invalidate cache at build. If you have following instruction in Dockerfile it will be run only once at first build then cached: RUN apt update && apt dist-upgrade -y To not use a cache, you have to do: docker build --no-cache -t test . Inspect Go template docker inspect with Go template for format parameter. e.g. to retrieve CMD: $ docker inspect --format='{{.Config.Cmd}}' node-test-001 [node app/app.js] Show the history of an image: $ docker image history node-test-001 Image size node image = 900 MB/3 min VS alpine + node install = 50 MB/30 sec => ??? First build of node based image takes around 3 minutes. Intermediate steps are cached by Docker. Second build of node based image takes now only around 3 seconds. Dockerfile build image Docker file, steps to build an image. Instructions: - FROM // pull image from docker hub \\ = layer - RUN // add node / new image/running intermediate container - COPY / = layer new image/running intermediate container - CMD constructed image resulting from the different images, layers, and intermediate containers You can't run commands in an image, so you need intermediate container. Dockerfile context !! Warning !! Create a Dockerfile then build image in a dedicated folder for your application Otherwise, all files/folders contained in where you build image will be sent to the daemon at build time as the context. It is for this reason that you must create the Dockerfile in the folder of your application, or here to test, in a separate folder. If you create your Dockerfile directly in the root / directory, your entire hard drive is sent as context to the daemon! APK apk = Alpine Package Management It is the equivalent of APT for Debian distributions and therefore in particular for Ubuntu apk add --update actually allows you to do apk update first, then apk add. Debian equivalent of: apt update && apt install && lets you do something based on whether the previous command completed successfully - that's why you tend to see it chained as do_something && do_something_else_that_depended_on_something. Furthermore, you also have || which is the logical or, and also ; which is just a separator which doesn't care what happen to the command before. Dockerfile Create a new folder docker-test. Open it with VS Code. In this example we gonna crate a node image (based on Alpine, not on official node image) to simply test console log in a js file. Create a new file named, with VS Code, 'app.js' and type in it: console.log('Hello, world!'); Then, create a new file, in folder, with VS Code, named: Dockerfile Base image Install node Copy js file from local folder to container. If folder does not exist, it will be created. Type following commands in newly created Dockerfile file (exactly respect the case and do not add any extensions): FROM alpine RUN apk add --update nodejs COPY ./app.js /app/","title":"Docker - 03 - Docker File"},{"location":"docker/3-docker-dockerfile/#docker-03-docker-file","text":"","title":"Docker - 03 - Docker File"},{"location":"docker/3-docker-dockerfile/#image-variants","text":"$ docker pull node:slim node:latest = 992MB VS node:slim = 242MB","title":"Image Variants"},{"location":"docker/3-docker-dockerfile/#tag","text":"tag to tag image after build $ docker image tag mynode:latest mynode:1.0","title":"tag"},{"location":"docker/3-docker-dockerfile/#history","text":"Show the history of an image $ docker history mynode:latest IMAGE CREATED CREATED BY SIZE COMMENT 1a8f184ef896 8 minutes ago sh 42.4MB 14119a10abf4 2 months ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 2 months ago /bin/sh -c #(nop) ADD file:aad4290d27580cc1a\u2026 5.6MB","title":"history"},{"location":"docker/3-docker-dockerfile/#logs","text":"$ docker container logs redis-4.0-001 -f to follow -t timestamp","title":"logs"},{"location":"docker/3-docker-dockerfile/#commit","text":"Snapshot a container to image $ docker run -it alpine sh # mkdir app open a new terminal to copy app.js \"manually\" to app folder $ docker container cp app.js ed6:/app/ then from inside container install node.js $c apk add --update nodejs then quit container and from host terminal $ docker container commit -c 'CMD [\"node\", \"/app/app.js\"]' ed6 mynode $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode latest 1a8f184ef896 6 seconds ago 48MB .. $ docker run --rm mynode hello node-test-010","title":"COMMIT"},{"location":"docker/3-docker-dockerfile/#label","text":"LABEL to add meta information LABEL MAINTAINER=oldu73@gmail.com LABEL version=1.0 $ docker build -t node10 . $ docker image inspect node10:latest | less /oldu .. \"MAINTAINER\": \"oldu73@gmail.com\", \"version\": \"1.0\" } ..","title":"LABEL"},{"location":"docker/3-docker-dockerfile/#env","text":"key value Usable in container, available as environment variable: ENV environment=production $ docker build -t node10 . $ docker run -it node10 sh /app $c env HOSTNAME=ac68969910b7 SHLVL=1 HOME=/root environment=production TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app","title":"ENV"},{"location":"docker/3-docker-dockerfile/#arg","text":"Argument available at build time only: ARG folder ARG file then WORKDIR $folder COPY $file . then $ docker build --build-arg folder=/app --build-arg file=app.js -t node-test-008 . then if you try to retriev ARGs by typing env inside the container you do not retrieve it because they are available only at build time: $ docker run --rm -it node-test-008 sh /app # env HOSTNAME=22cc31c49889 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app You may also put a default value: ARG folder=/app then $ docker build --build-arg file=app.js -t node-test-008 .","title":"ARG"},{"location":"docker/3-docker-dockerfile/#override-entry-point","text":"You can still override the entry point with the --entrypoint option: $ docker run --rm --entrypoint=\"echo\" node:test \"Hi, earth ;)\" or $ docker run -it --entrypoint=\"/bin/sh\" node:test","title":"Override entry point"},{"location":"docker/3-docker-dockerfile/#docker-default-entry-point","text":"By default, Docker has a default entry point which is \"/bin/sh -c\" but does not have a default command. $ man sh -> /-c -c Read commands from the command_string operand instead of from the standard input. Special parameter 0 will be set from the command_name operand and the positional parameters ($1, $2, etc.) set from the remaining argument operands.","title":"Docker default entry point"},{"location":"docker/3-docker-dockerfile/#entrypoint-and-cmd","text":"May have ENTRYPOINT and CMD: ENTRYPOINT [\"echo\"] CMD [\"hello\"] $ docker run --rm node:test hello then you may override hello in run parameter: $ docker run --rm node:test world world","title":"ENTRYPOINT and CMD"},{"location":"docker/3-docker-dockerfile/#exec-form","text":"[] exec form -> recommended .. shell form, like you would type the command in a terminal","title":"exec form"},{"location":"docker/3-docker-dockerfile/#entrypoint-instead-cmd","text":"ENTRYPOINT instead CMD avoid availability for end user to replace Dockerfile CMD by typing one at the end of run terminal command: ENTRYPOINT [\"node\", \"app.js\"] in Dockerfile, then: $ docker run --rm node:test Bonjour or $ docker run --rm node:test echo test Bonjour same same ;-), echo test at the end is not taking under consideration","title":"ENTRYPOINT instead CMD"},{"location":"docker/3-docker-dockerfile/#command-at-the-end-of-run","text":"Typing a command at the end of the run command replace the one in Dockerfile: $ docker run --rm node:test echo test test even if \"CMD [\"node\", \"app.js\"]\" in Dockerfile","title":"Command at the end of run"},{"location":"docker/3-docker-dockerfile/#remove-dangling-images","text":"Remove dangling ( ) images: $ docker image prune For removing dangling and ununsed images: $ docker image prune -a","title":"Remove dangling images"},{"location":"docker/3-docker-dockerfile/#docker-build-no-output","text":"Docker build not showing any output from commands(Dockerfile RUN): Dockerfile .. RUN echo hello Don't show anything in console at build. Use legacy mode by adding 'DOCKER_BUILDKIT=0' in front of docker build: $ DOCKER_BUILDKIT=0 docker build -t test:latest . .. Step 2/2 : RUN echo hello ---> Running in 3d9c96daa522 hello or (new fashion) with \"--progress=plain --no-cache\" after build command: $ docker build --progress=plain --no-cache -t node-test-007:latest . [3/5] RUN echo \"Hello, world!\" sha256:54040767d950b92027e2e377a0938fd42b89a34fa5d76e3ce281deacda0f1959 0.281 Hello, world! DONE 0.3s","title":"Docker build no output"},{"location":"docker/3-docker-dockerfile/#list-only-container-names","text":"To list only names of all containers: $ docker ps -a --format='{{.Names}}'","title":"List only container names"},{"location":"docker/3-docker-dockerfile/#env_1","text":"'ENV', environment variable: Dockerfile: - Base image - Test environment variable FROM alpine ENV DIR=/app WORKDIR ${DIR}/back then.. $ docker build -t node-test-006:latest . then.. $ docker run -it node-test-006 sh $c pwd /app/back","title":"ENV"},{"location":"docker/3-docker-dockerfile/#run","text":"RUN exist in 'exec' and 'shell' mode (which is 'sh' by default). exec: RUN [\"/bin/bash\", \"-c\", \"echo Bonjour !\"] shell: RUN echo \"Bonjour !\"","title":"RUN"},{"location":"docker/3-docker-dockerfile/#cmd","text":"Remove CMD line to test container in interactive mode, then build: $ docker build -t node-test-005:test . Launch a container in interactive mode with sh as shell. Don't forget to mention image tag after ':' as long as it ain't 'latest', and to mention the shell at the end, 'sh': $ docker run -it node-test-005:test sh /app $c As we can see, we are directly in 'app' folder. And by typing 'echo $0' to check shell is indeed, 'sh': $c echo $0 sh And check 'node' version: $c node --version v14.18.1 And test 'app.js' (in app.js -> console.log('Hi test 005');): $c node app.js Hi test 005","title":"CMD"},{"location":"docker/3-docker-dockerfile/#workdir","text":"WORKDIR define working directory in image: WORKDIR /app Then, for COPY command, no need to specify destination directory: COPY ./app.js . Also for CMD: CMD [\"node\", \"app.js\"] WORKDIR can be changed during the Dockerfile by being filled in again. WORKDIR can create folders if they do not exist (this saves us a mkdir).","title":"WORKDIR"},{"location":"docker/3-docker-dockerfile/#from","text":"Only one FROM command by Dockerfile","title":"FROM"},{"location":"docker/3-docker-dockerfile/#vs-code-dockerfile-command","text":"VS Code, in a Dockerfile, hit ctrl+space to get a list of available commands. Shortcut available due to Docker Microsoft extension installed in VS Code.","title":"VS Code Dockerfile command"},{"location":"docker/3-docker-dockerfile/#add-source-destination","text":"ADD source destination, similar to COPY but from URL or compressed file. If it's a compressed file it will be automatically uncompressed.","title":"ADD source destination"},{"location":"docker/3-docker-dockerfile/#copy-context","text":"Dockerfile context is current folder. Could not COPY file from parent folder.","title":"Copy context"},{"location":"docker/3-docker-dockerfile/#remove-image-with-pattern","text":"Remove all images that contain a pattern: $ docker image rm $(docker images --format \"{{.Repository}}\" | grep node-test-00)","title":"Remove image with pattern"},{"location":"docker/3-docker-dockerfile/#optimize-cache","text":"Optimizing cache. Only the RUN, COPY, and ADD instructions create new layers and increase the size of an image. It is therefore necessary to avoid multiplying the RUN commands, and try to group all the necessary commands in a single RUN instruction (multi-line separator '\\'): FROM ubuntu ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update && apt-get install -y \\ git \\ nodejs \\ && rm -rf /var/lib/apt/lists/* It's recommended to put one installation by line, alphabetically sorted. !! It is mandatory to put apt-get update and apt-get install in the same RUN statement. Otherwise you will have serious cache problems.!! For images using Ubuntu or Debian, it is recommended to remove /var/lib/apt/ lists which contains the APT cache with all available packages in order to reduce the size of the image. ENV DEBIAN_FRONTEND=noninteractive allows us to specify to the Debian Package Manager (APT) that we are in a non-interactive environment for the installation. This avoids the prompts requested by some programs during installation (eg Git).","title":"Optimize cache"},{"location":"docker/3-docker-dockerfile/#invalidate-cache","text":"!Important! Invalidate cache at build. If you have following instruction in Dockerfile it will be run only once at first build then cached: RUN apt update && apt dist-upgrade -y To not use a cache, you have to do: docker build --no-cache -t test .","title":"Invalidate cache"},{"location":"docker/3-docker-dockerfile/#inspect-go-template","text":"docker inspect with Go template for format parameter. e.g. to retrieve CMD: $ docker inspect --format='{{.Config.Cmd}}' node-test-001 [node app/app.js]","title":"Inspect Go template"},{"location":"docker/3-docker-dockerfile/#_1","text":"Show the history of an image: $ docker image history node-test-001","title":""},{"location":"docker/3-docker-dockerfile/#image-size","text":"node image = 900 MB/3 min VS alpine + node install = 50 MB/30 sec => ??? First build of node based image takes around 3 minutes. Intermediate steps are cached by Docker. Second build of node based image takes now only around 3 seconds.","title":"Image size"},{"location":"docker/3-docker-dockerfile/#dockerfile-build-image","text":"Docker file, steps to build an image. Instructions: - FROM // pull image from docker hub \\ = layer - RUN // add node / new image/running intermediate container - COPY / = layer new image/running intermediate container - CMD constructed image resulting from the different images, layers, and intermediate containers You can't run commands in an image, so you need intermediate container.","title":"Dockerfile build image"},{"location":"docker/3-docker-dockerfile/#dockerfile-context","text":"!! Warning !! Create a Dockerfile then build image in a dedicated folder for your application Otherwise, all files/folders contained in where you build image will be sent to the daemon at build time as the context. It is for this reason that you must create the Dockerfile in the folder of your application, or here to test, in a separate folder. If you create your Dockerfile directly in the root / directory, your entire hard drive is sent as context to the daemon!","title":"Dockerfile context"},{"location":"docker/3-docker-dockerfile/#apk","text":"apk = Alpine Package Management It is the equivalent of APT for Debian distributions and therefore in particular for Ubuntu apk add --update actually allows you to do apk update first, then apk add. Debian equivalent of: apt update && apt install && lets you do something based on whether the previous command completed successfully - that's why you tend to see it chained as do_something && do_something_else_that_depended_on_something. Furthermore, you also have || which is the logical or, and also ; which is just a separator which doesn't care what happen to the command before.","title":"APK"},{"location":"docker/3-docker-dockerfile/#dockerfile","text":"Create a new folder docker-test. Open it with VS Code. In this example we gonna crate a node image (based on Alpine, not on official node image) to simply test console log in a js file. Create a new file named, with VS Code, 'app.js' and type in it: console.log('Hello, world!'); Then, create a new file, in folder, with VS Code, named: Dockerfile Base image Install node Copy js file from local folder to container. If folder does not exist, it will be created. Type following commands in newly created Dockerfile file (exactly respect the case and do not add any extensions): FROM alpine RUN apk add --update nodejs COPY ./app.js /app/","title":"Dockerfile"},{"location":"docker/4-docker-dockerhub/","text":"Docker - 04 - Docker Hub export/import for container docker container export/import $ docker build -t mynode . $ docker run -it mynode sh $c touch hello.txt $c exit $ docker container ps -a CONTAINER ID IMAGE 3d8e43e502b0 mynode $ docker container export -o mycontainer.tar 3d8 $ tar -tvf mycontainer.tar $ docker container rm 3d8 $ docker image import mycontainer.tar nodetest $ docker images REPOSITORY TAG nodetest latest $ docker image inspect nodetest:latest Only one layer because exporting a container is like creating an image from a file system. It's not possible to relaunch a container directly from another exported container. You must first create an image with import. tar for image docker image save/load <-> tar $ docker build -t mynode:0.1 . $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode 0.1 c68e7a86d468 8 seconds ago 48MB $ docker image save -o monimage.tar mynode (to compress with gzip: docker save mon_image | gzip > mon_image.tar.gz) $ tar -tvf monimage.tar $ docker image prune -a $ docker image load < monimage.tar or $ docker image load -i mon_image.tar $ docker run --rm mynode:0.1 hello node-test-012 Encrypt identifiers Encrypt your identifiers GNU/Linux $ sudo apt install pass $ gpg2 --gen-key Enter your name and email when requested. Then do: $ wget https://github.com/docker/docker-credential-helpers/releases/download/v0.6.3/docker-credential-pass-v0.6.3-amd64.tar.gz && tar -xf docker-credential-pass-v0.6.3-amd64.tar.gz && chmod +x docker-credential-pass && sudo mv docker-credential-pass /usr/local/bin/ $ pass init \"YOUR NAME\" $ nano ~/.docker/config.json then: { \"credsStore\": \"pass\" } $ docker login Push image Push image to docker hub $ docker login $ docker build -t oldu73/mynode . $ docker image push oldu73/mynode $ docker image prune -a $ docker run --rm oldu73/mynode $ docker logout Docker hub docker image pull docker image push docker image pull/push / :[tag] docker search https://hub.docker.com/ $ docker pull node $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE node latest 7220633f01cd 7 days ago 992MB $ docker run -it --rm node sh $c ls $c node -v1 $c mkdir app $c cd app $c echo \"console.log('Hello, world!');\" > app.js $c node app.js","title":"Docker - 04 - Docker Hub"},{"location":"docker/4-docker-dockerhub/#docker-04-docker-hub","text":"","title":"Docker - 04 - Docker Hub"},{"location":"docker/4-docker-dockerhub/#exportimport","text":"for container docker container export/import $ docker build -t mynode . $ docker run -it mynode sh $c touch hello.txt $c exit $ docker container ps -a CONTAINER ID IMAGE 3d8e43e502b0 mynode $ docker container export -o mycontainer.tar 3d8 $ tar -tvf mycontainer.tar $ docker container rm 3d8 $ docker image import mycontainer.tar nodetest $ docker images REPOSITORY TAG nodetest latest $ docker image inspect nodetest:latest Only one layer because exporting a container is like creating an image from a file system. It's not possible to relaunch a container directly from another exported container. You must first create an image with import.","title":"export/import"},{"location":"docker/4-docker-dockerhub/#tar","text":"for image docker image save/load <-> tar $ docker build -t mynode:0.1 . $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode 0.1 c68e7a86d468 8 seconds ago 48MB $ docker image save -o monimage.tar mynode (to compress with gzip: docker save mon_image | gzip > mon_image.tar.gz) $ tar -tvf monimage.tar $ docker image prune -a $ docker image load < monimage.tar or $ docker image load -i mon_image.tar $ docker run --rm mynode:0.1 hello node-test-012","title":"tar"},{"location":"docker/4-docker-dockerhub/#encrypt-identifiers","text":"Encrypt your identifiers GNU/Linux $ sudo apt install pass $ gpg2 --gen-key Enter your name and email when requested. Then do: $ wget https://github.com/docker/docker-credential-helpers/releases/download/v0.6.3/docker-credential-pass-v0.6.3-amd64.tar.gz && tar -xf docker-credential-pass-v0.6.3-amd64.tar.gz && chmod +x docker-credential-pass && sudo mv docker-credential-pass /usr/local/bin/ $ pass init \"YOUR NAME\" $ nano ~/.docker/config.json then: { \"credsStore\": \"pass\" } $ docker login","title":"Encrypt identifiers"},{"location":"docker/4-docker-dockerhub/#push-image","text":"Push image to docker hub $ docker login $ docker build -t oldu73/mynode . $ docker image push oldu73/mynode $ docker image prune -a $ docker run --rm oldu73/mynode $ docker logout","title":"Push image"},{"location":"docker/4-docker-dockerhub/#docker-hub","text":"docker image pull docker image push docker image pull/push / :[tag] docker search https://hub.docker.com/ $ docker pull node $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE node latest 7220633f01cd 7 days ago 992MB $ docker run -it --rm node sh $c ls $c node -v1 $c mkdir app $c cd app $c echo \"console.log('Hello, world!');\" > app.js $c node app.js","title":"Docker hub"},{"location":"docker/5-docker-nodeserver/","text":"Docker - 05 - Node Server Node Server Image Stats Show resource usage statistic Maybe tried with Node server project running $ docker run --rm -d --name appnode -p 80:80 myapp Then $ docker stats After, open a browser at http://localhost/ address Click a lot on refresh button to see CPU % growing in stats terminal's live view. Detach mode -d option $ docker run --rm -d --name appnode -p 80:80 myapp --rm to remove container automatically after stop Then to go back inside running detached container $ docker exec -it appnode sh .dockerignore In current project folder, create a new file named \".dockerignore\" Add also a sample text file \"hello.txt\" file that maybe contain \"to be ignored\" sentence. Re-build image $ docker build -t myapp . Launch it in interactive mode with sh $ docker run --rm -it myapp sh ls/cat hello.txt file in container output respectively presence/content of hello.txt file. Now list hello.txt file in .dockerignore file # for current folder hello.txt # for first level of folder */hello.txt # for everywhere **/hello.txt # exception with ! **/*.txt !README.txt Re-build image Re-launch it in interactive mode ls output does not contain hello.txt file anymore Optimization Let's say we change listening port of Node server project from 80 to 70 file app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(70); Re-build image $ docker build -t myapp . => [4/4] RUN npm install 7.1s What we observe here is that NPM install is run again although only listening port in app.js has been modified. To avoid this behavior, Docker file should be modified accordingly. Split COPY instruction in two, before and after \"RUN npm install\" to not invalidate cache for dependencies (package.json). Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"app.js\"] And now, on build image after changing listening port in app.js $ docker build -t myapp . => [4/4] RUN npm install 0.0s Redirect port Redirect port from host to container docker run ... -p <hostport>:<containerport> ... -p option: -p, --publish list Publish a container's port(s) to the host To fix Node server project, add missing port redirection to run command: $ docker run --rm -p 80:80 myapp Many containers may listen on same port number because they're isolated. $ docker run --rm -d -p 81:80 myapp $ docker run --rm -d -p 82:80 myapp On the other hand, on the host, only one forwarding on a port is possible. One port = one application! Without opening port, a container may access to Internet. Outgoing traffic is possible. By default, all incoming traffic is blocked, all ports are closed by default. Port http 80 https 443 ssh 22 Node server project Node server project to return a minimal page in a browser at localhost address, with Express (which is a Node.js framework) Our image should have Node.js and its npm package manager. It should have several dependencies: nodemon and express. And it will have to launch the app contained in app.js by default. For the project, we'll create a new Dockerfile in a folder. In the same folder we will also have a package.json file (which allows you to manage the dependencies used) and an app.js file (which will contain our application). In the package.json file therefore have our two dependencies. In the app.js file we just have an Express route which will send in JSON format the character string \"Hello, world!\" for all routes. folder: - /mnt/c/tmp/docker/node-server $ touch package.json edit package.json { \"dependencies\": { \"nodemon\": \"2.0.14\", \"express\": \"4.17.1\" } } $ touch app.js edit app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); $ touch Dockerfile Browse a bit docker hub and look for alpine tagged image more lighter (169MB) than the official one (latest) (992MB) FROM node:alpine WORKDIR /app COPY . . RUN npm install CMD [\"nodemon\", \"app.js\"] then.. $ docker build -t myapp . $ docker image ls $ docker run --rm myapp path error to debug, run in interactive mode with sh to override Dockerfile CMD $ docker run --rm -it myapp sh /app $c env /app $c nodemon sh: nodemon: not found $c cd node_modules/.bin/ /app/node_modules/.bin # ls is-ci mime nodemon /app $c ./node_modules/.bin/nodemon app.js Fix the Docker file with adding value to image's path .. ENV PATH=$PATH:/app/node_modules/.bin .. $ docker build -t myapp . $ docker run --rm -it myapp sh /app $c env | grep PATH PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin /app $c nodemon app.js Now it's OK $ docker run --rm myapp Try \"localhost\" in a browser -> does not work and it's normal because default behavior does not allow to communicate with a container.","title":"Docker - 05 - Node Server"},{"location":"docker/5-docker-nodeserver/#docker-05-node-server","text":"Node Server Image","title":"Docker - 05 - Node Server"},{"location":"docker/5-docker-nodeserver/#stats","text":"Show resource usage statistic Maybe tried with Node server project running $ docker run --rm -d --name appnode -p 80:80 myapp Then $ docker stats After, open a browser at http://localhost/ address Click a lot on refresh button to see CPU % growing in stats terminal's live view.","title":"Stats"},{"location":"docker/5-docker-nodeserver/#detach-mode","text":"-d option $ docker run --rm -d --name appnode -p 80:80 myapp --rm to remove container automatically after stop Then to go back inside running detached container $ docker exec -it appnode sh","title":"Detach mode"},{"location":"docker/5-docker-nodeserver/#dockerignore","text":"In current project folder, create a new file named \".dockerignore\" Add also a sample text file \"hello.txt\" file that maybe contain \"to be ignored\" sentence. Re-build image $ docker build -t myapp . Launch it in interactive mode with sh $ docker run --rm -it myapp sh ls/cat hello.txt file in container output respectively presence/content of hello.txt file. Now list hello.txt file in .dockerignore file # for current folder hello.txt # for first level of folder */hello.txt # for everywhere **/hello.txt # exception with ! **/*.txt !README.txt Re-build image Re-launch it in interactive mode ls output does not contain hello.txt file anymore","title":".dockerignore"},{"location":"docker/5-docker-nodeserver/#optimization","text":"Let's say we change listening port of Node server project from 80 to 70 file app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(70); Re-build image $ docker build -t myapp . => [4/4] RUN npm install 7.1s What we observe here is that NPM install is run again although only listening port in app.js has been modified. To avoid this behavior, Docker file should be modified accordingly. Split COPY instruction in two, before and after \"RUN npm install\" to not invalidate cache for dependencies (package.json). Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"app.js\"] And now, on build image after changing listening port in app.js $ docker build -t myapp . => [4/4] RUN npm install 0.0s","title":"Optimization"},{"location":"docker/5-docker-nodeserver/#redirect-port","text":"Redirect port from host to container docker run ... -p <hostport>:<containerport> ... -p option: -p, --publish list Publish a container's port(s) to the host To fix Node server project, add missing port redirection to run command: $ docker run --rm -p 80:80 myapp Many containers may listen on same port number because they're isolated. $ docker run --rm -d -p 81:80 myapp $ docker run --rm -d -p 82:80 myapp On the other hand, on the host, only one forwarding on a port is possible. One port = one application! Without opening port, a container may access to Internet. Outgoing traffic is possible. By default, all incoming traffic is blocked, all ports are closed by default.","title":"Redirect port"},{"location":"docker/5-docker-nodeserver/#port","text":"http 80 https 443 ssh 22","title":"Port"},{"location":"docker/5-docker-nodeserver/#node-server-project","text":"Node server project to return a minimal page in a browser at localhost address, with Express (which is a Node.js framework) Our image should have Node.js and its npm package manager. It should have several dependencies: nodemon and express. And it will have to launch the app contained in app.js by default. For the project, we'll create a new Dockerfile in a folder. In the same folder we will also have a package.json file (which allows you to manage the dependencies used) and an app.js file (which will contain our application). In the package.json file therefore have our two dependencies. In the app.js file we just have an Express route which will send in JSON format the character string \"Hello, world!\" for all routes. folder: - /mnt/c/tmp/docker/node-server $ touch package.json edit package.json { \"dependencies\": { \"nodemon\": \"2.0.14\", \"express\": \"4.17.1\" } } $ touch app.js edit app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); $ touch Dockerfile Browse a bit docker hub and look for alpine tagged image more lighter (169MB) than the official one (latest) (992MB) FROM node:alpine WORKDIR /app COPY . . RUN npm install CMD [\"nodemon\", \"app.js\"] then.. $ docker build -t myapp . $ docker image ls $ docker run --rm myapp path error to debug, run in interactive mode with sh to override Dockerfile CMD $ docker run --rm -it myapp sh /app $c env /app $c nodemon sh: nodemon: not found $c cd node_modules/.bin/ /app/node_modules/.bin # ls is-ci mime nodemon /app $c ./node_modules/.bin/nodemon app.js Fix the Docker file with adding value to image's path .. ENV PATH=$PATH:/app/node_modules/.bin .. $ docker build -t myapp . $ docker run --rm -it myapp sh /app $c env | grep PATH PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin /app $c nodemon app.js Now it's OK $ docker run --rm myapp Try \"localhost\" in a browser -> does not work and it's normal because default behavior does not allow to communicate with a container.","title":"Node server project"},{"location":"docker/6-docker-datapersistence/","text":"Docker - 06 - Data Persistence Introduction Container = - writable layer (this layer is deleted if the container no longer exists) - image layer(s) (read) Writable layers use UnionFS, slow read write performance, not adapted to host database. To persist data, 3 possibilities: Volumes On Filesystem but managed by Docker, accessible through Docker CLI), mostly advised to use (in /var/lib/docker/volumes/ (not on WSL) but never access it directly. Volumes are stored on but isolated from host machine. Create a volume with Docker CLI command docker volume create Bind mount Manged by Filesystem and accessible from outside of Docker, not recommended. Bind mounts are regular folder and files stored on host machine. TMPFS Temporary File System -> RAM. TMPFS are used to store temporary not persisted data, sensitive information like secret. Bind mount Adapted for: - Sharing configuration files between host and container. - Development environment to share source code and alow live reload. Recommend syntax docker run --mount type=bind,source=<url>,target=<url> image $ mkdir data $ cd data $ touch hello.txt $ cd .. $ docker run --mount type=bind,source=\"$(pwd)\"/data,target=/data -it alpine sh $c ls .. data .. $c cd data $c ls hello.txt Search for Mounts section with inspect CLI command to see mounting details: docker container inspect containerName Development environment Set up of a development environnement for a node server application (c.f. Node server project ). The goal here is to have changes available from host machine (IDE) in container and automatically reloaded by nodemon. !!Warning!! A common mistake is to bind the root folder of a project. E.g. in case of node context, if we do so, the node_modules folder created/populated in container image by \"RUN npm install\" instruction from Dockerfile will be erased. To avoid this unwanted behavior, it's mostly advised to move the source code files modified through IDE on host machine in a dedicated folder (e.g. src). On host machine: $ mkdir node-server $ cd node-server $ mkdir src $ cd src $ touch app.js $ cd .. src/app.js: const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); Dockerfile (in root folder, \"node-server\"): FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] !! Warning !! In above Dockerfile we use -L option for --legacy-watch because in some containerized environnement, application may not restart automatically after file's change. Build image: $ docker build -t myapp . Start a container with new image version: $ docker run --rm -p 80:80 --mount type=bind,source=\"$(pwd)/src\",target=/app/src myapp Now try to edit 'src/app.js' file on host machine to observe nodemon restart in terminal. You may also observe the changes on your browser at 'localhost' address, after refresh. Volumes docker volume - create - inspect - ls - rm - prune old syntax (not advised, c.f. bind) docker run -v <volume-name>:<container-url> image new syntax docker run --mount type=volume,source=<volume-name>,target=<url> image Create New volume $ docker volume create mydata mydata $ docker volume ls DRIVER VOLUME NAME local mydata $ docker volume inspect mydata [ { \"CreatedAt\": \"2021-12-24T06:15:34Z\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/mydata/_data\", \"Name\": \"mydata\", \"Options\": {}, \"Scope\": \"local\" } ] WSL2 volumes are not in /var/lib/docker/volumes/mydata/_data You can find WSL2 volumes under a hidden network share. Open Windows Explorer, and type \\\\wsl$ into the location bar. Hit enter, and it should display your WSL volumes, including the ones for Docker for Windows. WSL2 volumes, in Windows Explorer bar \\\\wsl$\\docker-desktop-data\\version-pack-data\\community\\docker\\volumes New container with bind volume $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c touch hello.txt $c echo 123 > hello.txt ctrl+d $ docker rm containername $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c cat hello.txt 123 Share Backup Restore Share volume between containers $ docker run --mount type=volume,source=mydata,target=/data --name firstcont -it alpine sh $c1 cd data In another terminal $ docker run --mount type=volume,source=mydata,target=/data --name secondcont -it alpine sh $c2 cd data $c2 touch new.txt $c1 ls hello.txt new.txt Another way is volume from container $ docker run --volumes-from firstcont --name thirdcont -it alpine sh Backup volume Compress a volume to a bind folder with tar $ mkdir backup $ docker run --mount type=volume,source=mydata,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -czf /backup/mydata.tar.gz /data Restore volume Extract an archive from a bind folder to a volume $ docker volume create restore $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -xf /backup/mydata.tar.gz -C /data To not have a folder data in a folder data, use tar with option --strip-components 1 $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\",target=/backup -it alpine tar -xf /backup/backup.tar --strip-components 1 -C /data Check volume correctly restored $ docker container run -it --rm --mount source=restore,target=/data alpine sh Volume to persist a database (mongo) For mongo db it consist of mounting a volume with folder /data/db in mongo container $ docker volume create mydb $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer1 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.insertOne({ name: 'jean' }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61caeae2df845609f1835264\") } > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } > exit bye $c exit $ docker container stop mongocontainer1 $ docker container rm mongocontainer1 Container is removed but database is persisted in a volume. $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer2 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } Compass GUI to browse mongo db Should run container with opened port (default 27017). If port is already used on host machine, you may use 27018 for example $ docker run -p 27018:27017 --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer3 mongo Enter in connection field: mongodb://localhost:27018 TMPFS Rarely used, uniquely to keep data in RAM, e.g. secret or status data, works only on Linux system. $ docker run --mount type=tmpfs,target=/data -it alpine sh $c cd data $c touch secret.txt $c ls secret.txt $c exit $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 58f104d6a051 alpine \"sh\" 2 minutes ago Exited (0) 5 seconds ago musing_wilbur With 'TMPFS' if container is in an 'Exited' status, data aren't persisted. Relaunch container to observe that data aren't available anymore. $ docker start -ai musing_wilbur $c cd data $c ls (empty)","title":"Docker - 06 - Data Persistence"},{"location":"docker/6-docker-datapersistence/#docker-06-data-persistence","text":"","title":"Docker - 06 - Data Persistence"},{"location":"docker/6-docker-datapersistence/#introduction","text":"Container = - writable layer (this layer is deleted if the container no longer exists) - image layer(s) (read) Writable layers use UnionFS, slow read write performance, not adapted to host database. To persist data, 3 possibilities:","title":"Introduction"},{"location":"docker/6-docker-datapersistence/#volumes","text":"On Filesystem but managed by Docker, accessible through Docker CLI), mostly advised to use (in /var/lib/docker/volumes/ (not on WSL) but never access it directly. Volumes are stored on but isolated from host machine. Create a volume with Docker CLI command docker volume create","title":"Volumes"},{"location":"docker/6-docker-datapersistence/#bind-mount","text":"Manged by Filesystem and accessible from outside of Docker, not recommended. Bind mounts are regular folder and files stored on host machine.","title":"Bind mount"},{"location":"docker/6-docker-datapersistence/#tmpfs","text":"Temporary File System -> RAM. TMPFS are used to store temporary not persisted data, sensitive information like secret.","title":"TMPFS"},{"location":"docker/6-docker-datapersistence/#bind-mount_1","text":"Adapted for: - Sharing configuration files between host and container. - Development environment to share source code and alow live reload. Recommend syntax docker run --mount type=bind,source=<url>,target=<url> image $ mkdir data $ cd data $ touch hello.txt $ cd .. $ docker run --mount type=bind,source=\"$(pwd)\"/data,target=/data -it alpine sh $c ls .. data .. $c cd data $c ls hello.txt Search for Mounts section with inspect CLI command to see mounting details: docker container inspect containerName","title":"Bind mount"},{"location":"docker/6-docker-datapersistence/#development-environment","text":"Set up of a development environnement for a node server application (c.f. Node server project ). The goal here is to have changes available from host machine (IDE) in container and automatically reloaded by nodemon. !!Warning!! A common mistake is to bind the root folder of a project. E.g. in case of node context, if we do so, the node_modules folder created/populated in container image by \"RUN npm install\" instruction from Dockerfile will be erased. To avoid this unwanted behavior, it's mostly advised to move the source code files modified through IDE on host machine in a dedicated folder (e.g. src). On host machine: $ mkdir node-server $ cd node-server $ mkdir src $ cd src $ touch app.js $ cd .. src/app.js: const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); Dockerfile (in root folder, \"node-server\"): FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] !! Warning !! In above Dockerfile we use -L option for --legacy-watch because in some containerized environnement, application may not restart automatically after file's change. Build image: $ docker build -t myapp . Start a container with new image version: $ docker run --rm -p 80:80 --mount type=bind,source=\"$(pwd)/src\",target=/app/src myapp Now try to edit 'src/app.js' file on host machine to observe nodemon restart in terminal. You may also observe the changes on your browser at 'localhost' address, after refresh.","title":"Development environment"},{"location":"docker/6-docker-datapersistence/#volumes_1","text":"docker volume - create - inspect - ls - rm - prune old syntax (not advised, c.f. bind) docker run -v <volume-name>:<container-url> image new syntax docker run --mount type=volume,source=<volume-name>,target=<url> image","title":"Volumes"},{"location":"docker/6-docker-datapersistence/#create","text":"","title":"Create"},{"location":"docker/6-docker-datapersistence/#new-volume","text":"$ docker volume create mydata mydata $ docker volume ls DRIVER VOLUME NAME local mydata $ docker volume inspect mydata [ { \"CreatedAt\": \"2021-12-24T06:15:34Z\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/mydata/_data\", \"Name\": \"mydata\", \"Options\": {}, \"Scope\": \"local\" } ] WSL2 volumes are not in /var/lib/docker/volumes/mydata/_data You can find WSL2 volumes under a hidden network share. Open Windows Explorer, and type \\\\wsl$ into the location bar. Hit enter, and it should display your WSL volumes, including the ones for Docker for Windows. WSL2 volumes, in Windows Explorer bar \\\\wsl$\\docker-desktop-data\\version-pack-data\\community\\docker\\volumes","title":"New volume"},{"location":"docker/6-docker-datapersistence/#new-container-with-bind-volume","text":"$ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c touch hello.txt $c echo 123 > hello.txt ctrl+d $ docker rm containername $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c cat hello.txt 123","title":"New container with bind volume"},{"location":"docker/6-docker-datapersistence/#share-backup-restore","text":"","title":"Share Backup Restore"},{"location":"docker/6-docker-datapersistence/#share-volume-between-containers","text":"$ docker run --mount type=volume,source=mydata,target=/data --name firstcont -it alpine sh $c1 cd data In another terminal $ docker run --mount type=volume,source=mydata,target=/data --name secondcont -it alpine sh $c2 cd data $c2 touch new.txt $c1 ls hello.txt new.txt Another way is volume from container $ docker run --volumes-from firstcont --name thirdcont -it alpine sh","title":"Share volume between containers"},{"location":"docker/6-docker-datapersistence/#backup-volume","text":"Compress a volume to a bind folder with tar $ mkdir backup $ docker run --mount type=volume,source=mydata,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -czf /backup/mydata.tar.gz /data","title":"Backup volume"},{"location":"docker/6-docker-datapersistence/#restore-volume","text":"Extract an archive from a bind folder to a volume $ docker volume create restore $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -xf /backup/mydata.tar.gz -C /data To not have a folder data in a folder data, use tar with option --strip-components 1 $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\",target=/backup -it alpine tar -xf /backup/backup.tar --strip-components 1 -C /data Check volume correctly restored $ docker container run -it --rm --mount source=restore,target=/data alpine sh","title":"Restore volume"},{"location":"docker/6-docker-datapersistence/#volume-to-persist-a-database-mongo","text":"For mongo db it consist of mounting a volume with folder /data/db in mongo container $ docker volume create mydb $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer1 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.insertOne({ name: 'jean' }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61caeae2df845609f1835264\") } > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } > exit bye $c exit $ docker container stop mongocontainer1 $ docker container rm mongocontainer1 Container is removed but database is persisted in a volume. $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer2 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" }","title":"Volume to persist a database (mongo)"},{"location":"docker/6-docker-datapersistence/#compass-gui-to-browse-mongo-db","text":"Should run container with opened port (default 27017). If port is already used on host machine, you may use 27018 for example $ docker run -p 27018:27017 --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer3 mongo Enter in connection field: mongodb://localhost:27018","title":"Compass GUI to browse mongo db"},{"location":"docker/6-docker-datapersistence/#tmpfs_1","text":"Rarely used, uniquely to keep data in RAM, e.g. secret or status data, works only on Linux system. $ docker run --mount type=tmpfs,target=/data -it alpine sh $c cd data $c touch secret.txt $c ls secret.txt $c exit $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 58f104d6a051 alpine \"sh\" 2 minutes ago Exited (0) 5 seconds ago musing_wilbur With 'TMPFS' if container is in an 'Exited' status, data aren't persisted. Relaunch container to observe that data aren't available anymore. $ docker start -ai musing_wilbur $c cd data $c ls (empty)","title":"TMPFS"},{"location":"docker/7-docker-network/","text":"Docker - 07 - Network Introduction WAN = Internet LAN = Local docker network: - ls - create - rm - inspect - connect - disconnect - prune - --network | --net 3 methods: - Bridge, sub-segment - Host, merge host machine network - Overlay, Docker Swarm (- MACVLAN) (- Others) Bridge (mainly used) Grouped by sub-segment. Docker as bridge manager. By default a container belongs to named \"bridge\" (Docker0) network. Host (Linux only, rarely used) IP addresses for containers defined by router like for host machine. Containers will be straight forward connected to local network. Overlay (Swarm) To establish communication between Docker Daemons. Bridge $ docker network $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 119b5f46e464 none null local $ docker network inspect bridge ... \"Containers\": {}, ... $ ifconfig ... docker0: ... $ docker run --rm -it alpine sh in a second terminal $ docker network inspect bridge ... \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" } } ... $ docker run --rm -it alpine sh in a third terminal $ docker network inspect bridge \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"76ff8f56718ae5244eabe03092f7a0227aa2e42249bf2ab1c8f91a9faf76c715\": { \"Name\": \"admiring_driscoll\", \"EndpointID\": \"684e6a570db46dadd9bdf53bf383ea069fa626fc16b7ab26c11e604415c00b25\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } } in second terminal $c ping google.ch $c ping 172.17.0.2 Be aware that ip address maybe attributed randomly by Docker. To use name on default network, use --name and --link (deprecated) options on run command then you may ping by name instead of ip address (only for default bridge network). in first terminal $ docker run --rm --name alpine1 -it alpine sh in second terminal $ docker run --rm --link alpine1 -it alpine sh $c ping alpine1 Create bridge Create a network, make two containers communicate through it and use container name instead of ip addresses. Create network, default driver = bridge $ docker network create mynet $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 0a85e3670d62 mynet bridge local 119b5f46e464 none null local Use network with a named (important for name resolution over the network) container $ docker run --rm --network mynet --name server1 -d alpine ping google.ch $ docker inspect mynet \"Containers\": { \"249b952ab5db2ac4f3077e1a7fb89582eedaa02c236a92a7e15fc5cee73d3292\": { \"Name\": \"server1\", \"EndpointID\": \"48284c2119158a9ebf9d67b3eee0c74c58ede079ba173b769f5b791f2f507abb\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.18.0.2/16\", \"IPv6Address\": \"\" } } $ docker run --rm -it --network mynet --name server2 alpine sh $c ping server1 PING server1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.079 ms 64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.166 ms From another terminal $ docker exec -it server1 sh $c ping server2 PING server2 (172.18.0.3): 56 data bytes 64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.125 ms 64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.496 ms Remove network $ docker network rm mynet Remove all network at once $ docker network prune Connect a Node.js server with MongoDB Goal: - display a counter in a browser at 'localhost' address. Architecture: - Image - MongoDB - Image - Node.js - Volumes - mydb { count: x } - Container - server - Container - db - Network - mynet - Port 80 open to listen to request (count++) from a browser at 'localhost' address MongoDB Volume and container $ docker volume create mydb $ docker run --name db --mount type=volume,source=mydb,target=/data/db -d mongo Network and connect (and disconnect from default bridge) $ docker network create mynet $ docker network connect mynet db $ docker network disconnect bridge db Create db and collection to handle and initialize the counter $ docker exec -it db sh $c mongo > use test switched to db test > db.count.insertOne({count:0}) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61cc2517094e32ba7f98bb31\") } > db.count.find() { \"_id\" : ObjectId(\"61cc2517094e32ba7f98bb31\"), \"count\" : 0 } > exit bye $c exit Node server Development Development Environnement setup First step, application development with bind mount. We should use the mongo javascript driver in our application to allow connection to the db. In 'node-server' folder. File 'package.json' add mongo dependencies (browse for \"npm mongodb\" -> MongoDB NodeJS Driver, to check version) { \"dependencies\": { \"express\": \"^4.17.1\", \"mongodb\": \"^3.6.2\", \"nodemon\": \"^2.0.6\", \"console-stamp\": \"^3.0.3\" } } \"console-stamp\" is to add timestamp in logs ^version \u201cCompatible with version\u201d, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0. Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] Build image in 'node-server' folder $ docker build -t node-server . Application is in js file 'node-server/src/app.js' const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); To develop application use a bind mount $ docker run --name server --mount type=bind,source=\"$(pwd)\"/src,target=/app/src -p 80:80 --network mynet node-server Browse to 'localhost'. Observe live change availability by editing \"Hello, world!\" response in 'app.js' file and refreshing 'localhost' page in internet browser. Check that port '80' is published for 'server' container $ docker container port server 80/tcp -> 0.0.0.0:80 Development Server configuration Modify 'app.js' file as follow require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); Node server Production Rebuild node server image with released app.js in it (above development has been erased by bind mount) In 'node-server' folder $ docker build -t node-server . If 'node-server' container is still running, remove it and then $ docker run --name server --network mynet -d -p 80:80 node-server Host C.f. Bridge section for initial setup. Reset 'app.js' to const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); Rebuild 'node-server' image $ docker build -t node-server . Relaunch server but on local network, this time, no need to publish port $ docker run --network host node-server Do not work on WSL (Windows Subsystem for Linux), neither MacOs. To not use any network $ docker run --network none node-server","title":"Docker - 07 - Network"},{"location":"docker/7-docker-network/#docker-07-network","text":"","title":"Docker - 07 - Network"},{"location":"docker/7-docker-network/#introduction","text":"WAN = Internet LAN = Local docker network: - ls - create - rm - inspect - connect - disconnect - prune - --network | --net 3 methods: - Bridge, sub-segment - Host, merge host machine network - Overlay, Docker Swarm (- MACVLAN) (- Others)","title":"Introduction"},{"location":"docker/7-docker-network/#bridge-mainly-used","text":"Grouped by sub-segment. Docker as bridge manager. By default a container belongs to named \"bridge\" (Docker0) network.","title":"Bridge (mainly used)"},{"location":"docker/7-docker-network/#host-linux-only-rarely-used","text":"IP addresses for containers defined by router like for host machine. Containers will be straight forward connected to local network.","title":"Host (Linux only, rarely used)"},{"location":"docker/7-docker-network/#overlay-swarm","text":"To establish communication between Docker Daemons.","title":"Overlay (Swarm)"},{"location":"docker/7-docker-network/#bridge","text":"$ docker network $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 119b5f46e464 none null local $ docker network inspect bridge ... \"Containers\": {}, ... $ ifconfig ... docker0: ... $ docker run --rm -it alpine sh in a second terminal $ docker network inspect bridge ... \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" } } ... $ docker run --rm -it alpine sh in a third terminal $ docker network inspect bridge \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"76ff8f56718ae5244eabe03092f7a0227aa2e42249bf2ab1c8f91a9faf76c715\": { \"Name\": \"admiring_driscoll\", \"EndpointID\": \"684e6a570db46dadd9bdf53bf383ea069fa626fc16b7ab26c11e604415c00b25\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } } in second terminal $c ping google.ch $c ping 172.17.0.2 Be aware that ip address maybe attributed randomly by Docker. To use name on default network, use --name and --link (deprecated) options on run command then you may ping by name instead of ip address (only for default bridge network). in first terminal $ docker run --rm --name alpine1 -it alpine sh in second terminal $ docker run --rm --link alpine1 -it alpine sh $c ping alpine1","title":"Bridge"},{"location":"docker/7-docker-network/#create-bridge","text":"Create a network, make two containers communicate through it and use container name instead of ip addresses. Create network, default driver = bridge $ docker network create mynet $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 0a85e3670d62 mynet bridge local 119b5f46e464 none null local Use network with a named (important for name resolution over the network) container $ docker run --rm --network mynet --name server1 -d alpine ping google.ch $ docker inspect mynet \"Containers\": { \"249b952ab5db2ac4f3077e1a7fb89582eedaa02c236a92a7e15fc5cee73d3292\": { \"Name\": \"server1\", \"EndpointID\": \"48284c2119158a9ebf9d67b3eee0c74c58ede079ba173b769f5b791f2f507abb\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.18.0.2/16\", \"IPv6Address\": \"\" } } $ docker run --rm -it --network mynet --name server2 alpine sh $c ping server1 PING server1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.079 ms 64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.166 ms From another terminal $ docker exec -it server1 sh $c ping server2 PING server2 (172.18.0.3): 56 data bytes 64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.125 ms 64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.496 ms Remove network $ docker network rm mynet Remove all network at once $ docker network prune","title":"Create bridge"},{"location":"docker/7-docker-network/#connect-a-nodejs-server-with-mongodb","text":"Goal: - display a counter in a browser at 'localhost' address. Architecture: - Image - MongoDB - Image - Node.js - Volumes - mydb { count: x } - Container - server - Container - db - Network - mynet - Port 80 open to listen to request (count++) from a browser at 'localhost' address","title":"Connect a Node.js server with MongoDB"},{"location":"docker/7-docker-network/#mongodb","text":"Volume and container $ docker volume create mydb $ docker run --name db --mount type=volume,source=mydb,target=/data/db -d mongo Network and connect (and disconnect from default bridge) $ docker network create mynet $ docker network connect mynet db $ docker network disconnect bridge db Create db and collection to handle and initialize the counter $ docker exec -it db sh $c mongo > use test switched to db test > db.count.insertOne({count:0}) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61cc2517094e32ba7f98bb31\") } > db.count.find() { \"_id\" : ObjectId(\"61cc2517094e32ba7f98bb31\"), \"count\" : 0 } > exit bye $c exit","title":"MongoDB"},{"location":"docker/7-docker-network/#node-server-development","text":"","title":"Node server Development"},{"location":"docker/7-docker-network/#development-environnement-setup","text":"First step, application development with bind mount. We should use the mongo javascript driver in our application to allow connection to the db. In 'node-server' folder. File 'package.json' add mongo dependencies (browse for \"npm mongodb\" -> MongoDB NodeJS Driver, to check version) { \"dependencies\": { \"express\": \"^4.17.1\", \"mongodb\": \"^3.6.2\", \"nodemon\": \"^2.0.6\", \"console-stamp\": \"^3.0.3\" } } \"console-stamp\" is to add timestamp in logs ^version \u201cCompatible with version\u201d, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0. Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] Build image in 'node-server' folder $ docker build -t node-server . Application is in js file 'node-server/src/app.js' const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); To develop application use a bind mount $ docker run --name server --mount type=bind,source=\"$(pwd)\"/src,target=/app/src -p 80:80 --network mynet node-server Browse to 'localhost'. Observe live change availability by editing \"Hello, world!\" response in 'app.js' file and refreshing 'localhost' page in internet browser. Check that port '80' is published for 'server' container $ docker container port server 80/tcp -> 0.0.0.0:80","title":"Development Environnement setup"},{"location":"docker/7-docker-network/#development-server-configuration","text":"Modify 'app.js' file as follow require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80);","title":"Development Server configuration"},{"location":"docker/7-docker-network/#node-server-production","text":"Rebuild node server image with released app.js in it (above development has been erased by bind mount) In 'node-server' folder $ docker build -t node-server . If 'node-server' container is still running, remove it and then $ docker run --name server --network mynet -d -p 80:80 node-server","title":"Node server Production"},{"location":"docker/7-docker-network/#host","text":"C.f. Bridge section for initial setup. Reset 'app.js' to const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); Rebuild 'node-server' image $ docker build -t node-server . Relaunch server but on local network, this time, no need to publish port $ docker run --network host node-server Do not work on WSL (Windows Subsystem for Linux), neither MacOs. To not use any network $ docker run --network none node-server","title":"Host"},{"location":"docker/8-compose-use/","text":"Compose - 08 - Use Docker Compose - Use Introduction Application = - Container Web server + - Container Database Setup: - Ports - Volumes - Network - Environment Docker Compose, talking about service. One Application = (is composed of) Many Services (containers that communicate with each others). Docker Compose is a CLI that read 'docker-compose.yml' file. First, install Docker Compose and check installation and version by typing in a terminal: $ docker-compose version First use 'docker-compose ..' command(s) always refer to folder from where command is launched and context of 'docker-compose.yml' file contained in folder. Yaml format configuration file. Yaml syntax is based on an indented key value format. $ touch docker-compose.yml First, mention version to use to ensure retro-compatibility. To determine which version to specify in 'docker-compose.yml' file header, refer to docker engine version that run on your host machine: $ docker version ... Server: Docker Engine - Community Engine: Version: 20.10.11 ... Then refer to documentation Compose file - Reference and guidelines Second, specify service(s). docker-compose.yml: version: '3.8' services: myalpine: image: alpine $ docker-compose up Alternative to go straight in service's container: $ docker-compose run myapline $c In another console: $ docker-compose ps $ docker-compose ps -a $ docker-compose down Particularity of 'docker-compose down' command is to suppress (don't just stop) all container and network that was launched by previous 'docker-compose up' command. Anonymous volumes are never reused by Docker Compose. It launches new ones each time if declared in configuration. Default command is the one defined in image, for 'alpine' it's '/bin/sh'. To overwrite default command, specify it in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine command: ls Or by adding command directly after service name in run command: $ docker-compose run myalpine ls Or with entry point in exec form (instead of shell) in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine entrypoint: [\"ls\"] Or 'command: [\"ls\"]' instead of 'entrypoint: [\"ls\"]' Custom image $ touch Dockerfile Dockerfile: FROM alpine CMD [\"/bin/sh\"] docker-compose.yml version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: . $ docker-compose build Have a look to VS Code Docker plugin to have a synthetic view of all Docker ecosystem components, containers, images, network, etc. Context and Dockerfile Specify a context and Dockerfile: $ mkdir backend $ cp Dockerfile backend/DockerfileBackend docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend Arguments Passing arguments, e.g. create a folder at build, 'Dockerfile' receive args from 'docker-compose.yml'. DockerfileBackend: FROM alpine ARG FOLDER RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test Note the 'arg' indentation with '-' for an array of values (yaml syntax). test: $ docker-compose build $ docker-compose run b $c ls .. test .. Instead of list (- FOLDER=), e.g. for 'args' you may also use an object instead (FOLDER:). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder test: $ docker-compose build $ docker-compose run b $c ls .. myfolder .. Labels docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test labels: - EMAIL=toto@test.com test: $ docker-compose build $ docker image inspect compose_b:latest | grep EMAIL \"EMAIL\": \"toto@test.com\" Ports docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 Volumes Bind $ mkdir data $ touch data/hello.txt DockerfileBackend.yml: FROM alpine ARG FOLDER WORKDIR /app RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data test: $ docker-compose build $ docker-compose run b $c cd data $c ls $c exit Volumes docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: test: $ docker-compose build $ docker-compose run b [+] Running 1/0 \u283f Volume \"compose_datavolume\" Created $c ls data datavolume myfolder $c exit Volume option external to avoid docker-compose to create volume if it does not exist. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: external: true Before testing remove previously created volumes. test: $ docker-compose run b external volume \"\" not found To create anonymous volume, omit source option. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c ls data datavolume datavolumeanonymous myfolder Docker Compose does not always use the same anonymous volume for a service. Therefore, it is advisable to use: $ docker-compose down -v to remove it. -v, --volumes volumes, Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers. Environment Variables from cli $ docker-compose run b $c env HOSTNAME=0b9907714155 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app Add environnement variable from command line, value from host machine: $ docker-compose run -e USER b $c env | grep USER USER=toto By default, by not specifying a value, docker-compose search on host machine environnement variable and if find one that match, pass it (e.g. here with USER that do exist on host machine and has a value). Add environnement variable from command line with specified value: $ docker-compose run -e USER=tintin b $c env | grep USER USER=tintin from compose file Without specifying a value (comes from host machine). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=toto By specifying a value. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER=tintin build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=tintin from .env file If value of environment variable is not specified, docker compose search for corresponding value in host machine, if not found, search then in '.env' file. .env: NODE_ENV=development docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - NODE_ENV build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep NODE_ENV NODE_ENV=development By specifying an environnement file, all variables contained in it will be imported in container. .env: NODE_ENV=development TEST_ENV=test docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: env_file: - .env build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep _ENV TEST_ENV=test NODE_ENV=development You may have many environnement files. You may specify env file in command line, works only with 'up': $ docker-compose --env-file ./.env up You may use both 'env_file' and 'environnement' for same service. You may specify compose project name instead of current folder with, e.g. in .env file: COMPOSE_PROJECT_NAME=myproject Network Default By default docker compose create a network with folder name as a prefix, or with value of 'COMPOSE_PROJECT_NAME' key in project's environnement variable: $ docker-compose up [+] Running 4/4 \u283f Network myproject_default Created .. Note that containers using the network appear in the list ($ docker network inspect myproject_default) only when they are running. Below, we make a test with ping, note that we use shell form (instead of exec (cause: executable file not found in $PATH: unknown)). docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: command: ping a build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 2/2 \u283f Container myproject_a_1 Recreated 0.2s \u283f Container myproject_b_1 Recreated 0.2s Attaching to a_1, b_1 a_1 | PING b (172.29.0.3): 56 data bytes b_1 | PING a (172.29.0.2): 56 data bytes a_1 | 64 bytes from 172.29.0.3: seq=0 ttl=64 time=188.846 ms b_1 | 64 bytes from 172.29.0.2: seq=0 ttl=64 time=0.152 ms Links Links from a container to another one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 3/2 \u283f Network myproject_default Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (172.31.0.2): 56 data bytes b_1 | 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.078 ms b_1 | 64 bytes from 172.31.0.2: seq=1 ttl=64 time=0.190 ms b_1 | 64 bytes from 172.31.0.2: seq=2 ttl=64 time=0.220 ms a_1 | PING b (172.31.0.3): 56 data bytes a_1 | 64 bytes from 172.31.0.3: seq=0 ttl=64 time=0.407 ms b_1 | 64 bytes from 172.31.0.2: seq=3 ttl=64 time=0.305 ms test to ping a and containerA from b: $ docker-compose up -d $ docker-compose exec b sh $c ping a PING a (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.181 ms .. $c ping containerA PING containerA (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.287 ms Name Give network a name to replace the default one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up [+] Running 3/3 \u283f Network mynetwork Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 2.4s Attaching to a_1, b_1 b_1 | PING containerA (192.168.0.2): 56 data bytes b_1 | 64 bytes from 192.168.0.2: seq=0 ttl=64 time=0.081 ms b_1 | 64 bytes from 192.168.0.2: seq=1 ttl=64 time=0.088 ms b_1 | 64 bytes from 192.168.0.2: seq=2 ttl=64 time=0.122 ms a_1 | PING b (192.168.0.3): 56 data bytes a_1 | 64 bytes from 192.168.0.3: seq=0 ttl=64 time=0.339 ms Networks Link container to many networks with adding list in service configuration. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up service \"b\" refers to undefined network othernetwork: invalid compose project Error due to othernetwork missing. We add it to networks section in configuration file and then to services. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b networks: - 'othernetwork' b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork othernetwork: driver: bridge test: $ docker-compose up [+] Running 3/3 \u283f Network myproject_othernetwork Created 0.0s \u283f Container myproject_a_1 Created 0.1s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (192.168.48.2): 56 data bytes b_1 | 64 bytes from 192.168.48.2: seq=0 ttl=64 time=0.122 ms b_1 | 64 bytes from 192.168.48.2: seq=1 ttl=64 time=0.051 ms b_1 | 64 bytes from 192.168.48.2: seq=2 ttl=64 time=0.196 ms a_1 | PING b (192.168.48.3): 56 data bytes a_1 | 64 bytes from 192.168.48.3: seq=0 ttl=64 time=0.252 ms b_1 | 64 bytes from 192.168.48.2: seq=3 ttl=64 time=0.200 ms Sample application Node.js application that increment a counter in a MongoDB. MongoDB We provide volume to handle db data, so, preamble is to \"manually\" create the needed volume: $ docker volume create mydb docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db volumes: mydb: external: true We run db individually to initialize it: $ docker-compose run -d db 39cf.. $ docker container exec -it 39cf sh $c mongo > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1a03ac9a303a408034aca\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1a03ac9a303a408034aca\"), \"count\" : 0 } > exit bye $c exit $ docker container stop 39cf In MongoDB, volume that contain the database may not be mounted anywhere. MongoDB will specifically search for database in '/data/db' folder. No need to open specific port(s) for containers that run on same network. By default all ports are available for containers that run on same network. Node.js Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true \\src\\app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); In a terminal: $ docker-compose up .. server_1 | [02.01.2022 17:10.30.697] [LOG] CONNEXION DB OK! .. In a browser: http://localhost/ Authentication We add authentication through environnement variable to MongoDB. Clear docker environnement and recreate database volume: $ docker container prune $ docker volume prune $ docker volume create mydb Have a look to MongoDB official image on Docker Hub What's interesting us here is to set the two following environnement variables: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD $ touch .env .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true In a terminal, set up db with authenticated user and then create a new user 'tintin' with password '456' and role 'readWrite' on db 'test': $ docker-compose run -d db bad88.. $ docker exec -it bad88 sh $c mongo > use test > db.count.insertOne({ count: 0 }) .. error.. command insert requires authentication.. > use admin > db.auth({ user: 'toto', pwd: '123' }) 1 > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1e40276df2cfd1b903a8f\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1e40276df2cfd1b903a8f\"), \"count\" : 0 } > use admin switched to db admin > db.createUser({ user: 'tintin', pwd: '456', roles: [{ role: 'readWrite', db: 'test' }] }) Successfully added user: { \"user\" : \"tintin\", \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"test\" } ] } > exit bye $c exit $ docker stop bad88 Check that connection to db is OK ('CONNECTION DB OK!' in logs), but we cannot access data (trying to refresh 'localhost' in Internet browser), due to unauthenticated connection: $ docker-compose up .. server_1 | [02.01.2022 19:47.14.606] [LOG] CONNECTION DB OK! .. server_1 | MongoError: command findAndModify requires authentication .. We can authenticate with many different ways. By specifying (hard coded) user password directly in 'app.js' file ('mongodb://tintin:456@db'). We also add a 'console.log(process)' to have environnement variables in logs. app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process) // to have environnement variables in logs MongoClient.connect('mongodb://tintin:456@db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); server_1 logs (to see environnement variables): .. server_1 | env: { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'fbdb8ee68893', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | PWD: '/app' server_1 | } .. By refreshing Internet browser's page at localhost address, we may observer that application is now running fine. Now we stop application by hitting 'Ctrl+c'. Below is described a second manner (more secure, therefor, advised to use) to authenticate to 'db' service from 'sever' service through environnement variables. .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 MONGO_USER_NAME=tintin MONGO_USER_PASSWORD=456 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); ! Be aware of literal evaluation with use of ` character to surround mongodb connection URL instead of ' character like before. To test, type below command in a terminal and refresh Internet browser's page at 'localhost' address: $ docker-compose up .. server_1 | [02.01.2022 20:32.25.069] [LOG] { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'e9e18205ee72', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | MONGO_USER_PASSWORD: '456', server_1 | PWD: '/app', server_1 | MONGO_USER_NAME: 'tintin' server_1 | } .. Depends and Restart Depends Specify containers up priority order (depends_on). E.g. in our application we want that server (Node.js application) start only once database (MongoDB) container is up. docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db volumes: mydb: external: true In a terminal, type below command and you may observe, in logs, that, first, we have database logs, then server logs: $ docker-compose up Attaching to db_1, server_1 db_1 | .. db_1 | .. .. server_1 | .. server_1 | .. .. Restart restart: - \"no\" (between quotes because without it has a yaml signification), default value, never restart automatically. - always restart if container stop from inside or Docker daemon restart, but not with a 'docker-compose stop' command. - on-failure restart container only on quit with error code. - unless-stopped always restart unless stopped manually with a 'docker-compose stop' command. To test it we add a '/err' route to the server to exit the process (process.exit(errorCode)). app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(0); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); For testing purpose (different restart modes) avoid using nodemon. Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"node\", \"src/app.js\"] Terminal: $ docker-compose down $ docker-compose build --no-cache no docker-compose.yml (restart: \"no\"): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: \"no\" volumes: mydb: external: true Test: $ docker-compose down $ docker-compose up Navigate in Internet browser to: http://localhost/err You may observe in logs: .. server_1 exited with code 0 .. In another terminal: $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS 63c2040a78c6 node-server_server \"docker-entrypoint.s\u2026\" About a minute ago Exited (0) About a minute ago 2d8b795bf1ed mongo \"docker-entrypoint.s\u2026\" 7 minutes ago Up About a minute And server isn't available anymore. always docker-compose.yml (restart: always): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: always volumes: mydb: external: true Terminal: $ docker-compose up In an Internet browser, navigate alternatively to following addresses and observe in logs server exit and restart automatically: http://localhost/ http://localhost/err Terminal: .. server_1 | [03.01.2022 16:24.28.780] [LOG] CONNECTION DB OK! .. server_1 exited with code 0 .. server_1 | [03.01.2022 16:27.10.339] [LOG] CONNECTION DB OK! .. In another terminal: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp If we \"manually\" stop 'server' container from another terminal with below command: $ docker-compose stop server And then restart the Docker daemon, we may observe the 'server' that has restart automatically due to his 'always' restart policy and 'db' is down because, for now, he hasn't any restart policy defined in docker-compose yaml configuration file. on-failure docker-compose.yml (restart: on-failure): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: on-failure volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '0' = no error, therefore container does not restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (0) Modify exit code of 'err' route to app.js with '1', app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(1); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '1' = error, therefore container restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp unless-stopped Will always restart except if stopped \"manually\" with 'docker-compose stop server', then restart Docker daemon, then stopped 'server' container will not restart. docker-compose.yml (restart: unless-stopped): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: unless-stopped volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Restart Docker daemon, then: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db exited (255) 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) We may observe that 'server' container hasn't restarted automatically due to fact it has been \"manually\" stopped before Docker daemon restart. Note that you can change the restart configuration of an already running container by doing: $ docker container update --restart unless-stopped ID Other commands First: $ docker-compose up -d logs View output from containers: $ docker-compose logs .. db_1 | .. server_1 | .. .. To follow -f option, to show timestamps -t options: $ docker-compose logs -f -t 'Ctrl+c' does not stop containers, stop only logs display: $ Ctrl+c $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp top Display the running processes: $ docker-compose top misc Stop a container: $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Remove a stopped container: $ docker-compose rm server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp Remove a running container (+ -f to avoid confirm's need): $ docker-compose rm -s server Remove anonym volumes belonging to container: $ docker-compose rm -v db After removing a container, to get it back (+ -d): $ docker-compose up Port mapping information and entering ip allowed (0.0.0.0 for all entering ip address allowed): $ docker-compose port server 80 0.0.0.0:80 Means, outside port 80 is mapped to inside port 80 and all ip addresses allowed. config Let see environnement variables replaced with found values and configuration that will then be used to build the stack: $ docker-compose config services: db: environment: MONGO_INITDB_ROOT_PASSWORD: \"123\" MONGO_INITDB_ROOT_USERNAME: toto image: mongo restart: unless-stopped volumes: - type: volume source: mydb target: /data/db server: build: context: . depends_on: db: condition: service_started environment: MONGO_USER_NAME: tintin MONGO_USER_PASSWORD: \"456\" ports: - mode: ingress target: 80 published: 80 protocol: tcp restart: unless-stopped volumes: - type: bind source: /mnt/c/git/doc/test/docker/node-server/src target: /app/src volumes: mydb: name: mydb external: true pull push pull: get latest images of containers that compose the stack. push: if image has been modified with custom Dockerfile, let us push it to Docker Hub.","title":"Compose - 08 - Use"},{"location":"docker/8-compose-use/#compose-08-use","text":"Docker Compose - Use","title":"Compose - 08 - Use"},{"location":"docker/8-compose-use/#introduction","text":"Application = - Container Web server + - Container Database Setup: - Ports - Volumes - Network - Environment Docker Compose, talking about service. One Application = (is composed of) Many Services (containers that communicate with each others). Docker Compose is a CLI that read 'docker-compose.yml' file. First, install Docker Compose and check installation and version by typing in a terminal: $ docker-compose version","title":"Introduction"},{"location":"docker/8-compose-use/#first-use","text":"'docker-compose ..' command(s) always refer to folder from where command is launched and context of 'docker-compose.yml' file contained in folder. Yaml format configuration file. Yaml syntax is based on an indented key value format. $ touch docker-compose.yml First, mention version to use to ensure retro-compatibility. To determine which version to specify in 'docker-compose.yml' file header, refer to docker engine version that run on your host machine: $ docker version ... Server: Docker Engine - Community Engine: Version: 20.10.11 ... Then refer to documentation Compose file - Reference and guidelines Second, specify service(s). docker-compose.yml: version: '3.8' services: myalpine: image: alpine $ docker-compose up Alternative to go straight in service's container: $ docker-compose run myapline $c In another console: $ docker-compose ps $ docker-compose ps -a $ docker-compose down Particularity of 'docker-compose down' command is to suppress (don't just stop) all container and network that was launched by previous 'docker-compose up' command. Anonymous volumes are never reused by Docker Compose. It launches new ones each time if declared in configuration. Default command is the one defined in image, for 'alpine' it's '/bin/sh'. To overwrite default command, specify it in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine command: ls Or by adding command directly after service name in run command: $ docker-compose run myalpine ls Or with entry point in exec form (instead of shell) in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine entrypoint: [\"ls\"] Or 'command: [\"ls\"]' instead of 'entrypoint: [\"ls\"]'","title":"First use"},{"location":"docker/8-compose-use/#custom-image","text":"$ touch Dockerfile Dockerfile: FROM alpine CMD [\"/bin/sh\"] docker-compose.yml version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: . $ docker-compose build Have a look to VS Code Docker plugin to have a synthetic view of all Docker ecosystem components, containers, images, network, etc.","title":"Custom image"},{"location":"docker/8-compose-use/#context-and-dockerfile","text":"Specify a context and Dockerfile: $ mkdir backend $ cp Dockerfile backend/DockerfileBackend docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend","title":"Context and Dockerfile"},{"location":"docker/8-compose-use/#arguments","text":"Passing arguments, e.g. create a folder at build, 'Dockerfile' receive args from 'docker-compose.yml'. DockerfileBackend: FROM alpine ARG FOLDER RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test Note the 'arg' indentation with '-' for an array of values (yaml syntax). test: $ docker-compose build $ docker-compose run b $c ls .. test .. Instead of list (- FOLDER=), e.g. for 'args' you may also use an object instead (FOLDER:). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder test: $ docker-compose build $ docker-compose run b $c ls .. myfolder ..","title":"Arguments"},{"location":"docker/8-compose-use/#labels","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test labels: - EMAIL=toto@test.com test: $ docker-compose build $ docker image inspect compose_b:latest | grep EMAIL \"EMAIL\": \"toto@test.com\"","title":"Labels"},{"location":"docker/8-compose-use/#ports","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80","title":"Ports"},{"location":"docker/8-compose-use/#volumes","text":"","title":"Volumes"},{"location":"docker/8-compose-use/#bind","text":"$ mkdir data $ touch data/hello.txt DockerfileBackend.yml: FROM alpine ARG FOLDER WORKDIR /app RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data test: $ docker-compose build $ docker-compose run b $c cd data $c ls $c exit","title":"Bind"},{"location":"docker/8-compose-use/#volumes_1","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: test: $ docker-compose build $ docker-compose run b [+] Running 1/0 \u283f Volume \"compose_datavolume\" Created $c ls data datavolume myfolder $c exit Volume option external to avoid docker-compose to create volume if it does not exist. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: external: true Before testing remove previously created volumes. test: $ docker-compose run b external volume \"\" not found To create anonymous volume, omit source option. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c ls data datavolume datavolumeanonymous myfolder Docker Compose does not always use the same anonymous volume for a service. Therefore, it is advisable to use: $ docker-compose down -v to remove it. -v, --volumes volumes, Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers.","title":"Volumes"},{"location":"docker/8-compose-use/#environment-variables","text":"","title":"Environment Variables"},{"location":"docker/8-compose-use/#from-cli","text":"$ docker-compose run b $c env HOSTNAME=0b9907714155 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app Add environnement variable from command line, value from host machine: $ docker-compose run -e USER b $c env | grep USER USER=toto By default, by not specifying a value, docker-compose search on host machine environnement variable and if find one that match, pass it (e.g. here with USER that do exist on host machine and has a value). Add environnement variable from command line with specified value: $ docker-compose run -e USER=tintin b $c env | grep USER USER=tintin","title":"from cli"},{"location":"docker/8-compose-use/#from-compose-file","text":"Without specifying a value (comes from host machine). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=toto By specifying a value. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER=tintin build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=tintin","title":"from compose file"},{"location":"docker/8-compose-use/#from-env-file","text":"If value of environment variable is not specified, docker compose search for corresponding value in host machine, if not found, search then in '.env' file. .env: NODE_ENV=development docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - NODE_ENV build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep NODE_ENV NODE_ENV=development By specifying an environnement file, all variables contained in it will be imported in container. .env: NODE_ENV=development TEST_ENV=test docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: env_file: - .env build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep _ENV TEST_ENV=test NODE_ENV=development You may have many environnement files. You may specify env file in command line, works only with 'up': $ docker-compose --env-file ./.env up You may use both 'env_file' and 'environnement' for same service. You may specify compose project name instead of current folder with, e.g. in .env file: COMPOSE_PROJECT_NAME=myproject","title":"from .env file"},{"location":"docker/8-compose-use/#network","text":"","title":"Network"},{"location":"docker/8-compose-use/#default","text":"By default docker compose create a network with folder name as a prefix, or with value of 'COMPOSE_PROJECT_NAME' key in project's environnement variable: $ docker-compose up [+] Running 4/4 \u283f Network myproject_default Created .. Note that containers using the network appear in the list ($ docker network inspect myproject_default) only when they are running. Below, we make a test with ping, note that we use shell form (instead of exec (cause: executable file not found in $PATH: unknown)). docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: command: ping a build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 2/2 \u283f Container myproject_a_1 Recreated 0.2s \u283f Container myproject_b_1 Recreated 0.2s Attaching to a_1, b_1 a_1 | PING b (172.29.0.3): 56 data bytes b_1 | PING a (172.29.0.2): 56 data bytes a_1 | 64 bytes from 172.29.0.3: seq=0 ttl=64 time=188.846 ms b_1 | 64 bytes from 172.29.0.2: seq=0 ttl=64 time=0.152 ms","title":"Default"},{"location":"docker/8-compose-use/#links","text":"Links from a container to another one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 3/2 \u283f Network myproject_default Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (172.31.0.2): 56 data bytes b_1 | 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.078 ms b_1 | 64 bytes from 172.31.0.2: seq=1 ttl=64 time=0.190 ms b_1 | 64 bytes from 172.31.0.2: seq=2 ttl=64 time=0.220 ms a_1 | PING b (172.31.0.3): 56 data bytes a_1 | 64 bytes from 172.31.0.3: seq=0 ttl=64 time=0.407 ms b_1 | 64 bytes from 172.31.0.2: seq=3 ttl=64 time=0.305 ms test to ping a and containerA from b: $ docker-compose up -d $ docker-compose exec b sh $c ping a PING a (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.181 ms .. $c ping containerA PING containerA (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.287 ms","title":"Links"},{"location":"docker/8-compose-use/#name","text":"Give network a name to replace the default one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up [+] Running 3/3 \u283f Network mynetwork Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 2.4s Attaching to a_1, b_1 b_1 | PING containerA (192.168.0.2): 56 data bytes b_1 | 64 bytes from 192.168.0.2: seq=0 ttl=64 time=0.081 ms b_1 | 64 bytes from 192.168.0.2: seq=1 ttl=64 time=0.088 ms b_1 | 64 bytes from 192.168.0.2: seq=2 ttl=64 time=0.122 ms a_1 | PING b (192.168.0.3): 56 data bytes a_1 | 64 bytes from 192.168.0.3: seq=0 ttl=64 time=0.339 ms","title":"Name"},{"location":"docker/8-compose-use/#networks","text":"Link container to many networks with adding list in service configuration. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up service \"b\" refers to undefined network othernetwork: invalid compose project Error due to othernetwork missing. We add it to networks section in configuration file and then to services. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b networks: - 'othernetwork' b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork othernetwork: driver: bridge test: $ docker-compose up [+] Running 3/3 \u283f Network myproject_othernetwork Created 0.0s \u283f Container myproject_a_1 Created 0.1s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (192.168.48.2): 56 data bytes b_1 | 64 bytes from 192.168.48.2: seq=0 ttl=64 time=0.122 ms b_1 | 64 bytes from 192.168.48.2: seq=1 ttl=64 time=0.051 ms b_1 | 64 bytes from 192.168.48.2: seq=2 ttl=64 time=0.196 ms a_1 | PING b (192.168.48.3): 56 data bytes a_1 | 64 bytes from 192.168.48.3: seq=0 ttl=64 time=0.252 ms b_1 | 64 bytes from 192.168.48.2: seq=3 ttl=64 time=0.200 ms","title":"Networks"},{"location":"docker/8-compose-use/#sample-application","text":"Node.js application that increment a counter in a MongoDB.","title":"Sample application"},{"location":"docker/8-compose-use/#mongodb","text":"We provide volume to handle db data, so, preamble is to \"manually\" create the needed volume: $ docker volume create mydb docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db volumes: mydb: external: true We run db individually to initialize it: $ docker-compose run -d db 39cf.. $ docker container exec -it 39cf sh $c mongo > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1a03ac9a303a408034aca\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1a03ac9a303a408034aca\"), \"count\" : 0 } > exit bye $c exit $ docker container stop 39cf In MongoDB, volume that contain the database may not be mounted anywhere. MongoDB will specifically search for database in '/data/db' folder. No need to open specific port(s) for containers that run on same network. By default all ports are available for containers that run on same network.","title":"MongoDB"},{"location":"docker/8-compose-use/#nodejs","text":"Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true \\src\\app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); In a terminal: $ docker-compose up .. server_1 | [02.01.2022 17:10.30.697] [LOG] CONNEXION DB OK! .. In a browser: http://localhost/","title":"Node.js"},{"location":"docker/8-compose-use/#authentication","text":"We add authentication through environnement variable to MongoDB. Clear docker environnement and recreate database volume: $ docker container prune $ docker volume prune $ docker volume create mydb Have a look to MongoDB official image on Docker Hub What's interesting us here is to set the two following environnement variables: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD $ touch .env .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true In a terminal, set up db with authenticated user and then create a new user 'tintin' with password '456' and role 'readWrite' on db 'test': $ docker-compose run -d db bad88.. $ docker exec -it bad88 sh $c mongo > use test > db.count.insertOne({ count: 0 }) .. error.. command insert requires authentication.. > use admin > db.auth({ user: 'toto', pwd: '123' }) 1 > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1e40276df2cfd1b903a8f\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1e40276df2cfd1b903a8f\"), \"count\" : 0 } > use admin switched to db admin > db.createUser({ user: 'tintin', pwd: '456', roles: [{ role: 'readWrite', db: 'test' }] }) Successfully added user: { \"user\" : \"tintin\", \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"test\" } ] } > exit bye $c exit $ docker stop bad88 Check that connection to db is OK ('CONNECTION DB OK!' in logs), but we cannot access data (trying to refresh 'localhost' in Internet browser), due to unauthenticated connection: $ docker-compose up .. server_1 | [02.01.2022 19:47.14.606] [LOG] CONNECTION DB OK! .. server_1 | MongoError: command findAndModify requires authentication .. We can authenticate with many different ways. By specifying (hard coded) user password directly in 'app.js' file ('mongodb://tintin:456@db'). We also add a 'console.log(process)' to have environnement variables in logs. app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process) // to have environnement variables in logs MongoClient.connect('mongodb://tintin:456@db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); server_1 logs (to see environnement variables): .. server_1 | env: { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'fbdb8ee68893', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | PWD: '/app' server_1 | } .. By refreshing Internet browser's page at localhost address, we may observer that application is now running fine. Now we stop application by hitting 'Ctrl+c'. Below is described a second manner (more secure, therefor, advised to use) to authenticate to 'db' service from 'sever' service through environnement variables. .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 MONGO_USER_NAME=tintin MONGO_USER_PASSWORD=456 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); ! Be aware of literal evaluation with use of ` character to surround mongodb connection URL instead of ' character like before. To test, type below command in a terminal and refresh Internet browser's page at 'localhost' address: $ docker-compose up .. server_1 | [02.01.2022 20:32.25.069] [LOG] { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'e9e18205ee72', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | MONGO_USER_PASSWORD: '456', server_1 | PWD: '/app', server_1 | MONGO_USER_NAME: 'tintin' server_1 | } ..","title":"Authentication"},{"location":"docker/8-compose-use/#depends-and-restart","text":"","title":"Depends and Restart"},{"location":"docker/8-compose-use/#depends","text":"Specify containers up priority order (depends_on). E.g. in our application we want that server (Node.js application) start only once database (MongoDB) container is up. docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db volumes: mydb: external: true In a terminal, type below command and you may observe, in logs, that, first, we have database logs, then server logs: $ docker-compose up Attaching to db_1, server_1 db_1 | .. db_1 | .. .. server_1 | .. server_1 | .. ..","title":"Depends"},{"location":"docker/8-compose-use/#restart","text":"restart: - \"no\" (between quotes because without it has a yaml signification), default value, never restart automatically. - always restart if container stop from inside or Docker daemon restart, but not with a 'docker-compose stop' command. - on-failure restart container only on quit with error code. - unless-stopped always restart unless stopped manually with a 'docker-compose stop' command. To test it we add a '/err' route to the server to exit the process (process.exit(errorCode)). app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(0); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); For testing purpose (different restart modes) avoid using nodemon. Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"node\", \"src/app.js\"] Terminal: $ docker-compose down $ docker-compose build --no-cache","title":"Restart"},{"location":"docker/8-compose-use/#no","text":"docker-compose.yml (restart: \"no\"): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: \"no\" volumes: mydb: external: true Test: $ docker-compose down $ docker-compose up Navigate in Internet browser to: http://localhost/err You may observe in logs: .. server_1 exited with code 0 .. In another terminal: $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS 63c2040a78c6 node-server_server \"docker-entrypoint.s\u2026\" About a minute ago Exited (0) About a minute ago 2d8b795bf1ed mongo \"docker-entrypoint.s\u2026\" 7 minutes ago Up About a minute And server isn't available anymore.","title":"no"},{"location":"docker/8-compose-use/#always","text":"docker-compose.yml (restart: always): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: always volumes: mydb: external: true Terminal: $ docker-compose up In an Internet browser, navigate alternatively to following addresses and observe in logs server exit and restart automatically: http://localhost/ http://localhost/err Terminal: .. server_1 | [03.01.2022 16:24.28.780] [LOG] CONNECTION DB OK! .. server_1 exited with code 0 .. server_1 | [03.01.2022 16:27.10.339] [LOG] CONNECTION DB OK! .. In another terminal: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp If we \"manually\" stop 'server' container from another terminal with below command: $ docker-compose stop server And then restart the Docker daemon, we may observe the 'server' that has restart automatically due to his 'always' restart policy and 'db' is down because, for now, he hasn't any restart policy defined in docker-compose yaml configuration file.","title":"always"},{"location":"docker/8-compose-use/#on-failure","text":"docker-compose.yml (restart: on-failure): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: on-failure volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '0' = no error, therefore container does not restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (0) Modify exit code of 'err' route to app.js with '1', app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(1); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '1' = error, therefore container restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp","title":"on-failure"},{"location":"docker/8-compose-use/#unless-stopped","text":"Will always restart except if stopped \"manually\" with 'docker-compose stop server', then restart Docker daemon, then stopped 'server' container will not restart. docker-compose.yml (restart: unless-stopped): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: unless-stopped volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Restart Docker daemon, then: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db exited (255) 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) We may observe that 'server' container hasn't restarted automatically due to fact it has been \"manually\" stopped before Docker daemon restart. Note that you can change the restart configuration of an already running container by doing: $ docker container update --restart unless-stopped ID","title":"unless-stopped"},{"location":"docker/8-compose-use/#other-commands","text":"First: $ docker-compose up -d","title":"Other commands"},{"location":"docker/8-compose-use/#logs","text":"View output from containers: $ docker-compose logs .. db_1 | .. server_1 | .. .. To follow -f option, to show timestamps -t options: $ docker-compose logs -f -t 'Ctrl+c' does not stop containers, stop only logs display: $ Ctrl+c $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp","title":"logs"},{"location":"docker/8-compose-use/#top","text":"Display the running processes: $ docker-compose top","title":"top"},{"location":"docker/8-compose-use/#misc","text":"Stop a container: $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Remove a stopped container: $ docker-compose rm server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp Remove a running container (+ -f to avoid confirm's need): $ docker-compose rm -s server Remove anonym volumes belonging to container: $ docker-compose rm -v db After removing a container, to get it back (+ -d): $ docker-compose up Port mapping information and entering ip allowed (0.0.0.0 for all entering ip address allowed): $ docker-compose port server 80 0.0.0.0:80 Means, outside port 80 is mapped to inside port 80 and all ip addresses allowed.","title":"misc"},{"location":"docker/8-compose-use/#config","text":"Let see environnement variables replaced with found values and configuration that will then be used to build the stack: $ docker-compose config services: db: environment: MONGO_INITDB_ROOT_PASSWORD: \"123\" MONGO_INITDB_ROOT_USERNAME: toto image: mongo restart: unless-stopped volumes: - type: volume source: mydb target: /data/db server: build: context: . depends_on: db: condition: service_started environment: MONGO_USER_NAME: tintin MONGO_USER_PASSWORD: \"456\" ports: - mode: ingress target: 80 published: 80 protocol: tcp restart: unless-stopped volumes: - type: bind source: /mnt/c/git/doc/test/docker/node-server/src target: /app/src volumes: mydb: name: mydb external: true","title":"config"},{"location":"docker/8-compose-use/#pull-push","text":"pull: get latest images of containers that compose the stack. push: if image has been modified with custom Dockerfile, let us push it to Docker Hub.","title":"pull push"},{"location":"docker/9-compose-dockerfile/","text":"Compose - 09 - Dockerfile Docker Compose - Dockerfile !WSL2, advised to not use a mounted volume like '/mnt/c/' for handling a project to avoid slowness and live reload issues. Instead, prefer usage of a \"native\" WSL2 folder like for e.g. '/home/user/react-nginx' Dockerfile and Docker Compose to set up a client application composed of: React NGINX Setup of client application project Node 'create-React-app' is a script to install with 'npm' will pre-configure a 'webpack' environnement and give use access to a development server and a test server and a build command for production. Role of 'NGINX' (http server) is to treat all http(s) request and return response from 'React' application to requester. In this chapter we will see two new features: Dockerfile multi staging, defined with many 'from'. Stdin_open and TTY, two new options of Docker Compose. Prerequisite, install on host machine: 'nvm' - Node Version Manager 'Node.js' Set/check installation with: // Setup project root folder mkdir react-nginx cd react-nginx // To install 'nvm' curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash // Check nvm // Get last version nvm ls-remote | tail . . v17.0.1 v17.1.0 v17.2.0 v17.3.0 // Install last version nvm install 17.3.0 node -v v17.3.0 node Welcome to Node.js v17.3.0. Type \".help\" for more information. > (To exit, press Ctrl+C again or Ctrl+D or type .exit) > React Instal 'React' with 'npx' (like npm but executed once with last script release): npx create-react-app client cd client ls README.md node_modules package-lock.json package.json public src npm start . . Compiled successfully! You can now view client in the browser. Local: http://localhost:3000 Browse to: - http://localhost:3000 Test (launch tests contained in react-nginx/client/src/App.test.js): npm run test !! Fail on WSL2 :( Build for production (add a build folder to the project, this is the folder to return via NGINX for client): npm run build All of this just to initialize the project locally on host machine. Dockerized We may now delete the 'node_modules' folder ('node_modules' folder will then be only in container initialized with dependencies through 'npm install' command in 'Dockerfile'): rm -rf node_modules/ Add a 'Dockerfile' in client project folder '/home/user/react-nginx/client': touch Dockerfile Dockerfile: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install COPY . . CMD [\"npm\", \"start\"] Build docker image: docker build -t myreact . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE myreact latest c4c1b5bb9d21 45 seconds ago 483MB docker run --rm --name react -p 3000:3000 myreact Browse to: - http://localhost:3000 Live reload It's important to launch from a terminal a based VS Code instance from root client application folder to get live reload effect that works: cd .../react-nginx/client code . For development purpose, to automatically propagate local changes to container. Bind mount project folder: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app myreact !! => FAIL!! Why? Because when bind mount it crush all what was contained in container '/app' folder with local content and in local there isn't anymore 'node_modules' folder. To avoid this unwanted behavior and keep 'node_modules' in container folder not erased by bind mount (also needed for live reload feature), we bind an anonymous volume targeted on remote container '/app/node_modules' folder. Also, to avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder we modify 'Dockerfile' as follow: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] Bind mount project folder + anonymous volume with '/app/node_modules' as target: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app --mount type=volume,target=/app/node_modules myreact It's advised to run with '--rm' option when using anonymous volume to suppress it automatically on stop in addition to container suppression. Test live reload by changing text '.. save to reload.' with e.g. 'Hello, world!\" in 'src/App.js' and then observe live effect at http://localhost:3000 in an Internet browser. Set up Docker Compose docker-compose.yml version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules Reset Docker: docker system prune -a docker volume prune Start service: docker-compose up You may observe live reload working by changing 'App.js' content and 'localhost:3000' changing accordingly. Test during developpement Note: webpack is an open-source JavaScript module bundler (wikipedia). TDD (Test Driven Development). In a devellopement process it's mostly advised to continuously test in order to check that we don't brake anything. To achieve this, we lauch two terminals in prallel, one with webpack for running application and this other one for automatic testing purpose. It's done with same container image and duplicate services in Docker Compose configuration file, only thing that will change for second duplicated service is that we override command from Dockerfile in Docker Compose configuration file to launch test server and remove also port mapping which is useless for tests. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules docker-compose up --build In logs we may observe: . . test_1 | Tests: 1 passed, 1 total . . If we duplicate one exsisting test in '.../src/App.test.js' file, we may observe live change in logs: . . test_1 | Tests: 2 passed, 2 total . . To interact with test server we need a second terminal. If we want to send command in test container when attaching to it we need to add two options to the test service in Docker Compose configuration file, 'stdin_open' and 'tty', both set to 'true'. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules stdin_open: true tty: true In first terminal: docker-compose down -v docker-compose up --build In second terminal: docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca16b44236ad client_test \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute client_test_1 4633b0999f9c client_client \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute 0.0.0.0:3000->3000/tcp client_client_1 docker attach client_test_1 . . Watch Usage \u203a Press f to run only failed tests. \u203a Press o to only run tests related to changed files. \u203a Press q to quit watch mode. \u203a Press p to filter by a filename regex pattern. \u203a Press t to filter by a test name regex pattern. \u203a Press Enter to trigger a test run. We may now send commands to test server in second terminal. Then, shutdown gracefully: docker-compose down -v Production environnement Introduction NGINX return the build. NGINX intercept http request and return by default an html file. Browse docker hub for nginx on official image page to host some simple static content . Simple test: docker run --rm -p 80:80 nginx Browse to localhost In a second terminal: docker exec -it exciting_elion sh cd usr/share/nginx/html ls 50x.html index.html cat index.html <!DOCTYPE html> <html> <head> <title>Welcome to nginx!</title> . . It's in this folder we gonna copy our application '/usr/share/nginx/html'. For more complex configuration, have a look in '/etc/nginx/conf.d' folder. Multi stage Dockerfile Reuse a preceding builded image in next build. Goal to reach here is to put React's build folder into NGINX image. ../client/Dockerfile.prod FROM node:alpine as buildstage WORKDIR /app COPY package.json . RUN npm install COPY . . RUN npm run build FROM nginx COPY --from=buildstage /app/build /usr/share/nginx/html EXPOSE 80 After second FROM above, --from=buildstage refer to first stage of image build (npm run build, output is a 'build' folder that containe production application). Build Docker image: docker build -t nginxreact -f Dockerfile.prod . . . => [stage-1 2/2] COPY --from=buildstage /app/build /usr/share/nginx/html . . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginxreact latest ee3388384541 4 minutes ago 141MB . . <none> <none> 1c9dc1e2c948 6 hours ago 483MB . . \"\\<none>\" image are produced by intermediate build stage(s). Launch a container with just built image: docker run --rm -p 80:80 nginxreact Browse to localhost to observe your production application running. Docker Compose A new Docker Compose configuration file dedicated to prodction: touch docker-compose.prod.yml docker-compose.prod.yml version: \"3.8\" services: mynginx: build: context: . dockerfile: Dockerfile.prod ports: - 80:80 Reset Docker content: docker system prune -a docker volume prune Start a fresh new production application: docker-compose -f docker-compose.prod.yml up Browse to localhost to observe your production application running.","title":"Compose - 09 - Dockerfile"},{"location":"docker/9-compose-dockerfile/#compose-09-dockerfile","text":"Docker Compose - Dockerfile !WSL2, advised to not use a mounted volume like '/mnt/c/' for handling a project to avoid slowness and live reload issues. Instead, prefer usage of a \"native\" WSL2 folder like for e.g. '/home/user/react-nginx' Dockerfile and Docker Compose to set up a client application composed of: React NGINX","title":"Compose - 09 - Dockerfile"},{"location":"docker/9-compose-dockerfile/#setup-of-client-application-project","text":"","title":"Setup of client application project"},{"location":"docker/9-compose-dockerfile/#node","text":"'create-React-app' is a script to install with 'npm' will pre-configure a 'webpack' environnement and give use access to a development server and a test server and a build command for production. Role of 'NGINX' (http server) is to treat all http(s) request and return response from 'React' application to requester. In this chapter we will see two new features: Dockerfile multi staging, defined with many 'from'. Stdin_open and TTY, two new options of Docker Compose. Prerequisite, install on host machine: 'nvm' - Node Version Manager 'Node.js' Set/check installation with: // Setup project root folder mkdir react-nginx cd react-nginx // To install 'nvm' curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash // Check nvm // Get last version nvm ls-remote | tail . . v17.0.1 v17.1.0 v17.2.0 v17.3.0 // Install last version nvm install 17.3.0 node -v v17.3.0 node Welcome to Node.js v17.3.0. Type \".help\" for more information. > (To exit, press Ctrl+C again or Ctrl+D or type .exit) >","title":"Node"},{"location":"docker/9-compose-dockerfile/#react","text":"Instal 'React' with 'npx' (like npm but executed once with last script release): npx create-react-app client cd client ls README.md node_modules package-lock.json package.json public src npm start . . Compiled successfully! You can now view client in the browser. Local: http://localhost:3000 Browse to: - http://localhost:3000 Test (launch tests contained in react-nginx/client/src/App.test.js): npm run test !! Fail on WSL2 :( Build for production (add a build folder to the project, this is the folder to return via NGINX for client): npm run build All of this just to initialize the project locally on host machine.","title":"React"},{"location":"docker/9-compose-dockerfile/#dockerized","text":"We may now delete the 'node_modules' folder ('node_modules' folder will then be only in container initialized with dependencies through 'npm install' command in 'Dockerfile'): rm -rf node_modules/ Add a 'Dockerfile' in client project folder '/home/user/react-nginx/client': touch Dockerfile Dockerfile: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install COPY . . CMD [\"npm\", \"start\"] Build docker image: docker build -t myreact . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE myreact latest c4c1b5bb9d21 45 seconds ago 483MB docker run --rm --name react -p 3000:3000 myreact Browse to: - http://localhost:3000","title":"Dockerized"},{"location":"docker/9-compose-dockerfile/#live-reload","text":"It's important to launch from a terminal a based VS Code instance from root client application folder to get live reload effect that works: cd .../react-nginx/client code . For development purpose, to automatically propagate local changes to container. Bind mount project folder: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app myreact !! => FAIL!! Why? Because when bind mount it crush all what was contained in container '/app' folder with local content and in local there isn't anymore 'node_modules' folder. To avoid this unwanted behavior and keep 'node_modules' in container folder not erased by bind mount (also needed for live reload feature), we bind an anonymous volume targeted on remote container '/app/node_modules' folder. Also, to avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder we modify 'Dockerfile' as follow: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] Bind mount project folder + anonymous volume with '/app/node_modules' as target: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app --mount type=volume,target=/app/node_modules myreact It's advised to run with '--rm' option when using anonymous volume to suppress it automatically on stop in addition to container suppression. Test live reload by changing text '.. save to reload.' with e.g. 'Hello, world!\" in 'src/App.js' and then observe live effect at http://localhost:3000 in an Internet browser.","title":"Live reload"},{"location":"docker/9-compose-dockerfile/#set-up-docker-compose","text":"docker-compose.yml version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules Reset Docker: docker system prune -a docker volume prune Start service: docker-compose up You may observe live reload working by changing 'App.js' content and 'localhost:3000' changing accordingly.","title":"Set up Docker Compose"},{"location":"docker/9-compose-dockerfile/#test-during-developpement","text":"Note: webpack is an open-source JavaScript module bundler (wikipedia). TDD (Test Driven Development). In a devellopement process it's mostly advised to continuously test in order to check that we don't brake anything. To achieve this, we lauch two terminals in prallel, one with webpack for running application and this other one for automatic testing purpose. It's done with same container image and duplicate services in Docker Compose configuration file, only thing that will change for second duplicated service is that we override command from Dockerfile in Docker Compose configuration file to launch test server and remove also port mapping which is useless for tests. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules docker-compose up --build In logs we may observe: . . test_1 | Tests: 1 passed, 1 total . . If we duplicate one exsisting test in '.../src/App.test.js' file, we may observe live change in logs: . . test_1 | Tests: 2 passed, 2 total . . To interact with test server we need a second terminal. If we want to send command in test container when attaching to it we need to add two options to the test service in Docker Compose configuration file, 'stdin_open' and 'tty', both set to 'true'. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules stdin_open: true tty: true In first terminal: docker-compose down -v docker-compose up --build In second terminal: docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca16b44236ad client_test \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute client_test_1 4633b0999f9c client_client \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute 0.0.0.0:3000->3000/tcp client_client_1 docker attach client_test_1 . . Watch Usage \u203a Press f to run only failed tests. \u203a Press o to only run tests related to changed files. \u203a Press q to quit watch mode. \u203a Press p to filter by a filename regex pattern. \u203a Press t to filter by a test name regex pattern. \u203a Press Enter to trigger a test run. We may now send commands to test server in second terminal. Then, shutdown gracefully: docker-compose down -v","title":"Test during developpement"},{"location":"docker/9-compose-dockerfile/#production-environnement","text":"","title":"Production environnement"},{"location":"docker/9-compose-dockerfile/#introduction","text":"NGINX return the build. NGINX intercept http request and return by default an html file. Browse docker hub for nginx on official image page to host some simple static content . Simple test: docker run --rm -p 80:80 nginx Browse to localhost In a second terminal: docker exec -it exciting_elion sh cd usr/share/nginx/html ls 50x.html index.html cat index.html <!DOCTYPE html> <html> <head> <title>Welcome to nginx!</title> . . It's in this folder we gonna copy our application '/usr/share/nginx/html'. For more complex configuration, have a look in '/etc/nginx/conf.d' folder.","title":"Introduction"},{"location":"docker/9-compose-dockerfile/#multi-stage-dockerfile","text":"Reuse a preceding builded image in next build. Goal to reach here is to put React's build folder into NGINX image. ../client/Dockerfile.prod FROM node:alpine as buildstage WORKDIR /app COPY package.json . RUN npm install COPY . . RUN npm run build FROM nginx COPY --from=buildstage /app/build /usr/share/nginx/html EXPOSE 80 After second FROM above, --from=buildstage refer to first stage of image build (npm run build, output is a 'build' folder that containe production application). Build Docker image: docker build -t nginxreact -f Dockerfile.prod . . . => [stage-1 2/2] COPY --from=buildstage /app/build /usr/share/nginx/html . . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginxreact latest ee3388384541 4 minutes ago 141MB . . <none> <none> 1c9dc1e2c948 6 hours ago 483MB . . \"\\<none>\" image are produced by intermediate build stage(s). Launch a container with just built image: docker run --rm -p 80:80 nginxreact Browse to localhost to observe your production application running.","title":"Multi stage Dockerfile"},{"location":"docker/9-compose-dockerfile/#docker-compose","text":"A new Docker Compose configuration file dedicated to prodction: touch docker-compose.prod.yml docker-compose.prod.yml version: \"3.8\" services: mynginx: build: context: . dockerfile: Dockerfile.prod ports: - 80:80 Reset Docker content: docker system prune -a docker volume prune Start a fresh new production application: docker-compose -f docker-compose.prod.yml up Browse to localhost to observe your production application running.","title":"Docker Compose"},{"location":"elasticsearch/elasticsearch/","text":"ElasticSearch Update field Plugin Head Update boolean field with Chrome plugin ElasticSearch Head local: http://localhost:9200/ Other request tab URL http://localhost:9200/index/doc/id to check empty GET to update request _update POST {\"doc\":{\"deleted\":false}} Kibana 5.6 Browse to Dev Tools, Console to get: GET _index/_type/_id to update: POST _index/_type/_id/_update { \"doc\": { \"field\":\"value\" or \"field\":99 or \"field\":false } }","title":"ElasticSearch - Misc"},{"location":"elasticsearch/elasticsearch/#elasticsearch","text":"","title":"ElasticSearch"},{"location":"elasticsearch/elasticsearch/#update-field","text":"","title":"Update field"},{"location":"elasticsearch/elasticsearch/#plugin-head","text":"Update boolean field with Chrome plugin ElasticSearch Head local: http://localhost:9200/ Other request tab URL http://localhost:9200/index/doc/id to check empty GET to update request _update POST {\"doc\":{\"deleted\":false}}","title":"Plugin Head"},{"location":"elasticsearch/elasticsearch/#kibana-56","text":"Browse to Dev Tools, Console to get: GET _index/_type/_id to update: POST _index/_type/_id/_update { \"doc\": { \"field\":\"value\" or \"field\":99 or \"field\":false } }","title":"Kibana 5.6"},{"location":"git/git/","text":"Git Initialize Local settings: git config user.name \"Your Name\" git config user.email \"youremail@domain.com\" WSL Credential Manager setup SRC: microsoft git config credential.helper \"/mnt/c/Program\\ Files/Git/mingw64/libexec/git-core/git-credential-manager-core.exe\" Configuration List configuration parameters: git config --list Edit configuration parameters: git config --global --edit or git config --edit cache token to cache token (use token instead of password) (for 15 minutes, by default). SRC: github git config credential.helper cache or for 1 hour git config credential.helper 'cache --timeout=3600' SSH To HTTPS Change remote URL from SSH To HTTPS. Source Check existing remote: git remote -v Change your remote's URL from SSH to HTTPS with the git remote set-url command: git remote set-url origin https://github.com/USERNAME/REPOSITORY.git Many GitHub accounts How to manage credentials for many different GitHub accounts. Source Configure credentials to use the full repository path: git config --global credential.useHttpPath true","title":"Git - Misc"},{"location":"git/git/#git","text":"","title":"Git"},{"location":"git/git/#initialize","text":"Local settings: git config user.name \"Your Name\" git config user.email \"youremail@domain.com\"","title":"Initialize"},{"location":"git/git/#wsl-credential-manager-setup","text":"SRC: microsoft git config credential.helper \"/mnt/c/Program\\ Files/Git/mingw64/libexec/git-core/git-credential-manager-core.exe\"","title":"WSL Credential Manager setup"},{"location":"git/git/#configuration","text":"List configuration parameters: git config --list Edit configuration parameters: git config --global --edit or git config --edit","title":"Configuration"},{"location":"git/git/#cache-token","text":"to cache token (use token instead of password) (for 15 minutes, by default). SRC: github git config credential.helper cache or for 1 hour git config credential.helper 'cache --timeout=3600'","title":"cache token"},{"location":"git/git/#ssh-to-https","text":"Change remote URL from SSH To HTTPS. Source Check existing remote: git remote -v Change your remote's URL from SSH to HTTPS with the git remote set-url command: git remote set-url origin https://github.com/USERNAME/REPOSITORY.git","title":"SSH To HTTPS"},{"location":"git/git/#many-github-accounts","text":"How to manage credentials for many different GitHub accounts. Source Configure credentials to use the full repository path: git config --global credential.useHttpPath true","title":"Many GitHub accounts"},{"location":"intellij/1-intellij-misc/","text":"IntelliJ - 01 - Misc Setup project in WSL folder Fix EOL (LF vs CRLF) issue: git clone select root project folder menu File - File Properties - Line Separators - LF Unix git rollback entire project to reset CRLF issue SRC OR Terminal in a new \"native\" WSL folder, clone and fix CRLF issue : git clone project_url git config core.eol lf git config core.autocrlf input Service window For Docker connection, maybe not opened if comes from external project. To open it manually: View | Tool Windows | Services or Alt+8 SRC Search for ; and replace with ;\\r\\n For a file where each values are separated with ';' but need each values on a new line to compare files. replace ; enable regex by ;\\r\\n To revert, do it in Notepad++ with a record sequence Caret Cloning SRC: - IntelliJ IDEA Tips & Tricks: Multiple Cursors Alt + Shift + Insert to switch to column mode Then Shift + Up/Down Arrow(s)","title":"IntelliJ - 01 - Misc"},{"location":"intellij/1-intellij-misc/#intellij-01-misc","text":"","title":"IntelliJ - 01 - Misc"},{"location":"intellij/1-intellij-misc/#setup-project-in-wsl-folder","text":"Fix EOL (LF vs CRLF) issue: git clone select root project folder menu File - File Properties - Line Separators - LF Unix git rollback entire project to reset CRLF issue SRC OR Terminal in a new \"native\" WSL folder, clone and fix CRLF issue : git clone project_url git config core.eol lf git config core.autocrlf input","title":"Setup project in WSL folder"},{"location":"intellij/1-intellij-misc/#service-window","text":"For Docker connection, maybe not opened if comes from external project. To open it manually: View | Tool Windows | Services or Alt+8 SRC","title":"Service window"},{"location":"intellij/1-intellij-misc/#search-for-and-replace-with-rn","text":"For a file where each values are separated with ';' but need each values on a new line to compare files. replace ; enable regex by ;\\r\\n To revert, do it in Notepad++ with a record sequence","title":"Search for ; and replace with ;\\r\\n"},{"location":"intellij/1-intellij-misc/#caret-cloning","text":"SRC: - IntelliJ IDEA Tips & Tricks: Multiple Cursors Alt + Shift + Insert to switch to column mode Then Shift + Up/Down Arrow(s)","title":"Caret Cloning"},{"location":"intellij/2-intellij-wsl/","text":"IntelliJ - 02 - WSL IntelliJ integration with a project hosted in a WSL2 native folder (not /mnt/c) Test Maven To test that maven is correctly installed and running in Linux distribution. Setup a new maven project with a simple 'hello' class to test debug/run. Firewall rules To allow IntelliJ to communicate with WSL. SRC: - set IntelliJ rules to communicate with WSL PowerShell (admin mode): New-NetFirewallRule -DisplayName \"WSL\" -Direction Inbound -InterfaceAlias \"vEthernet (WSL)\" -Action Allow Get-NetFirewallRule | where DisplayName -ILike \"idea*.exe\" | Remove-NetFirewallRule CRLF issue After cloning a git repository maybe all files are marked as modified due to CRLF miss understanding between Windows and Linux file system. SRC: - fix CRLF issue From a terminal in a native (not /mnt/c) WSL folder: git clone <url> git config core.eol lf git config core.autocrlf input IntelliJ recipe At least release \"IntelliJ IDEA 2021.3.1 (Community Edition)\" Open existing project: - set project SDK with the one from WSL - set Maven home (IDE settings, search for maven) to : \"\\\\wsl$\\<linux distribution>\\usr\\share\\maven\" - invalidate cache and restart Note: - original Maven setting for Windows = C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2021.3.1\\plugins\\maven\\lib\\maven3 Fix IntelliJ Fix IntelliJ to disable one wsl experimental feature. SRC: - fix IntelliJ - press Shift-Shift to open \"Search everywhere\" - enter \"Experimental features\" and select the action - in the dialog that appears, turn off wsl.fsd.content.loader - restart the IDE Fix Docker For Docker Compose to prepare context with Docker Desktop for Windows. Enable the Docker Compose V2 option under the experimental settings. SRC: - fix Docker Fix Logback In case project fail to start due to Logback issue, \"Failed to create parent directories\" var log. Manually create needed log folder for project and set rights accordingly: sudo mkdir /var/log/<needed project folder name for log> sudo chmod a+rwx /var/log/<needed project folder name for log>","title":"IntelliJ - 02 - WSL"},{"location":"intellij/2-intellij-wsl/#intellij-02-wsl","text":"IntelliJ integration with a project hosted in a WSL2 native folder (not /mnt/c)","title":"IntelliJ - 02 - WSL"},{"location":"intellij/2-intellij-wsl/#test-maven","text":"To test that maven is correctly installed and running in Linux distribution. Setup a new maven project with a simple 'hello' class to test debug/run.","title":"Test Maven"},{"location":"intellij/2-intellij-wsl/#firewall-rules","text":"To allow IntelliJ to communicate with WSL. SRC: - set IntelliJ rules to communicate with WSL PowerShell (admin mode): New-NetFirewallRule -DisplayName \"WSL\" -Direction Inbound -InterfaceAlias \"vEthernet (WSL)\" -Action Allow Get-NetFirewallRule | where DisplayName -ILike \"idea*.exe\" | Remove-NetFirewallRule","title":"Firewall rules"},{"location":"intellij/2-intellij-wsl/#crlf-issue","text":"After cloning a git repository maybe all files are marked as modified due to CRLF miss understanding between Windows and Linux file system. SRC: - fix CRLF issue From a terminal in a native (not /mnt/c) WSL folder: git clone <url> git config core.eol lf git config core.autocrlf input","title":"CRLF issue"},{"location":"intellij/2-intellij-wsl/#intellij-recipe","text":"At least release \"IntelliJ IDEA 2021.3.1 (Community Edition)\" Open existing project: - set project SDK with the one from WSL - set Maven home (IDE settings, search for maven) to : \"\\\\wsl$\\<linux distribution>\\usr\\share\\maven\" - invalidate cache and restart Note: - original Maven setting for Windows = C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2021.3.1\\plugins\\maven\\lib\\maven3","title":"IntelliJ recipe"},{"location":"intellij/2-intellij-wsl/#fix-intellij","text":"Fix IntelliJ to disable one wsl experimental feature. SRC: - fix IntelliJ - press Shift-Shift to open \"Search everywhere\" - enter \"Experimental features\" and select the action - in the dialog that appears, turn off wsl.fsd.content.loader - restart the IDE","title":"Fix IntelliJ"},{"location":"intellij/2-intellij-wsl/#fix-docker","text":"For Docker Compose to prepare context with Docker Desktop for Windows. Enable the Docker Compose V2 option under the experimental settings. SRC: - fix Docker","title":"Fix Docker"},{"location":"intellij/2-intellij-wsl/#fix-logback","text":"In case project fail to start due to Logback issue, \"Failed to create parent directories\" var log. Manually create needed log folder for project and set rights accordingly: sudo mkdir /var/log/<needed project folder name for log> sudo chmod a+rwx /var/log/<needed project folder name for log>","title":"Fix Logback"},{"location":"java/test/mock/","text":"Mock Mockito in a springboot context. Test that a filter works as expected. Project source on gihub Extract from CustomerService.java: public String onlyCustomersWithPaulAsFirstNameThenLastNameToUpperCase() { List<Customer> customers = customerRepository.findAll(); List<Customer> onlyPauls = customers.stream().filter(customer -> \"Paul\".equals(customer.getFirstName())).collect(Collectors.toList()); converter.lastNameToUpperCase(onlyPauls); return !onlyPauls.isEmpty() ? String.join(\", \", onlyPauls.toString()) : \"none\"; } Extract from CustomerServiceTest.java: @InjectMocks private CustomerService customerService; @Mock private CustomerRepository customerRepository; @Mock Converter converter; @Test public void onlyCustomersWithPaulAsFirstNameThenLastNameToUpperCaseTest_WhenNotOnlyPaulsIn_ThenOnlyPaulsOut() { when(customerRepository.findAll()).thenReturn(CUSTOMERS); customerService.onlyCustomersWithPaulAsFirstNameThenLastNameToUpperCase(); @SuppressWarnings(\"unchecked\") ArgumentCaptor<List<Customer>> customersCaptor = ArgumentCaptor.forClass(List.class); verify(converter, times(1)).lastNameToUpperCase(customersCaptor.capture()); // For not captured/tested argument(s) replace with \"any()\" List<Customer> paulsOut = customersCaptor.getValue(); assertEquals(4, paulsOut.size()); assertTrue(paulsOut.stream().allMatch(customer -> PAUL.equals(customer.getFirstName()))); }","title":"mock"},{"location":"java/test/mock/#mock","text":"Mockito in a springboot context. Test that a filter works as expected. Project source on gihub Extract from CustomerService.java: public String onlyCustomersWithPaulAsFirstNameThenLastNameToUpperCase() { List<Customer> customers = customerRepository.findAll(); List<Customer> onlyPauls = customers.stream().filter(customer -> \"Paul\".equals(customer.getFirstName())).collect(Collectors.toList()); converter.lastNameToUpperCase(onlyPauls); return !onlyPauls.isEmpty() ? String.join(\", \", onlyPauls.toString()) : \"none\"; } Extract from CustomerServiceTest.java: @InjectMocks private CustomerService customerService; @Mock private CustomerRepository customerRepository; @Mock Converter converter; @Test public void onlyCustomersWithPaulAsFirstNameThenLastNameToUpperCaseTest_WhenNotOnlyPaulsIn_ThenOnlyPaulsOut() { when(customerRepository.findAll()).thenReturn(CUSTOMERS); customerService.onlyCustomersWithPaulAsFirstNameThenLastNameToUpperCase(); @SuppressWarnings(\"unchecked\") ArgumentCaptor<List<Customer>> customersCaptor = ArgumentCaptor.forClass(List.class); verify(converter, times(1)).lastNameToUpperCase(customersCaptor.capture()); // For not captured/tested argument(s) replace with \"any()\" List<Customer> paulsOut = customersCaptor.getValue(); assertEquals(4, paulsOut.size()); assertTrue(paulsOut.stream().allMatch(customer -> PAUL.equals(customer.getFirstName()))); }","title":"Mock"},{"location":"javascript/misc/","text":"misc","title":"misc"},{"location":"javascript/misc/#misc","text":"","title":"misc"},{"location":"javascript/training/02-environment/06-install-environnement/","text":"06-install-environnement For WSL2 refer to javascript dev environnement page from Microsoft documentation . VS Code Get latest release of Visual Studio Code from Internet page and install it accordingly to your Operating System (Windows, Linux, Mac). Node.js Get LTS (for Long Term Support) installation package from Internet page . Check install: node -v npm NPM should have installed along with installing Node.js. Check install: npm -v","title":"06-install-environnement"},{"location":"javascript/training/02-environment/06-install-environnement/#06-install-environnement","text":"For WSL2 refer to javascript dev environnement page from Microsoft documentation .","title":"06-install-environnement"},{"location":"javascript/training/02-environment/06-install-environnement/#vs-code","text":"Get latest release of Visual Studio Code from Internet page and install it accordingly to your Operating System (Windows, Linux, Mac).","title":"VS Code"},{"location":"javascript/training/02-environment/06-install-environnement/#nodejs","text":"Get LTS (for Long Term Support) installation package from Internet page . Check install: node -v","title":"Node.js"},{"location":"javascript/training/02-environment/06-install-environnement/#npm","text":"NPM should have installed along with installing Node.js. Check install: npm -v","title":"npm"},{"location":"javascript/training/02-environment/08-install-babel/","text":"08-install-babel Babel is a free and open-source JavaScript transcompiler that is mainly used to convert code into a backwards compatible version of JavaScript. Wiki Website Install In a terminal: mkdir test cd test npm init -y touch index.html touch babel.config.js touch es6.js es6.js: let test = \"123\"; let keyword only available since es6 and here we want to show that babel do his job by converting to an earlier version understandable by most of the browsers. In a terminal: npm i @babel/core @babel/cli @babel/preset-env Then all dependencies are in created in node_modules folder. If node_modules does not exist or removed, type command below will read package.json file and reinstall everything: npm i First, test babel without preset by adding script below in package.json: \"scripts\": { ..., \"babel\": \"babel es6.js\" } Then, in a terminal: npm run babel > test@1.0.0 babel > babel es6.js let test = \"123\"; No difference in output but at least we now that babel core is running well. To have output in a new file, package.json: \"scripts\": { ..., \"babel\": \"babel es6.js -o es6after.js\" } Then, again, in a terminal: npm run babel > test@1.0.0 babel > babel es6.js -o es6after.js Now, as expected, we have a new file es6after.js Now we configure babel in babel.config.js to use preset-env: module.exports = { presets: [[\"@babel/preset-env\"]] } Then, again, in a terminal: npm run babel > test@1.0.0 babel > babel es6.js -o es6after.js And now, es6after.js has been converted in an earlier version: \"use strict\"; var test = \"123\";","title":"08-install-babel"},{"location":"javascript/training/02-environment/08-install-babel/#08-install-babel","text":"Babel is a free and open-source JavaScript transcompiler that is mainly used to convert code into a backwards compatible version of JavaScript. Wiki Website","title":"08-install-babel"},{"location":"javascript/training/02-environment/08-install-babel/#install","text":"In a terminal: mkdir test cd test npm init -y touch index.html touch babel.config.js touch es6.js es6.js: let test = \"123\"; let keyword only available since es6 and here we want to show that babel do his job by converting to an earlier version understandable by most of the browsers. In a terminal: npm i @babel/core @babel/cli @babel/preset-env Then all dependencies are in created in node_modules folder. If node_modules does not exist or removed, type command below will read package.json file and reinstall everything: npm i First, test babel without preset by adding script below in package.json: \"scripts\": { ..., \"babel\": \"babel es6.js\" } Then, in a terminal: npm run babel > test@1.0.0 babel > babel es6.js let test = \"123\"; No difference in output but at least we now that babel core is running well. To have output in a new file, package.json: \"scripts\": { ..., \"babel\": \"babel es6.js -o es6after.js\" } Then, again, in a terminal: npm run babel > test@1.0.0 babel > babel es6.js -o es6after.js Now, as expected, we have a new file es6after.js Now we configure babel in babel.config.js to use preset-env: module.exports = { presets: [[\"@babel/preset-env\"]] } Then, again, in a terminal: npm run babel > test@1.0.0 babel > babel es6.js -o es6after.js And now, es6after.js has been converted in an earlier version: \"use strict\"; var test = \"123\";","title":"Install"},{"location":"javascript/training/02-environment/09-javascript-in-html/","text":"09-javascript-in-html Initial setup In root folder project create a src folder that will contain all javascript source code: mkdir src Move file (just a test file) used from previous chapter in src folder: mv es6.js src Edit babel script in package.json to specify input = src folder, output = dist folder: \"scripts\": { \"babel\": \"babel src --out-dir dist\" } Test, type below command in a terminal and have a look in dist folder to see the result of babel transpiled output: npm run babel Html In root project folder: touch index.html Open index.html in VS Code, and type \"!\" + tab to get a minimal html file set. Add a h1 section in body and from file explorer drag and drop it in a browser to see the result: <body> <h1>My app</h1> </body> Source In html Now to incorporate javascript in our html page, add a script section in head: <head> ... <script type=\"text/javascript\"></script> </head> Not really common expect for some dedicated usage like google analytic, but you may insert javascript directly inside script section of an html page (be aware to put only retro compatible code in it as long as it's directly interpreted by the browser, doesn't went through babel transpiler): <head> ... <script type=\"text/javascript\"> console.log('Hi'); </script> </head> Drag and drop index.html file in a browser, right click inspect and then observe message in console. You may incorporate anywhere inside a head or body section of an html document. Out html Separation of concern. Edit head, script section of index.html as follow: <script type=\"text/javascript\" src=\"dist/es6.js\"></script> Never edit files in dist folder. Edit src/es6.js by adding a line as follow: console.log(\"test\"); Recompile application with babel: npm run babel See the result in dist folder and refresh the page in the browser to observe message in log. From web E.g. jquery CDN = Content Delivery Network Browse for jquery cdn and copy script snippet of last minified version and add it to head section of html file: <head> <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\" integrity=\"sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=\" crossorigin=\"anonymous\"></script> <script type=\"text/javascript\" src=\"dist/es6.js\"></script> </head> Test that jquery is working by adding following line in src/es6.js file: console.log($); npm run babel and refresh page in browser, in console you may observe a message that correspond to a function like: \u0192 (e,t){return new S.fn.init(e,t)} What happen here is that we bring back javascript from internet.","title":"09-javascript-in-html"},{"location":"javascript/training/02-environment/09-javascript-in-html/#09-javascript-in-html","text":"","title":"09-javascript-in-html"},{"location":"javascript/training/02-environment/09-javascript-in-html/#initial-setup","text":"In root folder project create a src folder that will contain all javascript source code: mkdir src Move file (just a test file) used from previous chapter in src folder: mv es6.js src Edit babel script in package.json to specify input = src folder, output = dist folder: \"scripts\": { \"babel\": \"babel src --out-dir dist\" } Test, type below command in a terminal and have a look in dist folder to see the result of babel transpiled output: npm run babel","title":"Initial setup"},{"location":"javascript/training/02-environment/09-javascript-in-html/#html","text":"In root project folder: touch index.html Open index.html in VS Code, and type \"!\" + tab to get a minimal html file set. Add a h1 section in body and from file explorer drag and drop it in a browser to see the result: <body> <h1>My app</h1> </body>","title":"Html"},{"location":"javascript/training/02-environment/09-javascript-in-html/#source","text":"","title":"Source"},{"location":"javascript/training/02-environment/09-javascript-in-html/#in-html","text":"Now to incorporate javascript in our html page, add a script section in head: <head> ... <script type=\"text/javascript\"></script> </head> Not really common expect for some dedicated usage like google analytic, but you may insert javascript directly inside script section of an html page (be aware to put only retro compatible code in it as long as it's directly interpreted by the browser, doesn't went through babel transpiler): <head> ... <script type=\"text/javascript\"> console.log('Hi'); </script> </head> Drag and drop index.html file in a browser, right click inspect and then observe message in console. You may incorporate anywhere inside a head or body section of an html document.","title":"In html"},{"location":"javascript/training/02-environment/09-javascript-in-html/#out-html","text":"Separation of concern. Edit head, script section of index.html as follow: <script type=\"text/javascript\" src=\"dist/es6.js\"></script> Never edit files in dist folder. Edit src/es6.js by adding a line as follow: console.log(\"test\"); Recompile application with babel: npm run babel See the result in dist folder and refresh the page in the browser to observe message in log.","title":"Out html"},{"location":"javascript/training/02-environment/09-javascript-in-html/#from-web","text":"E.g. jquery CDN = Content Delivery Network Browse for jquery cdn and copy script snippet of last minified version and add it to head section of html file: <head> <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\" integrity=\"sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=\" crossorigin=\"anonymous\"></script> <script type=\"text/javascript\" src=\"dist/es6.js\"></script> </head> Test that jquery is working by adding following line in src/es6.js file: console.log($); npm run babel and refresh page in browser, in console you may observe a message that correspond to a function like: \u0192 (e,t){return new S.fn.init(e,t)} What happen here is that we bring back javascript from internet.","title":"From web"},{"location":"javascript/training/02-environment/10-webpack/","text":"10-webpack Basic principles Webpack is installed through npm. What is installed: webpack webpack-cli webpack-dev-server babel-loader Webpack Bundle creation. Webpack is configured through webpack.config.js configuration file. Webpack use babel-loader and take html + js content to create a dist bundle that contain optimized bundle.js and html content. Webpack-cli Use webpack in a terminal. Webpack-dev-server Local development web server the list at localhost address on dedicated port and return index.html file from dist folder. Installation Prerequisite First, rename used file in previous chapter src/es6.js to src/index.js and remove dist folder if it exist and move index.html in src/: mv src/es6.js src/index.js rm -rf dist mv index.html src/ In src/index.html remove script section. src/index.html: <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> <title>Document</title> </head> <body> <h1>My app</h1> </body> </html> Edit src/index.js as follow. src/index.js: let test = \"123\"; console.log(test); In package.json remove line in script section that concern babel because we'll let webpack to take it in charge. package.json: { \"name\": \"test\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"@babel/cli\": \"^7.17.6\", \"@babel/core\": \"^7.17.5\", \"@babel/preset-env\": \"^7.16.11\" } } Launch npm i webpack webpack-cli webpack-dev-server babel-loader Add new file at the project root level called webpack.config.js: touch webpack.config.js webpack.config.js: const path = require(\"path\"); const HtmlWebpackPlugin = require(\"html-webpack-plugin\"); module.exports = { entry: path.resolve(__dirname, \"src/index.js\"), output: { path: path.resolve(__dirname, \"dist\"), filename: \"[name].bundle.js\" }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, use: { loader: \"babel-loader\" } } ] }, plugins: [ new HtmlWebpackPlugin({ template: path.resolve(__dirname, \"src/index.html\") }) ], devtool: \"source-map\", mode: \"development\", devServer: { static: path.resolve(__dirname, './dist'), open: true, port: 4000 } }; Html webpack plugin automatically inject output js bundle to html file. Install: npm i html-webpack-plugin Edit package.json to use webpack and webpack server in script section. package.json ... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\", \"webpack\": \"webpack\", \"start\": \"webpack serve\" }, ... Run npm run webpack Now a dist folder appear with an index.html file that does include call to output result of bundled js, main.bundle.js. dist/index.html: ... <head> ... <script defer src=\"main.bundle.js\"></script> ... </head> ... In dist/main.bundle.js we may observe that output code went through babel because let has been replaced by var. dist/main.bundle.js: ... var test = \"123\"; ... Start npm start Browse to http://localhost:4000/ and hit F12 to open browser development tools and observe console. Retrieve code for this chapter on github","title":"10-webpack"},{"location":"javascript/training/02-environment/10-webpack/#10-webpack","text":"","title":"10-webpack"},{"location":"javascript/training/02-environment/10-webpack/#basic-principles","text":"Webpack is installed through npm. What is installed: webpack webpack-cli webpack-dev-server babel-loader","title":"Basic principles"},{"location":"javascript/training/02-environment/10-webpack/#webpack","text":"Bundle creation. Webpack is configured through webpack.config.js configuration file. Webpack use babel-loader and take html + js content to create a dist bundle that contain optimized bundle.js and html content.","title":"Webpack"},{"location":"javascript/training/02-environment/10-webpack/#webpack-cli","text":"Use webpack in a terminal.","title":"Webpack-cli"},{"location":"javascript/training/02-environment/10-webpack/#webpack-dev-server","text":"Local development web server the list at localhost address on dedicated port and return index.html file from dist folder.","title":"Webpack-dev-server"},{"location":"javascript/training/02-environment/10-webpack/#installation","text":"","title":"Installation"},{"location":"javascript/training/02-environment/10-webpack/#prerequisite","text":"First, rename used file in previous chapter src/es6.js to src/index.js and remove dist folder if it exist and move index.html in src/: mv src/es6.js src/index.js rm -rf dist mv index.html src/ In src/index.html remove script section. src/index.html: <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> <title>Document</title> </head> <body> <h1>My app</h1> </body> </html> Edit src/index.js as follow. src/index.js: let test = \"123\"; console.log(test); In package.json remove line in script section that concern babel because we'll let webpack to take it in charge. package.json: { \"name\": \"test\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"@babel/cli\": \"^7.17.6\", \"@babel/core\": \"^7.17.5\", \"@babel/preset-env\": \"^7.16.11\" } }","title":"Prerequisite"},{"location":"javascript/training/02-environment/10-webpack/#launch","text":"npm i webpack webpack-cli webpack-dev-server babel-loader Add new file at the project root level called webpack.config.js: touch webpack.config.js webpack.config.js: const path = require(\"path\"); const HtmlWebpackPlugin = require(\"html-webpack-plugin\"); module.exports = { entry: path.resolve(__dirname, \"src/index.js\"), output: { path: path.resolve(__dirname, \"dist\"), filename: \"[name].bundle.js\" }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, use: { loader: \"babel-loader\" } } ] }, plugins: [ new HtmlWebpackPlugin({ template: path.resolve(__dirname, \"src/index.html\") }) ], devtool: \"source-map\", mode: \"development\", devServer: { static: path.resolve(__dirname, './dist'), open: true, port: 4000 } }; Html webpack plugin automatically inject output js bundle to html file. Install: npm i html-webpack-plugin Edit package.json to use webpack and webpack server in script section. package.json ... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\", \"webpack\": \"webpack\", \"start\": \"webpack serve\" }, ...","title":"Launch"},{"location":"javascript/training/02-environment/10-webpack/#run","text":"npm run webpack Now a dist folder appear with an index.html file that does include call to output result of bundled js, main.bundle.js. dist/index.html: ... <head> ... <script defer src=\"main.bundle.js\"></script> ... </head> ... In dist/main.bundle.js we may observe that output code went through babel because let has been replaced by var. dist/main.bundle.js: ... var test = \"123\"; ...","title":"Run"},{"location":"javascript/training/02-environment/10-webpack/#start","text":"npm start Browse to http://localhost:4000/ and hit F12 to open browser development tools and observe console. Retrieve code for this chapter on github","title":"Start"},{"location":"javascript/training/02-environment/11-console/","text":"11-console Introduction console is an object which is part of javascript API. console.log is used to display information in browser console. console.error display output in red as an error. Error In a terminal from project's root folder start webpack: npm start Edit src/index.js as follow: let test = \"123\"; console.log(tost); tost variable does not exist and it will through an error in browser's console. Open a browser and DevTools window (F12 in Google Chrome), click on console tab. You can click on link to browse in file that trigger the error, index.js:2:13 You are now in original source code even he supposed to have been optimized by webpack. It's thanks to dist/main.bundle.js.map file that ease debugging stage with showing us original source code.","title":"11-console"},{"location":"javascript/training/02-environment/11-console/#11-console","text":"","title":"11-console"},{"location":"javascript/training/02-environment/11-console/#introduction","text":"console is an object which is part of javascript API. console.log is used to display information in browser console. console.error display output in red as an error.","title":"Introduction"},{"location":"javascript/training/02-environment/11-console/#error","text":"In a terminal from project's root folder start webpack: npm start Edit src/index.js as follow: let test = \"123\"; console.log(tost); tost variable does not exist and it will through an error in browser's console. Open a browser and DevTools window (F12 in Google Chrome), click on console tab. You can click on link to browse in file that trigger the error, index.js:2:13 You are now in original source code even he supposed to have been optimized by webpack. It's thanks to dist/main.bundle.js.map file that ease debugging stage with showing us original source code.","title":"Error"},{"location":"javascript/training/03-basis/12-intro-and-var/","text":"12-intro-and-var Introduction Chapter (03) objectives summary: Variables (var, let and const) Hoisting Types Operators Coercion Scope, Execution context Reference and value Environment is inherited from previous chapter and without particular mention, thereafter we will assume that the webpack environment has been launched with following command through a terminal at the root level of the project: npm start var src/index.js // declaration var firstName; // undefined console.log(firstName); // initialisation firstName = 'Olivier'; console.log(firstName); // reference error, does not exist // and stop execution if not commmented // console.log(lastName); // declare many variables at the same time var myvar1, myvar2; myvar1 = 123; myvar2 = 55; console.log(myvar1, myvar2);","title":"12-intro-and-var"},{"location":"javascript/training/03-basis/12-intro-and-var/#12-intro-and-var","text":"","title":"12-intro-and-var"},{"location":"javascript/training/03-basis/12-intro-and-var/#introduction","text":"Chapter (03) objectives summary: Variables (var, let and const) Hoisting Types Operators Coercion Scope, Execution context Reference and value Environment is inherited from previous chapter and without particular mention, thereafter we will assume that the webpack environment has been launched with following command through a terminal at the root level of the project: npm start","title":"Introduction"},{"location":"javascript/training/03-basis/12-intro-and-var/#var","text":"src/index.js // declaration var firstName; // undefined console.log(firstName); // initialisation firstName = 'Olivier'; console.log(firstName); // reference error, does not exist // and stop execution if not commmented // console.log(lastName); // declare many variables at the same time var myvar1, myvar2; myvar1 = 123; myvar2 = 55; console.log(myvar1, myvar2);","title":"var"},{"location":"javascript/training/03-basis/13-let-and-const/","text":"13-let-and-const var problematic let has been introduced to fix some var's problem. var allow to redeclare a variable that has already been declared with the same name, which could lead in very problematic issues in huge js file when you don't remember that a variable with a particular name has already been declared and you redeclare it with the same name for a different usage: var test = 123; var test = 456; Curly brace delimitate a code block but does not limit variable scope: { var test = 123; } console.log(test); let Reuse a name will raise a \"Identifier 'test' has already been declared.\" error in browser and webpack consoles: let test = 123; let test = 456; Scope of let is limited to code block, below example will raise a \"test not defined\" error: { let test = 123; } console.log(test); Use let instead of var is mostly advised. const const should be initialized on line where she's declared: const test = 123; Like expected const cannot be reassigned and trying to will raise a read only error. For an object reference it's possible to reassign a key inside a const object but not the reference himself: const simpleObject = { test: 123 }; console.log(simpleObject.test); // OK simpleObject.test = 456; console.log(simpleObject.test); // KO simpleObject = 456 Priority order of usage const let var","title":"13-let-and-const"},{"location":"javascript/training/03-basis/13-let-and-const/#13-let-and-const","text":"","title":"13-let-and-const"},{"location":"javascript/training/03-basis/13-let-and-const/#var-problematic","text":"let has been introduced to fix some var's problem. var allow to redeclare a variable that has already been declared with the same name, which could lead in very problematic issues in huge js file when you don't remember that a variable with a particular name has already been declared and you redeclare it with the same name for a different usage: var test = 123; var test = 456; Curly brace delimitate a code block but does not limit variable scope: { var test = 123; } console.log(test);","title":"var problematic"},{"location":"javascript/training/03-basis/13-let-and-const/#let","text":"Reuse a name will raise a \"Identifier 'test' has already been declared.\" error in browser and webpack consoles: let test = 123; let test = 456; Scope of let is limited to code block, below example will raise a \"test not defined\" error: { let test = 123; } console.log(test); Use let instead of var is mostly advised.","title":"let"},{"location":"javascript/training/03-basis/13-let-and-const/#const","text":"const should be initialized on line where she's declared: const test = 123; Like expected const cannot be reassigned and trying to will raise a read only error. For an object reference it's possible to reassign a key inside a const object but not the reference himself: const simpleObject = { test: 123 }; console.log(simpleObject.test); // OK simpleObject.test = 456; console.log(simpleObject.test); // KO simpleObject = 456","title":"const"},{"location":"javascript/training/03-basis/13-let-and-const/#priority-order-of-usage","text":"const let var","title":"Priority order of usage"},{"location":"javascript/training/03-basis/14-hoisting/","text":"14-hoisting Introduction At first when a browser receive a javascript file, he read the file content entirely and initialize a stack. This behavior is due to the fact that Javascript is an interpreted language. This stack is a reserved memory place to store needed things (var, function, etc.) for running the script. This process of preparing the stack for running the script is called \"Hoisting\". Initialization var Initialized during the hoisting phase to \"undefined\". let and const They are hoisted and NOT , initialized to \"undefined\". Initialized during the execution phase.","title":"14-hoisting"},{"location":"javascript/training/03-basis/14-hoisting/#14-hoisting","text":"","title":"14-hoisting"},{"location":"javascript/training/03-basis/14-hoisting/#introduction","text":"At first when a browser receive a javascript file, he read the file content entirely and initialize a stack. This behavior is due to the fact that Javascript is an interpreted language. This stack is a reserved memory place to store needed things (var, function, etc.) for running the script. This process of preparing the stack for running the script is called \"Hoisting\".","title":"Introduction"},{"location":"javascript/training/03-basis/14-hoisting/#initialization","text":"","title":"Initialization"},{"location":"javascript/training/03-basis/14-hoisting/#var","text":"Initialized during the hoisting phase to \"undefined\".","title":"var"},{"location":"javascript/training/03-basis/14-hoisting/#let-and-const","text":"They are hoisted and NOT , initialized to \"undefined\". Initialized during the execution phase.","title":"let and const"},{"location":"javascript/training/03-basis/15-type/","text":"15-type Introduction Javascript is a dynamically typed language. Statically typed languages types are checked during the compilation phase: bool test = '123' // error Dynamic types, in Javascript, may change during the execution and is inferred from the type of the value assigned to the variable: let test = '123' // ok test = true // ok test = 55 // ok In Javascript there's two main family of types: primitive object Everything that's ain't an object is a primitive. Primitive boolean number // may contain any type of number, integer, float, etc. string of characters Undefined // not yet assigned, automatic, implicit Null // like 'Undefined' but set manually, explicit Symbol // since ES6 BigInt // since ES2020 Primitives are immutable which mean on a reassignment the variable name point to a new value, but the previous value is still held in memory. Hence the need for garbage collection. Object Literal object Array Function Date .. all the rest // all what is not a primitive, is an object Objects and arrays are mutable. A mutable object is an object whose state can be modified after it is created. Review src/index.js: // string, console -> string const test01 = \"jean\"; console.log(typeof test01); // number, console -> number const test02 = 123.4; console.log(typeof test02); // null, console -> object = bug! const test03 = null; console.log(typeof test03); // undefined, console -> undefined // could not be a const like above // because const should be initialized // on the same line where declared let test04; console.log(typeof test04); // Symbol, console -> symbol let test05 = Symbol(); console.log(typeof test05); // Boolean, console -> boolean let test06 = true; console.log(typeof test06); // Literal object, console -> object const test07 = { test71: \"Hello\", test72: \"World\" } console.log(typeof test07); // Function object, console -> function, although it's an object const test08 = function() { console.log(\"Hello\"); }; console.log(typeof test08); // Date object, console -> object const test09 = new Date(); console.log(typeof test09); // Array object, console -> object const test10 = [1, 2, 3]; console.log(typeof test10);","title":"15-type"},{"location":"javascript/training/03-basis/15-type/#15-type","text":"","title":"15-type"},{"location":"javascript/training/03-basis/15-type/#introduction","text":"Javascript is a dynamically typed language. Statically typed languages types are checked during the compilation phase: bool test = '123' // error Dynamic types, in Javascript, may change during the execution and is inferred from the type of the value assigned to the variable: let test = '123' // ok test = true // ok test = 55 // ok In Javascript there's two main family of types: primitive object Everything that's ain't an object is a primitive.","title":"Introduction"},{"location":"javascript/training/03-basis/15-type/#primitive","text":"boolean number // may contain any type of number, integer, float, etc. string of characters Undefined // not yet assigned, automatic, implicit Null // like 'Undefined' but set manually, explicit Symbol // since ES6 BigInt // since ES2020 Primitives are immutable which mean on a reassignment the variable name point to a new value, but the previous value is still held in memory. Hence the need for garbage collection.","title":"Primitive"},{"location":"javascript/training/03-basis/15-type/#object","text":"Literal object Array Function Date .. all the rest // all what is not a primitive, is an object Objects and arrays are mutable. A mutable object is an object whose state can be modified after it is created.","title":"Object"},{"location":"javascript/training/03-basis/15-type/#review","text":"src/index.js: // string, console -> string const test01 = \"jean\"; console.log(typeof test01); // number, console -> number const test02 = 123.4; console.log(typeof test02); // null, console -> object = bug! const test03 = null; console.log(typeof test03); // undefined, console -> undefined // could not be a const like above // because const should be initialized // on the same line where declared let test04; console.log(typeof test04); // Symbol, console -> symbol let test05 = Symbol(); console.log(typeof test05); // Boolean, console -> boolean let test06 = true; console.log(typeof test06); // Literal object, console -> object const test07 = { test71: \"Hello\", test72: \"World\" } console.log(typeof test07); // Function object, console -> function, although it's an object const test08 = function() { console.log(\"Hello\"); }; console.log(typeof test08); // Date object, console -> object const test09 = new Date(); console.log(typeof test09); // Array object, console -> object const test10 = [1, 2, 3]; console.log(typeof test10);","title":"Review"},{"location":"javascript/training/03-basis/16-operator/","text":"16-operator Introduction Operators and the notions of precedence and associativity. Assignation let a = 1; console.log(a); Addition let a = 1 + 2; console.log(a); let b = 'hello, ' + 'world'; console.log(b); Precedence Operator precedence Precedence determine in which order operators are executed. For, let's say: let a = 1 + 2; // 3 We have two operators, '=' and '+'. By clicking one link above you may find Table precedence section with \"weight\" of each operators that will determine execution order: for '+' it's 12 for '=' it's 2 Means that '+' will be executed before '='. For: let a = 2 + 2 * 5; // 12 for '*' it's 13 for '+' it's 12 for '=' it's 2 Means that first '*' then '+' and finally '='. Associativity Associativity rules apply when there's many operator with same precedence weight. Even though the calculation below gives the same result no matter which way you apply the operators, we still use it as an example. Multiplication and division operator have same precedence weight of 13. let a = 2 + 2 * 5 / 3; // 5.333333333333334 But then what matter here is what 'Associativity' column contain (in above mentioned table) which is, in our case, 'left-to-right'. Means, calculation start by multiplication and then division. Note that parenthesis is also an operator with maximal precedence weight. Conditional (ternary) operator (?) Source let a = 1; // a += 2; let b = a == 3 ? 5 : 6; console.log(b); // 6","title":"16-operator"},{"location":"javascript/training/03-basis/16-operator/#16-operator","text":"","title":"16-operator"},{"location":"javascript/training/03-basis/16-operator/#introduction","text":"Operators and the notions of precedence and associativity.","title":"Introduction"},{"location":"javascript/training/03-basis/16-operator/#assignation","text":"let a = 1; console.log(a);","title":"Assignation"},{"location":"javascript/training/03-basis/16-operator/#addition","text":"let a = 1 + 2; console.log(a); let b = 'hello, ' + 'world'; console.log(b);","title":"Addition"},{"location":"javascript/training/03-basis/16-operator/#precedence","text":"Operator precedence Precedence determine in which order operators are executed. For, let's say: let a = 1 + 2; // 3 We have two operators, '=' and '+'. By clicking one link above you may find Table precedence section with \"weight\" of each operators that will determine execution order: for '+' it's 12 for '=' it's 2 Means that '+' will be executed before '='. For: let a = 2 + 2 * 5; // 12 for '*' it's 13 for '+' it's 12 for '=' it's 2 Means that first '*' then '+' and finally '='.","title":"Precedence"},{"location":"javascript/training/03-basis/16-operator/#associativity","text":"Associativity rules apply when there's many operator with same precedence weight. Even though the calculation below gives the same result no matter which way you apply the operators, we still use it as an example. Multiplication and division operator have same precedence weight of 13. let a = 2 + 2 * 5 / 3; // 5.333333333333334 But then what matter here is what 'Associativity' column contain (in above mentioned table) which is, in our case, 'left-to-right'. Means, calculation start by multiplication and then division. Note that parenthesis is also an operator with maximal precedence weight.","title":"Associativity"},{"location":"javascript/training/03-basis/16-operator/#conditional-ternary-operator","text":"Source let a = 1; // a += 2; let b = a == 3 ? 5 : 6; console.log(b); // 6","title":"Conditional (ternary) operator (?)"},{"location":"javascript/training/03-basis/17-coercion/","text":"17-coercion Introduction Due to the dynamic nature of JavaScript's typing. Type coercion Implicit coercion Implicit or automatic conversion. let a = 1; let b = 'hello'; console.log(a + b); // 1hello Unable to convert hello to a number but 1 is easily converted to a string and then the result of the addition is the concatenated string. Another example when adding a number to a true boolean value (converted to 1 (false would be converted to zero)): let a = 1; let b = true; console.log(a + b); // 2 Another example with string and boolean value, here converted to a string: let a = 'test'; let b = false; console.log(a + b); // testfalse Constructor conversion Types's constructor call with a value trying to convert, e.g. Number('hello'). console.log(Number('hello, world')); // NaN = not a number let a = 1; let b = undefined; console.log(a + b); // NaN console.log(Number(undefined)); // NaN console.log(String(undefined)); // undefined console.log(String(1)); // 1 console.log(String(null)); // null NaN, not a number, coercion not possible!","title":"17-coercion"},{"location":"javascript/training/03-basis/17-coercion/#17-coercion","text":"","title":"17-coercion"},{"location":"javascript/training/03-basis/17-coercion/#introduction","text":"Due to the dynamic nature of JavaScript's typing. Type coercion","title":"Introduction"},{"location":"javascript/training/03-basis/17-coercion/#implicit-coercion","text":"Implicit or automatic conversion. let a = 1; let b = 'hello'; console.log(a + b); // 1hello Unable to convert hello to a number but 1 is easily converted to a string and then the result of the addition is the concatenated string. Another example when adding a number to a true boolean value (converted to 1 (false would be converted to zero)): let a = 1; let b = true; console.log(a + b); // 2 Another example with string and boolean value, here converted to a string: let a = 'test'; let b = false; console.log(a + b); // testfalse","title":"Implicit coercion"},{"location":"javascript/training/03-basis/17-coercion/#constructor-conversion","text":"Types's constructor call with a value trying to convert, e.g. Number('hello'). console.log(Number('hello, world')); // NaN = not a number let a = 1; let b = undefined; console.log(a + b); // NaN console.log(Number(undefined)); // NaN console.log(String(undefined)); // undefined console.log(String(1)); // 1 console.log(String(null)); // null NaN, not a number, coercion not possible!","title":"Constructor conversion"},{"location":"kafka/1-kafka-misc/","text":"Kafka - 01 - Misc Listing Kafka Topics Source In a Docker Kafka Container CLI. Listing Topics kafka-topics.sh --list --zookeeper localhost:2181 kafka-topics.sh --list --zookeeper <zookeeper_container_name_in_docker_stack_network>:2181 kafka-topics.sh --list --zookeeper zookeeper-3.5.7:2181 Topic Details kafka-topics.sh --bootstrap-server=localhost:9092 --describe --topic <topic_name>","title":"Kafka - 01 - Misc"},{"location":"kafka/1-kafka-misc/#kafka-01-misc","text":"","title":"Kafka - 01 - Misc"},{"location":"kafka/1-kafka-misc/#listing-kafka-topics","text":"Source In a Docker Kafka Container CLI.","title":"Listing Kafka Topics"},{"location":"kafka/1-kafka-misc/#listing-topics","text":"kafka-topics.sh --list --zookeeper localhost:2181 kafka-topics.sh --list --zookeeper <zookeeper_container_name_in_docker_stack_network>:2181 kafka-topics.sh --list --zookeeper zookeeper-3.5.7:2181","title":"Listing Topics"},{"location":"kafka/1-kafka-misc/#topic-details","text":"kafka-topics.sh --bootstrap-server=localhost:9092 --describe --topic <topic_name>","title":"Topic Details"},{"location":"linux/1-linux-misc/","text":"Linux - 01 - Misc Curl curl -i localhost curl -sb -H \"Accept: application/json\" \"http://localhost\" | json_pp Compress Decompress Compress (czf) - c compress, -z zip, -f file tar -czf /targetfolder/targetfile.tar.gz /sourcefolder Decompress (xzf) - x extract, -z zip, -f file tar -xzf targetfile.tar.gz or gzip, -k to keep original, -d to decompress: gzip -kd file.gz Package List installed apt list --installed Info apt-cache show packagename Remove sudo apt-get --purge autoremove packagename Switch user to root Switch current user to root sudo su - Grep lines before after match -B before -A after Stick ne lines just after option grep -B2 -A3 pattern infile.txt Copy files from list Copy specific files from a text list of files rsync -a sourcefolder --files-from=list.txt destinationfolder Get data between two patterns In error.log . . 05:59:30.024 [nioEventLoopGroup-3-5] ERROR c.l.d.c.ConnectorServerHandlerTCP.parseAndSendMessageTeltonika(177) - class java.util.concurrent.ExecutionException FOR RAW DATA : 0000017d55747fb00003f5380c1be045ce00000000000000000804ef005000c8024503034230fc430f8d440000011007e0fca600 WITH STACKTRACE : {} . . Get data between \"DATA : \" and \" WITH\" (hex raw data) cat error.log | sed -nr 's/.*DATA : (.*) WITH.*/\\1/p' or cat file | grep -o -P '(?<=left).*(?=right)' Grep patterns from a file -f option, maybe -oF options also grep -f patterns_file *.log or grep -oFf patterns.txt *.log If result's count's not OK, check by not found pattern (-h option to hide filename in output) grep -hoFf patterns.txt *.log | grep -vFf - patterns.txt For list of file For list of file in current folder, do operation. Here we want to have file name, cat content and separate result with a new line ll *.txt 1.txt 2.txt 3.txt 4.txt 5.txt for f in {2..4}.txt; do echo \"$f\"; cat \"$f\"; printf \"\\n\"; done 2.txt jkl mno pqr 3.txt stu vwx yza 4.txt bcd efg hij Search between timestamp sed -rne '/10:50/,/11:05/ p' file Put existing time range in file (10:50 - 11:05). Highlight search result grep --color=always -z pattern file | less -R always to transmit color through pipe -z to show everything, not only the matching pattern -R to avoid showing esc char instead of color Delete history history 1003 25-04-2016 17:54:52 echo \"Command 1\" 1004 25-04-2016 17:54:54 echo \"Command 2\" 1005 25-04-2016 17:54:57 echo \"Command 3\" 1006 25-04-2016 17:54:59 echo \"Command 4\" 1007 25-04-2016 17:55:01 echo \"Command 5\" 1008 25-04-2016 17:55:03 echo \"Command 6\" 1009 25-04-2016 17:55:07 echo \"Command 7\" 1010 25-04-2016 17:55:09 echo \"Command 8\" 1011 25-04-2016 17:55:11 echo \"Command 9\" 1012 25-04-2016 17:55:14 echo \"Command 10\" for h in $(seq 1006 1008); do history -d 1006; done Where is a program How to know where reside a program, e.g. ls? which ls /usr/bin/ls env env | grep PATH Difference of cmd output diff <(ls test1) <(ls test2) Difference of sorted lists sort ok.txt > okSorted.txt sort all.txt > allSorted.txt diff --new-line-format=\"\" --unchanged-line-format=\"\" allSorted.txt okSorted.txt Column Min cat ... | grep ... | sort -n -r | tail -n10 Max cat ... | grep ... | sort -n -r | head -n10 Average test.txt (warning on empty lines (maybe at the end)) 1 3 7 cat test.txt | awk '{ total += $1 } END { print total/NR }' 3.66667 Median test.txt (warning on empty lines (maybe at the end)) 1 3 7 11 22 45 71 median.awk #/usr/bin/env awk { count[NR] = $1; } END { if (NR % 2) { print count[(NR + 1) / 2]; } else { print (count[(NR / 2)] + count[(NR / 2) + 1]) / 2.0; } } cat test.txt | awk -f median.awk 11 Check equal number of values below and above median cat test.txt | awk '{if($1 < 11) print $1}' | wc -l 3 cat test.txt | awk '{if($1 > 11) print $1}' | wc -l 3 Get nth column from file Get nth column from file with field separated values test.txt column 1 row 1;column 2 row 1;column 3 row 1 column 1 row 2;column 2 row 2;column 3 row 2 column 1 row 3;column 2 row 3;column 3 row 3 cat test.txt | awk -F ';' '{print $2}' column 2 row 1 column 2 row 2 column 2 row 3 Conditional cat test.txt | awk -F ';' '{if($1 == \"column 1 row 2\") print $2}' column 2 row 2 List files Sorted by sizes and human readable ll -S -h Uniq values in a file Uniq values in a file, sorted and counted (first sort is mandatory) test.txt 1 71 3 7 22 1 11 22 45 71 22 cat test.txt | sort | uniq -c 2 1 1 11 3 22 1 3 1 45 1 7 2 71 sorted output cat test.txt | sort | uniq -c | sort 1 11 1 3 1 45 1 7 2 1 2 71 3 22 revert sorted output cat test.txt | sort | uniq -c | sort -r 3 22 2 71 2 1 1 7 1 45 1 3 1 11 All file containing a pattern List all file that contain a pattern in current folder: Be aware to filtered out subfolder by precising some file name pattern (e.g. '*.log', not only '*') grep searchedString *.log Grep end of line after match SRC cat error.log | grep -A 1 -B 1 --group-separator==============\\\\r\\\\n \"not valid\" Empty file Empty File Content by Redirecting to Null: > access.log Disk usage df -h Huge file: sudo du -xh / | grep -P \"G\\t\" Last modification of a file date -r fileName Creation date of a file Below process to find creation date of a test file In a tmp directory create a test file Find inode of the file Find partition on which current folder belongs to Use file system debugger to find creation date mkdir tmp cd tmp touch test ls -i 201769 test df . Filesystem 1K-blocks Used Available Use% Mounted on /dev/sdd 263174212 10339304 239396752 5% / sudo debugfs -R 'stat <201769>' /dev/sdd . . debugfs 1.45.5 (07-Jan-2020) . . Filesystem 1K-blocks Used Available Use% Mounted on /dev/sdd 263174212 10339304 239396752 5% / 16:15:36 \u2714 oldu:(main)~/git/doc/tmp$ sudo debugfs -R 'stat <201769>' /dev/sdd Inode: 201769 Type: regular Mode: 0644 Flags: 0x80000 Generation: 333662723 Version: 0x00000000:00000001 User: 1000 Group: 1000 Project: 0 Size: 0 File ACL: 0 Links: 1 Blockcount: 0 Fragment: Address: 0 Number: 0 Size: 0 ctime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 atime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 mtime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 crtime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 Size of extra inode fields: 32 Inode checksum: 0x38e4efd5 Since when a process run ps -p pid -o etime Then use this online tool to calculate time between above result and now. How many file descriptors opened by a process disk usage find processName's process id (e.g. 28043) number of fd opened for pid max limit of opened fd for pid df -H ps ax | grep processName sudo ls /proc/28043/fd | wc -l sudo grep \"Max open files\" /proc/28043/limits | awk '{ print $4; }' Copy filtered file list Copy (for move replace below cp by mv) grep\"ed\" filtered files list to another folder. ls | grep pattern1 | grep pattern2 | ... | xargs cp -t /destinationFolder Add prefix to file names list for f in * ; do mv -- \"$f\" \"PRE_$f\" ; done","title":"Linux - 01 - Misc"},{"location":"linux/1-linux-misc/#linux-01-misc","text":"","title":"Linux - 01 - Misc"},{"location":"linux/1-linux-misc/#curl","text":"curl -i localhost curl -sb -H \"Accept: application/json\" \"http://localhost\" | json_pp","title":"Curl"},{"location":"linux/1-linux-misc/#compress-decompress","text":"","title":"Compress Decompress"},{"location":"linux/1-linux-misc/#compress-czf","text":"- c compress, -z zip, -f file tar -czf /targetfolder/targetfile.tar.gz /sourcefolder","title":"Compress (czf)"},{"location":"linux/1-linux-misc/#decompress-xzf","text":"- x extract, -z zip, -f file tar -xzf targetfile.tar.gz or gzip, -k to keep original, -d to decompress: gzip -kd file.gz","title":"Decompress (xzf)"},{"location":"linux/1-linux-misc/#package","text":"","title":"Package"},{"location":"linux/1-linux-misc/#list-installed","text":"apt list --installed","title":"List installed"},{"location":"linux/1-linux-misc/#info","text":"apt-cache show packagename","title":"Info"},{"location":"linux/1-linux-misc/#remove","text":"sudo apt-get --purge autoremove packagename","title":"Remove"},{"location":"linux/1-linux-misc/#switch-user-to-root","text":"Switch current user to root sudo su -","title":"Switch user to root"},{"location":"linux/1-linux-misc/#grep-lines-before-after-match","text":"-B before -A after Stick ne lines just after option grep -B2 -A3 pattern infile.txt","title":"Grep lines before after match"},{"location":"linux/1-linux-misc/#copy-files-from-list","text":"Copy specific files from a text list of files rsync -a sourcefolder --files-from=list.txt destinationfolder","title":"Copy files from list"},{"location":"linux/1-linux-misc/#get-data-between-two-patterns","text":"In error.log . . 05:59:30.024 [nioEventLoopGroup-3-5] ERROR c.l.d.c.ConnectorServerHandlerTCP.parseAndSendMessageTeltonika(177) - class java.util.concurrent.ExecutionException FOR RAW DATA : 0000017d55747fb00003f5380c1be045ce00000000000000000804ef005000c8024503034230fc430f8d440000011007e0fca600 WITH STACKTRACE : {} . . Get data between \"DATA : \" and \" WITH\" (hex raw data) cat error.log | sed -nr 's/.*DATA : (.*) WITH.*/\\1/p' or cat file | grep -o -P '(?<=left).*(?=right)'","title":"Get data between two patterns"},{"location":"linux/1-linux-misc/#grep-patterns-from-a-file","text":"-f option, maybe -oF options also grep -f patterns_file *.log or grep -oFf patterns.txt *.log If result's count's not OK, check by not found pattern (-h option to hide filename in output) grep -hoFf patterns.txt *.log | grep -vFf - patterns.txt","title":"Grep patterns from a file"},{"location":"linux/1-linux-misc/#for-list-of-file","text":"For list of file in current folder, do operation. Here we want to have file name, cat content and separate result with a new line ll *.txt 1.txt 2.txt 3.txt 4.txt 5.txt for f in {2..4}.txt; do echo \"$f\"; cat \"$f\"; printf \"\\n\"; done 2.txt jkl mno pqr 3.txt stu vwx yza 4.txt bcd efg hij","title":"For list of file"},{"location":"linux/1-linux-misc/#search-between-timestamp","text":"sed -rne '/10:50/,/11:05/ p' file Put existing time range in file (10:50 - 11:05).","title":"Search between timestamp"},{"location":"linux/1-linux-misc/#highlight-search-result","text":"grep --color=always -z pattern file | less -R always to transmit color through pipe -z to show everything, not only the matching pattern -R to avoid showing esc char instead of color","title":"Highlight search result"},{"location":"linux/1-linux-misc/#delete-history","text":"history 1003 25-04-2016 17:54:52 echo \"Command 1\" 1004 25-04-2016 17:54:54 echo \"Command 2\" 1005 25-04-2016 17:54:57 echo \"Command 3\" 1006 25-04-2016 17:54:59 echo \"Command 4\" 1007 25-04-2016 17:55:01 echo \"Command 5\" 1008 25-04-2016 17:55:03 echo \"Command 6\" 1009 25-04-2016 17:55:07 echo \"Command 7\" 1010 25-04-2016 17:55:09 echo \"Command 8\" 1011 25-04-2016 17:55:11 echo \"Command 9\" 1012 25-04-2016 17:55:14 echo \"Command 10\" for h in $(seq 1006 1008); do history -d 1006; done","title":"Delete history"},{"location":"linux/1-linux-misc/#where-is-a-program","text":"How to know where reside a program, e.g. ls? which ls /usr/bin/ls env env | grep PATH","title":"Where is a program"},{"location":"linux/1-linux-misc/#difference-of-cmd-output","text":"diff <(ls test1) <(ls test2) Difference of sorted lists sort ok.txt > okSorted.txt sort all.txt > allSorted.txt diff --new-line-format=\"\" --unchanged-line-format=\"\" allSorted.txt okSorted.txt","title":"Difference of cmd output"},{"location":"linux/1-linux-misc/#column","text":"","title":"Column"},{"location":"linux/1-linux-misc/#min","text":"cat ... | grep ... | sort -n -r | tail -n10","title":"Min"},{"location":"linux/1-linux-misc/#max","text":"cat ... | grep ... | sort -n -r | head -n10","title":"Max"},{"location":"linux/1-linux-misc/#average","text":"test.txt (warning on empty lines (maybe at the end)) 1 3 7 cat test.txt | awk '{ total += $1 } END { print total/NR }' 3.66667","title":"Average"},{"location":"linux/1-linux-misc/#median","text":"test.txt (warning on empty lines (maybe at the end)) 1 3 7 11 22 45 71 median.awk #/usr/bin/env awk { count[NR] = $1; } END { if (NR % 2) { print count[(NR + 1) / 2]; } else { print (count[(NR / 2)] + count[(NR / 2) + 1]) / 2.0; } } cat test.txt | awk -f median.awk 11 Check equal number of values below and above median cat test.txt | awk '{if($1 < 11) print $1}' | wc -l 3 cat test.txt | awk '{if($1 > 11) print $1}' | wc -l 3","title":"Median"},{"location":"linux/1-linux-misc/#get-nth-column-from-file","text":"Get nth column from file with field separated values test.txt column 1 row 1;column 2 row 1;column 3 row 1 column 1 row 2;column 2 row 2;column 3 row 2 column 1 row 3;column 2 row 3;column 3 row 3 cat test.txt | awk -F ';' '{print $2}' column 2 row 1 column 2 row 2 column 2 row 3","title":"Get nth column from file"},{"location":"linux/1-linux-misc/#conditional","text":"cat test.txt | awk -F ';' '{if($1 == \"column 1 row 2\") print $2}' column 2 row 2","title":"Conditional"},{"location":"linux/1-linux-misc/#list-files","text":"Sorted by sizes and human readable ll -S -h","title":"List files"},{"location":"linux/1-linux-misc/#uniq-values-in-a-file","text":"Uniq values in a file, sorted and counted (first sort is mandatory) test.txt 1 71 3 7 22 1 11 22 45 71 22 cat test.txt | sort | uniq -c 2 1 1 11 3 22 1 3 1 45 1 7 2 71 sorted output cat test.txt | sort | uniq -c | sort 1 11 1 3 1 45 1 7 2 1 2 71 3 22 revert sorted output cat test.txt | sort | uniq -c | sort -r 3 22 2 71 2 1 1 7 1 45 1 3 1 11","title":"Uniq values in a file"},{"location":"linux/1-linux-misc/#all-file-containing-a-pattern","text":"List all file that contain a pattern in current folder: Be aware to filtered out subfolder by precising some file name pattern (e.g. '*.log', not only '*') grep searchedString *.log","title":"All file containing a pattern"},{"location":"linux/1-linux-misc/#grep-end-of-line-after-match","text":"SRC cat error.log | grep -A 1 -B 1 --group-separator==============\\\\r\\\\n \"not valid\"","title":"Grep end of line after match"},{"location":"linux/1-linux-misc/#empty-file","text":"Empty File Content by Redirecting to Null: > access.log","title":"Empty file"},{"location":"linux/1-linux-misc/#disk-usage","text":"df -h Huge file: sudo du -xh / | grep -P \"G\\t\"","title":"Disk usage"},{"location":"linux/1-linux-misc/#last-modification-of-a-file","text":"date -r fileName","title":"Last modification of a file"},{"location":"linux/1-linux-misc/#creation-date-of-a-file","text":"Below process to find creation date of a test file In a tmp directory create a test file Find inode of the file Find partition on which current folder belongs to Use file system debugger to find creation date mkdir tmp cd tmp touch test ls -i 201769 test df . Filesystem 1K-blocks Used Available Use% Mounted on /dev/sdd 263174212 10339304 239396752 5% / sudo debugfs -R 'stat <201769>' /dev/sdd . . debugfs 1.45.5 (07-Jan-2020) . . Filesystem 1K-blocks Used Available Use% Mounted on /dev/sdd 263174212 10339304 239396752 5% / 16:15:36 \u2714 oldu:(main)~/git/doc/tmp$ sudo debugfs -R 'stat <201769>' /dev/sdd Inode: 201769 Type: regular Mode: 0644 Flags: 0x80000 Generation: 333662723 Version: 0x00000000:00000001 User: 1000 Group: 1000 Project: 0 Size: 0 File ACL: 0 Links: 1 Blockcount: 0 Fragment: Address: 0 Number: 0 Size: 0 ctime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 atime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 mtime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 crtime: 0x624da077:74d33a00 -- Wed Apr 6 16:15:19 2022 Size of extra inode fields: 32 Inode checksum: 0x38e4efd5","title":"Creation date of a file"},{"location":"linux/1-linux-misc/#since-when-a-process-run","text":"ps -p pid -o etime Then use this online tool to calculate time between above result and now.","title":"Since when a process run"},{"location":"linux/1-linux-misc/#how-many-file-descriptors-opened-by-a-process","text":"disk usage find processName's process id (e.g. 28043) number of fd opened for pid max limit of opened fd for pid df -H ps ax | grep processName sudo ls /proc/28043/fd | wc -l sudo grep \"Max open files\" /proc/28043/limits | awk '{ print $4; }'","title":"How many file descriptors opened by a process"},{"location":"linux/1-linux-misc/#copy-filtered-file-list","text":"Copy (for move replace below cp by mv) grep\"ed\" filtered files list to another folder. ls | grep pattern1 | grep pattern2 | ... | xargs cp -t /destinationFolder","title":"Copy filtered file list"},{"location":"linux/1-linux-misc/#add-prefix-to-file-names-list","text":"for f in * ; do mv -- \"$f\" \"PRE_$f\" ; done","title":"Add prefix to file names list"},{"location":"mkdocs/mkdocs/","text":"MkDocs Installation pip install mkdocs check mkdocs --version Initialize current folder mkdocs new . Build documentation mkdocs build Deploy to github First synchronize current folder with corresponding github repository. mkdocs gh-deploy Material for MkDocs (theme) Set up pip install mkdocs-material Configuration Simply add the following lines to mkdocs.yml to enable the theme. theme: name: material Link A double dash section title like below ## Node server project Should be referenced like below to be used in a link: #node-server-project To link this section from another markdown file: [Node server project](otherFile.md#node-server-project) VS Code Extension Usefull markdown editing VS Code extensions: Markdown All in One markdownlint Markdown All in One allow code autocompletion for inserting code block by hitting 'Ctrl+space' shortcut keys.","title":"MkDocs - Misc"},{"location":"mkdocs/mkdocs/#mkdocs","text":"","title":"MkDocs"},{"location":"mkdocs/mkdocs/#installation","text":"pip install mkdocs check mkdocs --version","title":"Installation"},{"location":"mkdocs/mkdocs/#initialize-current-folder","text":"mkdocs new .","title":"Initialize current folder"},{"location":"mkdocs/mkdocs/#build-documentation","text":"mkdocs build","title":"Build documentation"},{"location":"mkdocs/mkdocs/#deploy-to-github","text":"First synchronize current folder with corresponding github repository. mkdocs gh-deploy","title":"Deploy to github"},{"location":"mkdocs/mkdocs/#material-for-mkdocs-theme","text":"","title":"Material for MkDocs (theme)"},{"location":"mkdocs/mkdocs/#set-up","text":"pip install mkdocs-material","title":"Set up"},{"location":"mkdocs/mkdocs/#configuration","text":"Simply add the following lines to mkdocs.yml to enable the theme. theme: name: material","title":"Configuration"},{"location":"mkdocs/mkdocs/#link","text":"A double dash section title like below ## Node server project Should be referenced like below to be used in a link: #node-server-project To link this section from another markdown file: [Node server project](otherFile.md#node-server-project)","title":"Link"},{"location":"mkdocs/mkdocs/#vs-code-extension","text":"Usefull markdown editing VS Code extensions: Markdown All in One markdownlint Markdown All in One allow code autocompletion for inserting code block by hitting 'Ctrl+space' shortcut keys.","title":"VS Code Extension"},{"location":"mongodb/mongodb/","text":"MongoDB Clear console > cls","title":"MongoDB - Misc"},{"location":"mongodb/mongodb/#mongodb","text":"","title":"MongoDB"},{"location":"mongodb/mongodb/#clear-console","text":"> cls","title":"Clear console"},{"location":"redis/1-redis-misc/","text":"Redis - 01 - Misc Basic operations (CRUD) Basic operations from command line interface ( source ). Test redis-cli ping Client redis-cli Create SET mykey \"Hi!\" Read GET mykey Update SET mykey \"Hello\" Delete DEL mykey List all keys keys * Monitor Source redis-cli monitor Quit exit","title":"Redis - 01 - Misc"},{"location":"redis/1-redis-misc/#redis-01-misc","text":"","title":"Redis - 01 - Misc"},{"location":"redis/1-redis-misc/#basic-operations-crud","text":"Basic operations from command line interface ( source ).","title":"Basic operations (CRUD)"},{"location":"redis/1-redis-misc/#test","text":"redis-cli ping","title":"Test"},{"location":"redis/1-redis-misc/#client","text":"redis-cli","title":"Client"},{"location":"redis/1-redis-misc/#create","text":"SET mykey \"Hi!\"","title":"Create"},{"location":"redis/1-redis-misc/#read","text":"GET mykey","title":"Read"},{"location":"redis/1-redis-misc/#update","text":"SET mykey \"Hello\"","title":"Update"},{"location":"redis/1-redis-misc/#delete","text":"DEL mykey","title":"Delete"},{"location":"redis/1-redis-misc/#list-all-keys","text":"keys *","title":"List all keys"},{"location":"redis/1-redis-misc/#monitor","text":"Source redis-cli monitor","title":"Monitor"},{"location":"redis/1-redis-misc/#quit","text":"exit","title":"Quit"},{"location":"vscode/vscode/","text":"VS Code Switch terminals Alt+up/down left/right arrows to switch between split terminals. Code snippet shortcut Ctrl+space Console code block in markdown file: Ctrl+space, then select fenced codeblock, then select console $ ... Move line Alt + Up/down keys Duplicate line If you want to copy the line to the line above itself, press Shift + Alt + Up Arrow Key. If you want to copy the line to the line below itself, press Shift + Alt + Down Arrow Key. Column select Mouse Shift + Alt then click and drag Keyboard Ctrl + Shift + Alt then use arrow keys Comment code Comment code block Ctrl+K+C Uncomment code block Ctrl+K+U Multiple cursors Alt+Click . Each cursor operates independently based on the context it sits in. A common way to add more cursors is with Shift+Alt+Down or Shift+Alt+Up that insert cursors below or above.","title":"VS Code - Misc"},{"location":"vscode/vscode/#vs-code","text":"","title":"VS Code"},{"location":"vscode/vscode/#switch-terminals","text":"Alt+up/down left/right arrows to switch between split terminals.","title":"Switch terminals"},{"location":"vscode/vscode/#code-snippet-shortcut","text":"Ctrl+space Console code block in markdown file: Ctrl+space, then select fenced codeblock, then select console $ ...","title":"Code snippet shortcut"},{"location":"vscode/vscode/#move-line","text":"Alt + Up/down keys","title":"Move line"},{"location":"vscode/vscode/#duplicate-line","text":"If you want to copy the line to the line above itself, press Shift + Alt + Up Arrow Key. If you want to copy the line to the line below itself, press Shift + Alt + Down Arrow Key.","title":"Duplicate line"},{"location":"vscode/vscode/#column-select","text":"Mouse Shift + Alt then click and drag Keyboard Ctrl + Shift + Alt then use arrow keys","title":"Column select"},{"location":"vscode/vscode/#comment-code","text":"Comment code block Ctrl+K+C Uncomment code block Ctrl+K+U","title":"Comment code"},{"location":"vscode/vscode/#multiple-cursors","text":"Alt+Click . Each cursor operates independently based on the context it sits in. A common way to add more cursors is with Shift+Alt+Down or Shift+Alt+Up that insert cursors below or above.","title":"Multiple cursors"},{"location":"windows/windows/","text":"Windows find process that uses a port Open CMD prompt as admin C:\\> netstat -ano -p tcp | find \"50307\" Last column shows the PID that uses the port C:\\> netstat --help -a Displays all connections and listening ports. -n Displays addresses and port numbers in numerical form. -o Displays the owning process ID associated with each connection. In PowerShell C:\\> Get-Process -Id (Get-NetTCPConnection -LocalPort 50307).OwningProcess grep equivalent find \"50307\" or findstr 50307 C:\\> netstat -ano -p tcp | findstr 50307 kill process C:\\> taskkill /F /PID pid_number","title":"Windows - Misc"},{"location":"windows/windows/#windows","text":"","title":"Windows"},{"location":"windows/windows/#find-process-that-uses-a-port","text":"Open CMD prompt as admin C:\\> netstat -ano -p tcp | find \"50307\" Last column shows the PID that uses the port C:\\> netstat --help -a Displays all connections and listening ports. -n Displays addresses and port numbers in numerical form. -o Displays the owning process ID associated with each connection. In PowerShell C:\\> Get-Process -Id (Get-NetTCPConnection -LocalPort 50307).OwningProcess","title":"find process that uses a port"},{"location":"windows/windows/#grep-equivalent","text":"find \"50307\" or findstr 50307 C:\\> netstat -ano -p tcp | findstr 50307","title":"grep equivalent"},{"location":"windows/windows/#kill-process","text":"C:\\> taskkill /F /PID pid_number","title":"kill process"}]}