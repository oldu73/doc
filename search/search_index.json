{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to doc Hello, doc ;)","title":"Home"},{"location":"#welcome-to-doc","text":"Hello, doc ;)","title":"Welcome to doc"},{"location":"docker/1-docker-misc/","text":"Docker - 1 - Misc $ = console $c = console inside container","title":"Docker - 01 - Misc"},{"location":"docker/1-docker-misc/#docker-1-misc","text":"$ = console $c = console inside container","title":"Docker - 1 - Misc"},{"location":"docker/10-compose-services/","text":"Compose - 10 - Services Docker Compose - Services Chapter y Sub chapter y.1 ...","title":"Compose - 10 - Services"},{"location":"docker/10-compose-services/#compose-10-services","text":"Docker Compose - Services","title":"Compose - 10 - Services"},{"location":"docker/10-compose-services/#chapter-y","text":"","title":"Chapter y"},{"location":"docker/10-compose-services/#sub-chapter-y1","text":"...","title":"Sub chapter y.1"},{"location":"docker/11-compose-production/","text":"Compose - 11 - Production Docker Compose - Production Chapter y Sub chapter y.1 ...","title":"Compose - 11 - Production"},{"location":"docker/11-compose-production/#compose-11-production","text":"Docker Compose - Production","title":"Compose - 11 - Production"},{"location":"docker/11-compose-production/#chapter-y","text":"","title":"Chapter y"},{"location":"docker/11-compose-production/#sub-chapter-y1","text":"...","title":"Sub chapter y.1"},{"location":"docker/2-docker-basis/","text":"Docker - 2 - Basis Node Command to launch node with app.js in folder app CMD [\"node\", \"app/app.js\"] Then from terminal, build command with -t argument to name:tag image . to mention path of Dockerfile in current directory: $ docker build -t node-test-001:latest . To check: $ docker images (or $ docker image ls) To test: $ docker run node-test-001 Hello, world! To auto delete container after execution, use \u2013rm option: $ docker run --rm node-test-001 Hello, world! Check if node is installed on host machine: $ node --version v14.16.1 Test app.js on host machine (if node is installed): $ node app.js Hello, world! VS Code VS Code install Microsoft Docker extension Docker file in short My image -> Docker file =: Base image Modification Action Add Alpine package Add/del Alpine package A base image (e.g. Alpine) is not based on any other image. Add or del package in Alpine $c apk update $c apk add grep $c apk del grep Running container Running container as a running process To demonstrate running container is just a running process on host machine $ docker run -d redis In contrary of a virtual machine (VM) a container is \"just\" a running process sharing Linux kernel on host machine. SRC: - https://stackoverflow.com/questions/64787125/why-doesnt-htop-show-my-docker-processes-using-wsl2 To see running process on WSL use command prompt (would be \"$ sudo ps -ef | grep redis\" on a Linux machine): C:\\> wsl -d docker-desktop top (or C:\\> wsl -d docker-desktop ps -ef) If you want htop, you need to install it first: C:\\> wsl -d docker-desktop apk update C:\\> wsl -d docker-desktop apk add htop ... 0% redis-server *:6379 To kill a process on host machine, WSL: C:\\> wsl -d docker-desktop killall redis-server To kill a process on host machine, Linux: $ sudo killall redis-server Running: C:\\> wsl -d docker-desktop htop See that container isn't running anymore: $ docker container ls Disk usage Show docker disk usage $ docker system df Show detailed information on space usage, -v, --verbose docker system df -v Consumed resource to see live consuming resources of running containers: $ docker container stats Inspect to inspect all configuration of a container $ docker container inspect alpinetest001 Running process Show running process in a container from host $ docker container top alpinetest001 See the difference from inside the container $ docker attach alpine001 update $c apk update add bash $c apk add bash test bash $c bash $c echo $0 bash ctrl+p+q $ docker exec -it alpinetest001 bash if ps not present, install it with: $c apk update && apk add procps then: $c ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 16:15 pts/0 00:00:00 /bin/sh root 16 1 0 16:27 pts/0 00:00:00 bash root 17 0 0 16:28 pts/1 00:00:00 bash root 31 17 0 16:33 pts/1 00:00:00 ps -ef sh and bash does not have parent process ID (PPID) = '0' because of container isolation, container does not see running processes of host machine neither the ones belonging to other containers. Modified file Show modified file in a container: A = added, D = deleted, C = modified $ docker container diff alpinetest001 A /test A /test/test1.txt A /test/test2.txt C /root A /root/.ash_history Copy file copy file from host to container, docker cp path container:path docker cp test1.txt alpinetest001:test copy file from container to host, docker cp container:path path docker cp alpinetest001:test/test2.txt . Execute command in container Execute a command in a container without using terminal $ docker container exec alpine001 mkdir testdir $ docker container exec alpine001 touch /testdir/hello.txt other e.g. $ docker run -d --name redis001 redis $ docker exec -it redis001 redis-cli redis command: set cle 42 get cle exit Get shell in container Get a shell, in a no matter which running container it is: $ docker exec -it redis001 bash $c echo $0 bash if bash not installed in container (e.g. with alpine) you may use sh instead: (if both presents, both works (e.g. redis) $ docker exec -it redis001 sh $c echo $0 sh $ docker run -it -d --name alpine001 alpine $ docker exec -it alpine001 bash OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \"bash\": executable file not found in $PATH: unknown $ docker exec -it alpine001 sh $c echo $0 sh Pause/unpause a container $ docker container start -ai alpine001 $ docker container pause alpine001 $ docker container unpause alpine001 Rename a container rename a container named \"beautiful_leakey\" $ docker container rename beautiful_leakey alpine001 not allowed to rename image Postgres with environnement variable $ docker run -d --name mongo mongo $ docker run -d --name redis redis $ docker run -d --name postgres postgres $ docker logs postgres Error: ... $ docker container rm postgres $ docker container run --name postgres -d -e POSTGRES_HOST_AUTH_METHOD=trust postgres Stop container Stop all running container at once docker stop $(docker ps -aq) Suppress all !Suppress all not used (stopped container(s) and not used for the rest)! $ docker system prune -a Remove image $ docker image rm NAME_OR_ID remove unused images (dangling = image is not tagged and no other image depends on it) $ docker image prune -a Remove container try to remove a running container Launch a background test named redis container with: $ docker run --name test -d redis then try to remove it with: $ docker container rm test Error - Stop the container before attempting removal or force remove Force remove running container: $ docker container rm -f test $ docker run --name test1 -d redis $ docker run --name test2 -d redis $ docker run --name test3 -d redis $ docker container rm -f test1 test2 test3 remove all stopped container $ docker container prune Image, images $ docker images $ docker image ls redis Help to get help, simply type: $ docker help on a command: $ docker ps --help Redis $ docker run redis $ docker run -d redis Alpine $ docker run alpine -i, interactive mode $ docker run -i alpine $c ls . . dev etc home . . . exit -t, terminal -> prompt $ docker run -it alpine (= docker run -it alpine sh) $c echo $0 // check which shell (/bin/sh) $c apk update $c apk add bash $c bash $c echo $0 // check which shell (bash) start in foreground mode $ docker run alpine ping google.ch $ docker run alpine echo hello start in background mode (-d = detach (!= daemon)) $ docker run -d alpine ping google.fr 3593... docker logs 3593... $ docker logs 8e86... --follow Available image show available image(s) $ docker images None running container check none running container with (-a show all containers (default shows just running)): $ docker container ls -a Ubuntu $ docker run -it ubuntu bash $c cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"20.04.3 LTS (Focal Fossa)\" ... to exit container and stop it $c ctrl + d then to start/stop it again, e.g container name is 'trusting_yalow' $ docker start trusting_yalow $ docker stop trusting_yalow then to bash into it $ docker attach trusting_yalow to detach from a docker container without stopping it $c ctrl + p + q Hello, world! $ docker run hello-world Info $ docker info","title":"Docker - 02 - Basis"},{"location":"docker/2-docker-basis/#docker-2-basis","text":"","title":"Docker - 2 - Basis"},{"location":"docker/2-docker-basis/#node","text":"Command to launch node with app.js in folder app CMD [\"node\", \"app/app.js\"] Then from terminal, build command with -t argument to name:tag image . to mention path of Dockerfile in current directory: $ docker build -t node-test-001:latest . To check: $ docker images (or $ docker image ls) To test: $ docker run node-test-001 Hello, world! To auto delete container after execution, use \u2013rm option: $ docker run --rm node-test-001 Hello, world! Check if node is installed on host machine: $ node --version v14.16.1 Test app.js on host machine (if node is installed): $ node app.js Hello, world!","title":"Node"},{"location":"docker/2-docker-basis/#vs-code","text":"VS Code install Microsoft Docker extension","title":"VS Code"},{"location":"docker/2-docker-basis/#docker-file-in-short","text":"My image -> Docker file =: Base image Modification Action","title":"Docker file in short"},{"location":"docker/2-docker-basis/#add-alpine-package","text":"Add/del Alpine package A base image (e.g. Alpine) is not based on any other image. Add or del package in Alpine $c apk update $c apk add grep $c apk del grep","title":"Add Alpine package"},{"location":"docker/2-docker-basis/#running-container","text":"Running container as a running process To demonstrate running container is just a running process on host machine $ docker run -d redis In contrary of a virtual machine (VM) a container is \"just\" a running process sharing Linux kernel on host machine. SRC: - https://stackoverflow.com/questions/64787125/why-doesnt-htop-show-my-docker-processes-using-wsl2 To see running process on WSL use command prompt (would be \"$ sudo ps -ef | grep redis\" on a Linux machine): C:\\> wsl -d docker-desktop top (or C:\\> wsl -d docker-desktop ps -ef) If you want htop, you need to install it first: C:\\> wsl -d docker-desktop apk update C:\\> wsl -d docker-desktop apk add htop ... 0% redis-server *:6379 To kill a process on host machine, WSL: C:\\> wsl -d docker-desktop killall redis-server To kill a process on host machine, Linux: $ sudo killall redis-server Running: C:\\> wsl -d docker-desktop htop See that container isn't running anymore: $ docker container ls","title":"Running container"},{"location":"docker/2-docker-basis/#disk-usage","text":"Show docker disk usage $ docker system df Show detailed information on space usage, -v, --verbose docker system df -v","title":"Disk usage"},{"location":"docker/2-docker-basis/#consumed-resource","text":"to see live consuming resources of running containers: $ docker container stats","title":"Consumed resource"},{"location":"docker/2-docker-basis/#inspect","text":"to inspect all configuration of a container $ docker container inspect alpinetest001","title":"Inspect"},{"location":"docker/2-docker-basis/#running-process","text":"Show running process in a container from host $ docker container top alpinetest001 See the difference from inside the container $ docker attach alpine001 update $c apk update add bash $c apk add bash test bash $c bash $c echo $0 bash ctrl+p+q $ docker exec -it alpinetest001 bash if ps not present, install it with: $c apk update && apk add procps then: $c ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 16:15 pts/0 00:00:00 /bin/sh root 16 1 0 16:27 pts/0 00:00:00 bash root 17 0 0 16:28 pts/1 00:00:00 bash root 31 17 0 16:33 pts/1 00:00:00 ps -ef sh and bash does not have parent process ID (PPID) = '0' because of container isolation, container does not see running processes of host machine neither the ones belonging to other containers.","title":"Running process"},{"location":"docker/2-docker-basis/#modified-file","text":"Show modified file in a container: A = added, D = deleted, C = modified $ docker container diff alpinetest001 A /test A /test/test1.txt A /test/test2.txt C /root A /root/.ash_history","title":"Modified file"},{"location":"docker/2-docker-basis/#copy-file","text":"copy file from host to container, docker cp path container:path docker cp test1.txt alpinetest001:test copy file from container to host, docker cp container:path path docker cp alpinetest001:test/test2.txt .","title":"Copy file"},{"location":"docker/2-docker-basis/#execute-command-in-container","text":"Execute a command in a container without using terminal $ docker container exec alpine001 mkdir testdir $ docker container exec alpine001 touch /testdir/hello.txt other e.g. $ docker run -d --name redis001 redis $ docker exec -it redis001 redis-cli redis command: set cle 42 get cle exit","title":"Execute command in container"},{"location":"docker/2-docker-basis/#get-shell-in-container","text":"Get a shell, in a no matter which running container it is: $ docker exec -it redis001 bash $c echo $0 bash if bash not installed in container (e.g. with alpine) you may use sh instead: (if both presents, both works (e.g. redis) $ docker exec -it redis001 sh $c echo $0 sh $ docker run -it -d --name alpine001 alpine $ docker exec -it alpine001 bash OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \"bash\": executable file not found in $PATH: unknown $ docker exec -it alpine001 sh $c echo $0 sh","title":"Get shell in container"},{"location":"docker/2-docker-basis/#pauseunpause-a-container","text":"$ docker container start -ai alpine001 $ docker container pause alpine001 $ docker container unpause alpine001","title":"Pause/unpause a container"},{"location":"docker/2-docker-basis/#rename-a-container","text":"rename a container named \"beautiful_leakey\" $ docker container rename beautiful_leakey alpine001 not allowed to rename image","title":"Rename a container"},{"location":"docker/2-docker-basis/#postgres-with-environnement-variable","text":"$ docker run -d --name mongo mongo $ docker run -d --name redis redis $ docker run -d --name postgres postgres $ docker logs postgres Error: ... $ docker container rm postgres $ docker container run --name postgres -d -e POSTGRES_HOST_AUTH_METHOD=trust postgres","title":"Postgres with environnement variable"},{"location":"docker/2-docker-basis/#stop-container","text":"Stop all running container at once docker stop $(docker ps -aq)","title":"Stop container"},{"location":"docker/2-docker-basis/#suppress-all","text":"!Suppress all not used (stopped container(s) and not used for the rest)! $ docker system prune -a","title":"Suppress all"},{"location":"docker/2-docker-basis/#remove-image","text":"$ docker image rm NAME_OR_ID remove unused images (dangling = image is not tagged and no other image depends on it) $ docker image prune -a","title":"Remove image"},{"location":"docker/2-docker-basis/#remove-container","text":"try to remove a running container Launch a background test named redis container with: $ docker run --name test -d redis then try to remove it with: $ docker container rm test Error - Stop the container before attempting removal or force remove Force remove running container: $ docker container rm -f test $ docker run --name test1 -d redis $ docker run --name test2 -d redis $ docker run --name test3 -d redis $ docker container rm -f test1 test2 test3 remove all stopped container $ docker container prune","title":"Remove container"},{"location":"docker/2-docker-basis/#image-images","text":"$ docker images $ docker image ls redis","title":"Image, images"},{"location":"docker/2-docker-basis/#help","text":"to get help, simply type: $ docker help on a command: $ docker ps --help","title":"Help"},{"location":"docker/2-docker-basis/#redis","text":"$ docker run redis $ docker run -d redis","title":"Redis"},{"location":"docker/2-docker-basis/#alpine","text":"$ docker run alpine -i, interactive mode $ docker run -i alpine $c ls . . dev etc home . . . exit -t, terminal -> prompt $ docker run -it alpine (= docker run -it alpine sh) $c echo $0 // check which shell (/bin/sh) $c apk update $c apk add bash $c bash $c echo $0 // check which shell (bash) start in foreground mode $ docker run alpine ping google.ch $ docker run alpine echo hello start in background mode (-d = detach (!= daemon)) $ docker run -d alpine ping google.fr 3593... docker logs 3593... $ docker logs 8e86... --follow","title":"Alpine"},{"location":"docker/2-docker-basis/#available-image","text":"show available image(s) $ docker images","title":"Available image"},{"location":"docker/2-docker-basis/#none-running-container","text":"check none running container with (-a show all containers (default shows just running)): $ docker container ls -a","title":"None running container"},{"location":"docker/2-docker-basis/#ubuntu","text":"$ docker run -it ubuntu bash $c cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"20.04.3 LTS (Focal Fossa)\" ... to exit container and stop it $c ctrl + d then to start/stop it again, e.g container name is 'trusting_yalow' $ docker start trusting_yalow $ docker stop trusting_yalow then to bash into it $ docker attach trusting_yalow to detach from a docker container without stopping it $c ctrl + p + q","title":"Ubuntu"},{"location":"docker/2-docker-basis/#hello-world","text":"$ docker run hello-world","title":"Hello, world!"},{"location":"docker/2-docker-basis/#info","text":"$ docker info","title":"Info"},{"location":"docker/3-docker-dockerfile/","text":"Docker - 3 - Docker File Image Variants $ docker pull node:slim node:latest = 992MB VS node:slim = 242MB tag tag to tag image after build $ docker image tag mynode:latest mynode:1.0 history Show the history of an image $ docker history mynode:latest IMAGE CREATED CREATED BY SIZE COMMENT 1a8f184ef896 8 minutes ago sh 42.4MB 14119a10abf4 2 months ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 2 months ago /bin/sh -c #(nop) ADD file:aad4290d27580cc1a\u2026 5.6MB logs $ docker container logs redis-4.0-001 -f to follow -t timestamp COMMIT Snapshot a container to image $ docker run -it alpine sh # mkdir app open a new terminal to copy app.js \"manually\" to app folder $ docker container cp app.js ed6:/app/ then from inside container install node.js $c apk add --update nodejs then quit container and from host terminal $ docker container commit -c 'CMD [\"node\", \"/app/app.js\"]' ed6 mynode $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode latest 1a8f184ef896 6 seconds ago 48MB .. $ docker run --rm mynode hello node-test-010 LABEL LABEL to add meta information LABEL MAINTAINER=oldu73@gmail.com LABEL version=1.0 $ docker build -t node10 . $ docker image inspect node10:latest | less /oldu .. \"MAINTAINER\": \"oldu73@gmail.com\", \"version\": \"1.0\" } .. ENV key value Usable in container, available as environment variable: ENV environment=production $ docker build -t node10 . $ docker run -it node10 sh /app $c env HOSTNAME=ac68969910b7 SHLVL=1 HOME=/root environment=production TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app ARG Argument available at build time only: ARG folder ARG file then WORKDIR $folder COPY $file . then $ docker build --build-arg folder=/app --build-arg file=app.js -t node-test-008 . then if you try to retriev ARGs by typing env inside the container you do not retrieve it because they are available only at build time: $ docker run --rm -it node-test-008 sh /app # env HOSTNAME=22cc31c49889 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app You may also put a default value: ARG folder=/app then $ docker build --build-arg file=app.js -t node-test-008 . Override entry point You can still override the entry point with the --entrypoint option: $ docker run --rm --entrypoint=\"echo\" node:test \"Hi, earth ;)\" or $ docker run -it --entrypoint=\"/bin/sh\" node:test Docker default entry point By default, Docker has a default entry point which is \"/bin/sh -c\" but does not have a default command. $ man sh -> /-c -c Read commands from the command_string operand instead of from the standard input. Special parameter 0 will be set from the command_name operand and the positional parameters ($1, $2, etc.) set from the remaining argument operands. ENTRYPOINT and CMD May have ENTRYPOINT and CMD: ENTRYPOINT [\"echo\"] CMD [\"hello\"] $ docker run --rm node:test hello then you may override hello in run parameter: $ docker run --rm node:test world world exec form [] exec form -> recommended .. shell form, like you would type the command in a terminal ENTRYPOINT instead CMD ENTRYPOINT instead CMD avoid availability for end user to replace Dockerfile CMD by typing one at the end of run terminal command: ENTRYPOINT [\"node\", \"app.js\"] in Dockerfile, then: $ docker run --rm node:test Bonjour or $ docker run --rm node:test echo test Bonjour same same ;-), echo test at the end is not taking under consideration Command at the end of run Typing a command at the end of the run command replace the one in Dockerfile: $ docker run --rm node:test echo test test even if \"CMD [\"node\", \"app.js\"]\" in Dockerfile Remove dangling images Remove dangling ( ) images: $ docker image prune For removing dangling and ununsed images: $ docker image prune -a Docker build no output Docker build not showing any output from commands(Dockerfile RUN): Dockerfile .. RUN echo hello Don't show anything in console at build. Use legacy mode by adding 'DOCKER_BUILDKIT=0' in front of docker build: $ DOCKER_BUILDKIT=0 docker build -t test:latest . .. Step 2/2 : RUN echo hello ---> Running in 3d9c96daa522 hello or (new fashion) with \"--progress=plain --no-cache\" after build command: $ docker build --progress=plain --no-cache -t node-test-007:latest . [3/5] RUN echo \"Hello, world!\" sha256:54040767d950b92027e2e377a0938fd42b89a34fa5d76e3ce281deacda0f1959 0.281 Hello, world! DONE 0.3s List only container names To list only names of all containers: $ docker ps -a --format='{{.Names}}' ENV 'ENV', environment variable: Dockerfile: - Base image - Test environment variable FROM alpine ENV DIR=/app WORKDIR ${DIR}/back then.. $ docker build -t node-test-006:latest . then.. $ docker run -it node-test-006 sh $c pwd /app/back RUN RUN exist in 'exec' and 'shell' mode (which is 'sh' by default). exec: RUN [\"/bin/bash\", \"-c\", \"echo Bonjour !\"] shell: RUN echo \"Bonjour !\" CMD Remove CMD line to test container in interactive mode, then build: $ docker build -t node-test-005:test . Launch a container in interactive mode with sh as shell. Don't forget to mention image tag after ':' as long as it ain't 'latest', and to mention the shell at the end, 'sh': $ docker run -it node-test-005:test sh /app $c As we can see, we are directly in 'app' folder. And by typing 'echo $0' to check shell is indeed, 'sh': $c echo $0 sh And check 'node' version: $c node --version v14.18.1 And test 'app.js' (in app.js -> console.log('Hi test 005');): $c node app.js Hi test 005 WORKDIR WORKDIR define working directory in image: WORKDIR /app Then, for COPY command, no need to specify destination directory: COPY ./app.js . Also for CMD: CMD [\"node\", \"app.js\"] WORKDIR can be changed during the Dockerfile by being filled in again. WORKDIR can create folders if they do not exist (this saves us a mkdir). FROM Only one FROM command by Dockerfile VS Code Dockerfile command VS Code, in a Dockerfile, hit ctrl+space to get a list of available commands. Shortcut available due to Docker Microsoft extension installed in VS Code. ADD source destination ADD source destination, similar to COPY but from URL or compressed file. If it's a compressed file it will be automatically uncompressed. Copy context Dockerfile context is current folder. Could not COPY file from parent folder. Remove image with pattern Remove all images that contain a pattern: $ docker image rm $(docker images --format \"{{.Repository}}\" | grep node-test-00) Optimize cache Optimizing cache. Only the RUN, COPY, and ADD instructions create new layers and increase the size of an image. It is therefore necessary to avoid multiplying the RUN commands, and try to group all the necessary commands in a single RUN instruction (multi-line separator '\\'): FROM ubuntu ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update && apt-get install -y \\ git \\ nodejs \\ && rm -rf /var/lib/apt/lists/* It's recommended to put one installation by line, alphabetically sorted. !! It is mandatory to put apt-get update and apt-get install in the same RUN statement. Otherwise you will have serious cache problems.!! For images using Ubuntu or Debian, it is recommended to remove /var/lib/apt/ lists which contains the APT cache with all available packages in order to reduce the size of the image. ENV DEBIAN_FRONTEND=noninteractive allows us to specify to the Debian Package Manager (APT) that we are in a non-interactive environment for the installation. This avoids the prompts requested by some programs during installation (eg Git). Invalidate cache !Important! Invalidate cache at build. If you have following instruction in Dockerfile it will be run only once at first build then cached: RUN apt update && apt dist-upgrade -y To not use a cache, you have to do: docker build --no-cache -t test . Inspect Go template docker inspect with Go template for format parameter. e.g. to retrieve CMD: $ docker inspect --format='{{.Config.Cmd}}' node-test-001 [node app/app.js] Show the history of an image: $ docker image history node-test-001 Image size node image = 900 MB/3 min VS alpine + node install = 50 MB/30 sec => ??? First build of node based image takes around 3 minutes. Intermediate steps are cached by Docker. Second build of node based image takes now only around 3 seconds. Dockerfile build image Docker file, steps to build an image. Instructions: - FROM // pull image from docker hub \\ = layer - RUN // add node / new image/running intermediate container - COPY / = layer new image/running intermediate container - CMD constructed image resulting from the different images, layers, and intermediate containers You can't run commands in an image, so you need intermediate container. Dockerfile context !! Warning !! Create a Dockerfile then build image in a dedicated folder for your application Otherwise, all files/folders contained in where you build image will be sent to the daemon at build time as the context. It is for this reason that you must create the Dockerfile in the folder of your application, or here to test, in a separate folder. If you create your Dockerfile directly in the root / directory, your entire hard drive is sent as context to the daemon! APK apk = Alpine Package Management It is the equivalent of APT for Debian distributions and therefore in particular for Ubuntu apk add --update actually allows you to do apk update first, then apk add. Debian equivalent of: apt update && apt install && lets you do something based on whether the previous command completed successfully - that's why you tend to see it chained as do_something && do_something_else_that_depended_on_something. Furthermore, you also have || which is the logical or, and also ; which is just a separator which doesn't care what happen to the command before. Dockerfile Create a new folder docker-test. Open it with VS Code. In this example we gonna crate a node image (based on Alpine, not on official node image) to simply test console log in a js file. Create a new file named, with VS Code, 'app.js' and type in it: console.log('Hello, world!'); Then, create a new file, in folder, with VS Code, named: Dockerfile Base image Install node Copy js file from local folder to container. If folder does not exist, it will be created. Type following commands in newly created Dockerfile file (exactly respect the case and do not add any extensions): FROM alpine RUN apk add --update nodejs COPY ./app.js /app/","title":"Docker - 03 - Docker File"},{"location":"docker/3-docker-dockerfile/#docker-3-docker-file","text":"","title":"Docker - 3 - Docker File"},{"location":"docker/3-docker-dockerfile/#image-variants","text":"$ docker pull node:slim node:latest = 992MB VS node:slim = 242MB","title":"Image Variants"},{"location":"docker/3-docker-dockerfile/#tag","text":"tag to tag image after build $ docker image tag mynode:latest mynode:1.0","title":"tag"},{"location":"docker/3-docker-dockerfile/#history","text":"Show the history of an image $ docker history mynode:latest IMAGE CREATED CREATED BY SIZE COMMENT 1a8f184ef896 8 minutes ago sh 42.4MB 14119a10abf4 2 months ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 2 months ago /bin/sh -c #(nop) ADD file:aad4290d27580cc1a\u2026 5.6MB","title":"history"},{"location":"docker/3-docker-dockerfile/#logs","text":"$ docker container logs redis-4.0-001 -f to follow -t timestamp","title":"logs"},{"location":"docker/3-docker-dockerfile/#commit","text":"Snapshot a container to image $ docker run -it alpine sh # mkdir app open a new terminal to copy app.js \"manually\" to app folder $ docker container cp app.js ed6:/app/ then from inside container install node.js $c apk add --update nodejs then quit container and from host terminal $ docker container commit -c 'CMD [\"node\", \"/app/app.js\"]' ed6 mynode $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode latest 1a8f184ef896 6 seconds ago 48MB .. $ docker run --rm mynode hello node-test-010","title":"COMMIT"},{"location":"docker/3-docker-dockerfile/#label","text":"LABEL to add meta information LABEL MAINTAINER=oldu73@gmail.com LABEL version=1.0 $ docker build -t node10 . $ docker image inspect node10:latest | less /oldu .. \"MAINTAINER\": \"oldu73@gmail.com\", \"version\": \"1.0\" } ..","title":"LABEL"},{"location":"docker/3-docker-dockerfile/#env","text":"key value Usable in container, available as environment variable: ENV environment=production $ docker build -t node10 . $ docker run -it node10 sh /app $c env HOSTNAME=ac68969910b7 SHLVL=1 HOME=/root environment=production TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app","title":"ENV"},{"location":"docker/3-docker-dockerfile/#arg","text":"Argument available at build time only: ARG folder ARG file then WORKDIR $folder COPY $file . then $ docker build --build-arg folder=/app --build-arg file=app.js -t node-test-008 . then if you try to retriev ARGs by typing env inside the container you do not retrieve it because they are available only at build time: $ docker run --rm -it node-test-008 sh /app # env HOSTNAME=22cc31c49889 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app You may also put a default value: ARG folder=/app then $ docker build --build-arg file=app.js -t node-test-008 .","title":"ARG"},{"location":"docker/3-docker-dockerfile/#override-entry-point","text":"You can still override the entry point with the --entrypoint option: $ docker run --rm --entrypoint=\"echo\" node:test \"Hi, earth ;)\" or $ docker run -it --entrypoint=\"/bin/sh\" node:test","title":"Override entry point"},{"location":"docker/3-docker-dockerfile/#docker-default-entry-point","text":"By default, Docker has a default entry point which is \"/bin/sh -c\" but does not have a default command. $ man sh -> /-c -c Read commands from the command_string operand instead of from the standard input. Special parameter 0 will be set from the command_name operand and the positional parameters ($1, $2, etc.) set from the remaining argument operands.","title":"Docker default entry point"},{"location":"docker/3-docker-dockerfile/#entrypoint-and-cmd","text":"May have ENTRYPOINT and CMD: ENTRYPOINT [\"echo\"] CMD [\"hello\"] $ docker run --rm node:test hello then you may override hello in run parameter: $ docker run --rm node:test world world","title":"ENTRYPOINT and CMD"},{"location":"docker/3-docker-dockerfile/#exec-form","text":"[] exec form -> recommended .. shell form, like you would type the command in a terminal","title":"exec form"},{"location":"docker/3-docker-dockerfile/#entrypoint-instead-cmd","text":"ENTRYPOINT instead CMD avoid availability for end user to replace Dockerfile CMD by typing one at the end of run terminal command: ENTRYPOINT [\"node\", \"app.js\"] in Dockerfile, then: $ docker run --rm node:test Bonjour or $ docker run --rm node:test echo test Bonjour same same ;-), echo test at the end is not taking under consideration","title":"ENTRYPOINT instead CMD"},{"location":"docker/3-docker-dockerfile/#command-at-the-end-of-run","text":"Typing a command at the end of the run command replace the one in Dockerfile: $ docker run --rm node:test echo test test even if \"CMD [\"node\", \"app.js\"]\" in Dockerfile","title":"Command at the end of run"},{"location":"docker/3-docker-dockerfile/#remove-dangling-images","text":"Remove dangling ( ) images: $ docker image prune For removing dangling and ununsed images: $ docker image prune -a","title":"Remove dangling images"},{"location":"docker/3-docker-dockerfile/#docker-build-no-output","text":"Docker build not showing any output from commands(Dockerfile RUN): Dockerfile .. RUN echo hello Don't show anything in console at build. Use legacy mode by adding 'DOCKER_BUILDKIT=0' in front of docker build: $ DOCKER_BUILDKIT=0 docker build -t test:latest . .. Step 2/2 : RUN echo hello ---> Running in 3d9c96daa522 hello or (new fashion) with \"--progress=plain --no-cache\" after build command: $ docker build --progress=plain --no-cache -t node-test-007:latest . [3/5] RUN echo \"Hello, world!\" sha256:54040767d950b92027e2e377a0938fd42b89a34fa5d76e3ce281deacda0f1959 0.281 Hello, world! DONE 0.3s","title":"Docker build no output"},{"location":"docker/3-docker-dockerfile/#list-only-container-names","text":"To list only names of all containers: $ docker ps -a --format='{{.Names}}'","title":"List only container names"},{"location":"docker/3-docker-dockerfile/#env_1","text":"'ENV', environment variable: Dockerfile: - Base image - Test environment variable FROM alpine ENV DIR=/app WORKDIR ${DIR}/back then.. $ docker build -t node-test-006:latest . then.. $ docker run -it node-test-006 sh $c pwd /app/back","title":"ENV"},{"location":"docker/3-docker-dockerfile/#run","text":"RUN exist in 'exec' and 'shell' mode (which is 'sh' by default). exec: RUN [\"/bin/bash\", \"-c\", \"echo Bonjour !\"] shell: RUN echo \"Bonjour !\"","title":"RUN"},{"location":"docker/3-docker-dockerfile/#cmd","text":"Remove CMD line to test container in interactive mode, then build: $ docker build -t node-test-005:test . Launch a container in interactive mode with sh as shell. Don't forget to mention image tag after ':' as long as it ain't 'latest', and to mention the shell at the end, 'sh': $ docker run -it node-test-005:test sh /app $c As we can see, we are directly in 'app' folder. And by typing 'echo $0' to check shell is indeed, 'sh': $c echo $0 sh And check 'node' version: $c node --version v14.18.1 And test 'app.js' (in app.js -> console.log('Hi test 005');): $c node app.js Hi test 005","title":"CMD"},{"location":"docker/3-docker-dockerfile/#workdir","text":"WORKDIR define working directory in image: WORKDIR /app Then, for COPY command, no need to specify destination directory: COPY ./app.js . Also for CMD: CMD [\"node\", \"app.js\"] WORKDIR can be changed during the Dockerfile by being filled in again. WORKDIR can create folders if they do not exist (this saves us a mkdir).","title":"WORKDIR"},{"location":"docker/3-docker-dockerfile/#from","text":"Only one FROM command by Dockerfile","title":"FROM"},{"location":"docker/3-docker-dockerfile/#vs-code-dockerfile-command","text":"VS Code, in a Dockerfile, hit ctrl+space to get a list of available commands. Shortcut available due to Docker Microsoft extension installed in VS Code.","title":"VS Code Dockerfile command"},{"location":"docker/3-docker-dockerfile/#add-source-destination","text":"ADD source destination, similar to COPY but from URL or compressed file. If it's a compressed file it will be automatically uncompressed.","title":"ADD source destination"},{"location":"docker/3-docker-dockerfile/#copy-context","text":"Dockerfile context is current folder. Could not COPY file from parent folder.","title":"Copy context"},{"location":"docker/3-docker-dockerfile/#remove-image-with-pattern","text":"Remove all images that contain a pattern: $ docker image rm $(docker images --format \"{{.Repository}}\" | grep node-test-00)","title":"Remove image with pattern"},{"location":"docker/3-docker-dockerfile/#optimize-cache","text":"Optimizing cache. Only the RUN, COPY, and ADD instructions create new layers and increase the size of an image. It is therefore necessary to avoid multiplying the RUN commands, and try to group all the necessary commands in a single RUN instruction (multi-line separator '\\'): FROM ubuntu ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update && apt-get install -y \\ git \\ nodejs \\ && rm -rf /var/lib/apt/lists/* It's recommended to put one installation by line, alphabetically sorted. !! It is mandatory to put apt-get update and apt-get install in the same RUN statement. Otherwise you will have serious cache problems.!! For images using Ubuntu or Debian, it is recommended to remove /var/lib/apt/ lists which contains the APT cache with all available packages in order to reduce the size of the image. ENV DEBIAN_FRONTEND=noninteractive allows us to specify to the Debian Package Manager (APT) that we are in a non-interactive environment for the installation. This avoids the prompts requested by some programs during installation (eg Git).","title":"Optimize cache"},{"location":"docker/3-docker-dockerfile/#invalidate-cache","text":"!Important! Invalidate cache at build. If you have following instruction in Dockerfile it will be run only once at first build then cached: RUN apt update && apt dist-upgrade -y To not use a cache, you have to do: docker build --no-cache -t test .","title":"Invalidate cache"},{"location":"docker/3-docker-dockerfile/#inspect-go-template","text":"docker inspect with Go template for format parameter. e.g. to retrieve CMD: $ docker inspect --format='{{.Config.Cmd}}' node-test-001 [node app/app.js]","title":"Inspect Go template"},{"location":"docker/3-docker-dockerfile/#_1","text":"Show the history of an image: $ docker image history node-test-001","title":""},{"location":"docker/3-docker-dockerfile/#image-size","text":"node image = 900 MB/3 min VS alpine + node install = 50 MB/30 sec => ??? First build of node based image takes around 3 minutes. Intermediate steps are cached by Docker. Second build of node based image takes now only around 3 seconds.","title":"Image size"},{"location":"docker/3-docker-dockerfile/#dockerfile-build-image","text":"Docker file, steps to build an image. Instructions: - FROM // pull image from docker hub \\ = layer - RUN // add node / new image/running intermediate container - COPY / = layer new image/running intermediate container - CMD constructed image resulting from the different images, layers, and intermediate containers You can't run commands in an image, so you need intermediate container.","title":"Dockerfile build image"},{"location":"docker/3-docker-dockerfile/#dockerfile-context","text":"!! Warning !! Create a Dockerfile then build image in a dedicated folder for your application Otherwise, all files/folders contained in where you build image will be sent to the daemon at build time as the context. It is for this reason that you must create the Dockerfile in the folder of your application, or here to test, in a separate folder. If you create your Dockerfile directly in the root / directory, your entire hard drive is sent as context to the daemon!","title":"Dockerfile context"},{"location":"docker/3-docker-dockerfile/#apk","text":"apk = Alpine Package Management It is the equivalent of APT for Debian distributions and therefore in particular for Ubuntu apk add --update actually allows you to do apk update first, then apk add. Debian equivalent of: apt update && apt install && lets you do something based on whether the previous command completed successfully - that's why you tend to see it chained as do_something && do_something_else_that_depended_on_something. Furthermore, you also have || which is the logical or, and also ; which is just a separator which doesn't care what happen to the command before.","title":"APK"},{"location":"docker/3-docker-dockerfile/#dockerfile","text":"Create a new folder docker-test. Open it with VS Code. In this example we gonna crate a node image (based on Alpine, not on official node image) to simply test console log in a js file. Create a new file named, with VS Code, 'app.js' and type in it: console.log('Hello, world!'); Then, create a new file, in folder, with VS Code, named: Dockerfile Base image Install node Copy js file from local folder to container. If folder does not exist, it will be created. Type following commands in newly created Dockerfile file (exactly respect the case and do not add any extensions): FROM alpine RUN apk add --update nodejs COPY ./app.js /app/","title":"Dockerfile"},{"location":"docker/4-docker-dockerhub/","text":"Docker - 4 - Docker Hub export/import for container docker container export/import $ docker build -t mynode . $ docker run -it mynode sh $c touch hello.txt $c exit $ docker container ps -a CONTAINER ID IMAGE 3d8e43e502b0 mynode $ docker container export -o mycontainer.tar 3d8 $ tar -tvf mycontainer.tar $ docker container rm 3d8 $ docker image import mycontainer.tar nodetest $ docker images REPOSITORY TAG nodetest latest $ docker image inspect nodetest:latest Only one layer because exporting a container is like creating an image from a file system. It's not possible to relaunch a container directly from another exported container. You must first create an image with import. tar for image docker image save/load <-> tar $ docker build -t mynode:0.1 . $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode 0.1 c68e7a86d468 8 seconds ago 48MB $ docker image save -o monimage.tar mynode (to compress with gzip: docker save mon_image | gzip > mon_image.tar.gz) $ tar -tvf monimage.tar $ docker image prune -a $ docker image load < monimage.tar or $ docker image load -i mon_image.tar $ docker run --rm mynode:0.1 hello node-test-012 Encrypt identifiers Encrypt your identifiers GNU/Linux $ sudo apt install pass $ gpg2 --gen-key Enter your name and email when requested. Then do: $ wget https://github.com/docker/docker-credential-helpers/releases/download/v0.6.3/docker-credential-pass-v0.6.3-amd64.tar.gz && tar -xf docker-credential-pass-v0.6.3-amd64.tar.gz && chmod +x docker-credential-pass && sudo mv docker-credential-pass /usr/local/bin/ $ pass init \"YOUR NAME\" $ nano ~/.docker/config.json then: { \"credsStore\": \"pass\" } $ docker login Push image Push image to docker hub $ docker login $ docker build -t oldu73/mynode . $ docker image push oldu73/mynode $ docker image prune -a $ docker run --rm oldu73/mynode $ docker logout Docker hub docker image pull docker image push docker image pull/push / :[tag] docker search https://hub.docker.com/ $ docker pull node $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE node latest 7220633f01cd 7 days ago 992MB $ docker run -it --rm node sh $c ls $c node -v1 $c mkdir app $c cd app $c echo \"console.log('Hello, world!');\" > app.js $c node app.js","title":"Docker - 04 - Docker Hub"},{"location":"docker/4-docker-dockerhub/#docker-4-docker-hub","text":"","title":"Docker - 4 - Docker Hub"},{"location":"docker/4-docker-dockerhub/#exportimport","text":"for container docker container export/import $ docker build -t mynode . $ docker run -it mynode sh $c touch hello.txt $c exit $ docker container ps -a CONTAINER ID IMAGE 3d8e43e502b0 mynode $ docker container export -o mycontainer.tar 3d8 $ tar -tvf mycontainer.tar $ docker container rm 3d8 $ docker image import mycontainer.tar nodetest $ docker images REPOSITORY TAG nodetest latest $ docker image inspect nodetest:latest Only one layer because exporting a container is like creating an image from a file system. It's not possible to relaunch a container directly from another exported container. You must first create an image with import.","title":"export/import"},{"location":"docker/4-docker-dockerhub/#tar","text":"for image docker image save/load <-> tar $ docker build -t mynode:0.1 . $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode 0.1 c68e7a86d468 8 seconds ago 48MB $ docker image save -o monimage.tar mynode (to compress with gzip: docker save mon_image | gzip > mon_image.tar.gz) $ tar -tvf monimage.tar $ docker image prune -a $ docker image load < monimage.tar or $ docker image load -i mon_image.tar $ docker run --rm mynode:0.1 hello node-test-012","title":"tar"},{"location":"docker/4-docker-dockerhub/#encrypt-identifiers","text":"Encrypt your identifiers GNU/Linux $ sudo apt install pass $ gpg2 --gen-key Enter your name and email when requested. Then do: $ wget https://github.com/docker/docker-credential-helpers/releases/download/v0.6.3/docker-credential-pass-v0.6.3-amd64.tar.gz && tar -xf docker-credential-pass-v0.6.3-amd64.tar.gz && chmod +x docker-credential-pass && sudo mv docker-credential-pass /usr/local/bin/ $ pass init \"YOUR NAME\" $ nano ~/.docker/config.json then: { \"credsStore\": \"pass\" } $ docker login","title":"Encrypt identifiers"},{"location":"docker/4-docker-dockerhub/#push-image","text":"Push image to docker hub $ docker login $ docker build -t oldu73/mynode . $ docker image push oldu73/mynode $ docker image prune -a $ docker run --rm oldu73/mynode $ docker logout","title":"Push image"},{"location":"docker/4-docker-dockerhub/#docker-hub","text":"docker image pull docker image push docker image pull/push / :[tag] docker search https://hub.docker.com/ $ docker pull node $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE node latest 7220633f01cd 7 days ago 992MB $ docker run -it --rm node sh $c ls $c node -v1 $c mkdir app $c cd app $c echo \"console.log('Hello, world!');\" > app.js $c node app.js","title":"Docker hub"},{"location":"docker/5-docker-nodeserver/","text":"Docker - 5 - Node Server Node Server Image Stats Show resource usage statistic Maybe tried with Node server project running $ docker run --rm -d --name appnode -p 80:80 myapp Then $ docker stats After, open a browser at http://localhost/ address Click a lot on refresh button to see CPU % growing in stats terminal's live view. Detach mode -d option $ docker run --rm -d --name appnode -p 80:80 myapp --rm to remove container automatically after stop Then to go back inside running detached container $ docker exec -it appnode sh .dockerignore In current project folder, create a new file named \".dockerignore\" Add also a sample text file \"hello.txt\" file that maybe contain \"to be ignored\" sentence. Re-build image $ docker build -t myapp . Launch it in interactive mode with sh $ docker run --rm -it myapp sh ls/cat hello.txt file in container output respectively presence/content of hello.txt file. Now list hello.txt file in .dockerignore file # for current folder hello.txt # for first level of folder */hello.txt # for everywhere **/hello.txt # exception with ! **/*.txt !README.txt Re-build image Re-launch it in interactive mode ls output does not contain hello.txt file anymore Optimization Let's say we change listening port of Node server project from 80 to 70 file app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(70); Re-build image $ docker build -t myapp . => [4/4] RUN npm install 7.1s What we observe here is that NPM install is run again although only listening port in app.js has been modified. To avoid this behavior, Docker file should be modified accordingly. Split COPY instruction in two, before and after \"RUN npm install\" to not invalidate cache for dependencies (package.json). Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"app.js\"] And now, on build image after changing listening port in app.js $ docker build -t myapp . => [4/4] RUN npm install 0.0s Redirect port Redirect port from host to container docker run ... -p <hostport>:<containerport> ... -p option: -p, --publish list Publish a container's port(s) to the host To fix Node server project, add missing port redirection to run command: $ docker run --rm -p 80:80 myapp Many containers may listen on same port number because they're isolated. $ docker run --rm -d -p 81:80 myapp $ docker run --rm -d -p 82:80 myapp On the other hand, on the host, only one forwarding on a port is possible. One port = one application! Without opening port, a container may access to Internet. Outgoing traffic is possible. By default, all incoming traffic is blocked, all ports are closed by default. Port http 80 https 443 ssh 22 Node server project Node server project to return a minimal page in a browser at localhost address, with Express (which is a Node.js framework) Our image should have Node.js and its npm package manager. It should have several dependencies: nodemon and express. And it will have to launch the app contained in app.js by default. For the project, we'll create a new Dockerfile in a folder. In the same folder we will also have a package.json file (which allows you to manage the dependencies used) and an app.js file (which will contain our application). In the package.json file therefore have our two dependencies. In the app.js file we just have an Express route which will send in JSON format the character string \"Hello, world!\" for all routes. folder: - /mnt/c/tmp/docker/node-server $ touch package.json edit package.json { \"dependencies\": { \"nodemon\": \"2.0.14\", \"express\": \"4.17.1\" } } $ touch app.js edit app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); $ touch Dockerfile Browse a bit docker hub and look for alpine tagged image more lighter (169MB) than the official one (latest) (992MB) FROM node:alpine WORKDIR /app COPY . . RUN npm install CMD [\"nodemon\", \"app.js\"] then.. $ docker build -t myapp . $ docker image ls $ docker run --rm myapp path error to debug, run in interactive mode with sh to override Dockerfile CMD $ docker run --rm -it myapp sh /app $c env /app $c nodemon sh: nodemon: not found $c cd node_modules/.bin/ /app/node_modules/.bin # ls is-ci mime nodemon /app $c ./node_modules/.bin/nodemon app.js Fix the Docker file with adding value to image's path .. ENV PATH=$PATH:/app/node_modules/.bin .. $ docker build -t myapp . $ docker run --rm -it myapp sh /app $c env | grep PATH PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin /app $c nodemon app.js Now it's OK $ docker run --rm myapp Try \"localhost\" in a browser -> does not work and it's normal because default behavior does not allow to communicate with a container.","title":"Docker - 05 - Node Server"},{"location":"docker/5-docker-nodeserver/#docker-5-node-server","text":"Node Server Image","title":"Docker - 5 - Node Server"},{"location":"docker/5-docker-nodeserver/#stats","text":"Show resource usage statistic Maybe tried with Node server project running $ docker run --rm -d --name appnode -p 80:80 myapp Then $ docker stats After, open a browser at http://localhost/ address Click a lot on refresh button to see CPU % growing in stats terminal's live view.","title":"Stats"},{"location":"docker/5-docker-nodeserver/#detach-mode","text":"-d option $ docker run --rm -d --name appnode -p 80:80 myapp --rm to remove container automatically after stop Then to go back inside running detached container $ docker exec -it appnode sh","title":"Detach mode"},{"location":"docker/5-docker-nodeserver/#dockerignore","text":"In current project folder, create a new file named \".dockerignore\" Add also a sample text file \"hello.txt\" file that maybe contain \"to be ignored\" sentence. Re-build image $ docker build -t myapp . Launch it in interactive mode with sh $ docker run --rm -it myapp sh ls/cat hello.txt file in container output respectively presence/content of hello.txt file. Now list hello.txt file in .dockerignore file # for current folder hello.txt # for first level of folder */hello.txt # for everywhere **/hello.txt # exception with ! **/*.txt !README.txt Re-build image Re-launch it in interactive mode ls output does not contain hello.txt file anymore","title":".dockerignore"},{"location":"docker/5-docker-nodeserver/#optimization","text":"Let's say we change listening port of Node server project from 80 to 70 file app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(70); Re-build image $ docker build -t myapp . => [4/4] RUN npm install 7.1s What we observe here is that NPM install is run again although only listening port in app.js has been modified. To avoid this behavior, Docker file should be modified accordingly. Split COPY instruction in two, before and after \"RUN npm install\" to not invalidate cache for dependencies (package.json). Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"app.js\"] And now, on build image after changing listening port in app.js $ docker build -t myapp . => [4/4] RUN npm install 0.0s","title":"Optimization"},{"location":"docker/5-docker-nodeserver/#redirect-port","text":"Redirect port from host to container docker run ... -p <hostport>:<containerport> ... -p option: -p, --publish list Publish a container's port(s) to the host To fix Node server project, add missing port redirection to run command: $ docker run --rm -p 80:80 myapp Many containers may listen on same port number because they're isolated. $ docker run --rm -d -p 81:80 myapp $ docker run --rm -d -p 82:80 myapp On the other hand, on the host, only one forwarding on a port is possible. One port = one application! Without opening port, a container may access to Internet. Outgoing traffic is possible. By default, all incoming traffic is blocked, all ports are closed by default.","title":"Redirect port"},{"location":"docker/5-docker-nodeserver/#port","text":"http 80 https 443 ssh 22","title":"Port"},{"location":"docker/5-docker-nodeserver/#node-server-project","text":"Node server project to return a minimal page in a browser at localhost address, with Express (which is a Node.js framework) Our image should have Node.js and its npm package manager. It should have several dependencies: nodemon and express. And it will have to launch the app contained in app.js by default. For the project, we'll create a new Dockerfile in a folder. In the same folder we will also have a package.json file (which allows you to manage the dependencies used) and an app.js file (which will contain our application). In the package.json file therefore have our two dependencies. In the app.js file we just have an Express route which will send in JSON format the character string \"Hello, world!\" for all routes. folder: - /mnt/c/tmp/docker/node-server $ touch package.json edit package.json { \"dependencies\": { \"nodemon\": \"2.0.14\", \"express\": \"4.17.1\" } } $ touch app.js edit app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); $ touch Dockerfile Browse a bit docker hub and look for alpine tagged image more lighter (169MB) than the official one (latest) (992MB) FROM node:alpine WORKDIR /app COPY . . RUN npm install CMD [\"nodemon\", \"app.js\"] then.. $ docker build -t myapp . $ docker image ls $ docker run --rm myapp path error to debug, run in interactive mode with sh to override Dockerfile CMD $ docker run --rm -it myapp sh /app $c env /app $c nodemon sh: nodemon: not found $c cd node_modules/.bin/ /app/node_modules/.bin # ls is-ci mime nodemon /app $c ./node_modules/.bin/nodemon app.js Fix the Docker file with adding value to image's path .. ENV PATH=$PATH:/app/node_modules/.bin .. $ docker build -t myapp . $ docker run --rm -it myapp sh /app $c env | grep PATH PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin /app $c nodemon app.js Now it's OK $ docker run --rm myapp Try \"localhost\" in a browser -> does not work and it's normal because default behavior does not allow to communicate with a container.","title":"Node server project"},{"location":"docker/6-docker-datapersistence/","text":"Docker - 6 - Data Persistence Introduction Container = - writable layer (this layer is deleted if the container no longer exists) - image layer(s) (read) Writable layers use UnionFS, slow read write performance, not adapted to host database. To persist data, 3 possibilities: Volumes On Filesystem but managed by Docker, accessible through Docker CLI), mostly advised to use (in /var/lib/docker/volumes/ (not on WSL) but never access it directly. Volumes are stored on but isolated from host machine. Create a volume with Docker CLI command docker volume create Bind mount Manged by Filesystem and accessible from outside of Docker, not recommended. Bind mounts are regular folder and files stored on host machine. TMPFS Temporary File System -> RAM. TMPFS are used to store temporary not persisted data, sensitive information like secret. Bind mount Adapted for: - Sharing configuration files between host and container. - Development environment to share source code and alow live reload. Recommend syntax docker run --mount type=bind,source=<url>,target=<url> image $ mkdir data $ cd data $ touch hello.txt $ cd .. $ docker run --mount type=bind,source=\"$(pwd)\"/data,target=/data -it alpine sh $c ls .. data .. $c cd data $c ls hello.txt Search for Mounts section with inspect CLI command to see mounting details: docker container inspect containerName Development environment Set up of a development environnement for a node server application (c.f. Node server project ). The goal here is to have changes available from host machine (IDE) in container and automatically reloaded by nodemon. !!Warning!! A common mistake is to bind the root folder of a project. E.g. in case of node context, if we do so, the node_modules folder created/populated in container image by \"RUN npm install\" instruction from Dockerfile will be erased. To avoid this unwanted behavior, it's mostly advised to move the source code files modified through IDE on host machine in a dedicated folder (e.g. src). On host machine: $ mkdir node-server $ cd node-server $ mkdir src $ cd src $ touch app.js $ cd .. src/app.js: const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); Dockerfile (in root folder, \"node-server\"): FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] !! Warning !! In above Dockerfile we use -L option for --legacy-watch because in some containerized environnement, application may not restart automatically after file's change. Build image: $ docker build -t myapp . Start a container with new image version: $ docker run --rm -p 80:80 --mount type=bind,source=\"$(pwd)/src\",target=/app/src myapp Now try to edit 'src/app.js' file on host machine to observe nodemon restart in terminal. You may also observe the changes on your browser at 'localhost' address, after refresh. Volumes docker volume - create - inspect - ls - rm - prune old syntax (not advised, c.f. bind) docker run -v <volume-name>:<container-url> image new syntax docker run --mount type=volume,source=<volume-name>,target=<url> image Create New volume $ docker volume create mydata mydata $ docker volume ls DRIVER VOLUME NAME local mydata $ docker volume inspect mydata [ { \"CreatedAt\": \"2021-12-24T06:15:34Z\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/mydata/_data\", \"Name\": \"mydata\", \"Options\": {}, \"Scope\": \"local\" } ] WSL2 volumes are not in /var/lib/docker/volumes/mydata/_data You can find WSL2 volumes under a hidden network share. Open Windows Explorer, and type \\\\wsl$ into the location bar. Hit enter, and it should display your WSL volumes, including the ones for Docker for Windows. WSL2 volumes, in Windows Explorer bar \\\\wsl$\\docker-desktop-data\\version-pack-data\\community\\docker\\volumes New container with bind volume $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c touch hello.txt $c echo 123 > hello.txt ctrl+d $ docker rm containername $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c cat hello.txt 123 Share Backup Restore Share volume between containers $ docker run --mount type=volume,source=mydata,target=/data --name firstcont -it alpine sh $c1 cd data In another terminal $ docker run --mount type=volume,source=mydata,target=/data --name secondcont -it alpine sh $c2 cd data $c2 touch new.txt $c1 ls hello.txt new.txt Another way is volume from container $ docker run --volumes-from firstcont --name thirdcont -it alpine sh Backup volume Compress a volume to a bind folder with tar $ mkdir backup $ docker run --mount type=volume,source=mydata,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -czf /backup/mydata.tar.gz /data Restore volume Extract an archive from a bind folder to a volume $ docker volume create restore $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -xf /backup/mydata.tar.gz -C /data To not have a folder data in a folder data, use tar with option --strip-components 1 $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\",target=/backup -it alpine tar -xf /backup/backup.tar --strip-components 1 -C /data Check volume correctly restored $ docker container run -it --rm --mount source=restore,target=/data alpine sh Volume to persist a database (mongo) For mongo db it consist of mounting a volume with folder /data/db in mongo container $ docker volume create mydb $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer1 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.insertOne({ name: 'jean' }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61caeae2df845609f1835264\") } > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } > exit bye $c exit $ docker container stop mongocontainer1 $ docker container rm mongocontainer1 Container is removed but database is persisted in a volume. $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer2 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } Compass GUI to browse mongo db Should run container with opened port (default 27017). If port is already used on host machine, you may use 27018 for example $ docker run -p 27018:27017 --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer3 mongo Enter in connection field: mongodb://localhost:27018 TMPFS Rarely used, uniquely to keep data in RAM, e.g. secret or status data, works only on Linux system. $ docker run --mount type=tmpfs,target=/data -it alpine sh $c cd data $c touch secret.txt $c ls secret.txt $c exit $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 58f104d6a051 alpine \"sh\" 2 minutes ago Exited (0) 5 seconds ago musing_wilbur With 'TMPFS' if container is in an 'Exited' status, data aren't persisted. Relaunch container to observe that data aren't available anymore. $ docker start -ai musing_wilbur $c cd data $c ls (empty)","title":"Docker - 06 - Data Persistence"},{"location":"docker/6-docker-datapersistence/#docker-6-data-persistence","text":"","title":"Docker - 6 - Data Persistence"},{"location":"docker/6-docker-datapersistence/#introduction","text":"Container = - writable layer (this layer is deleted if the container no longer exists) - image layer(s) (read) Writable layers use UnionFS, slow read write performance, not adapted to host database. To persist data, 3 possibilities:","title":"Introduction"},{"location":"docker/6-docker-datapersistence/#volumes","text":"On Filesystem but managed by Docker, accessible through Docker CLI), mostly advised to use (in /var/lib/docker/volumes/ (not on WSL) but never access it directly. Volumes are stored on but isolated from host machine. Create a volume with Docker CLI command docker volume create","title":"Volumes"},{"location":"docker/6-docker-datapersistence/#bind-mount","text":"Manged by Filesystem and accessible from outside of Docker, not recommended. Bind mounts are regular folder and files stored on host machine.","title":"Bind mount"},{"location":"docker/6-docker-datapersistence/#tmpfs","text":"Temporary File System -> RAM. TMPFS are used to store temporary not persisted data, sensitive information like secret.","title":"TMPFS"},{"location":"docker/6-docker-datapersistence/#bind-mount_1","text":"Adapted for: - Sharing configuration files between host and container. - Development environment to share source code and alow live reload. Recommend syntax docker run --mount type=bind,source=<url>,target=<url> image $ mkdir data $ cd data $ touch hello.txt $ cd .. $ docker run --mount type=bind,source=\"$(pwd)\"/data,target=/data -it alpine sh $c ls .. data .. $c cd data $c ls hello.txt Search for Mounts section with inspect CLI command to see mounting details: docker container inspect containerName","title":"Bind mount"},{"location":"docker/6-docker-datapersistence/#development-environment","text":"Set up of a development environnement for a node server application (c.f. Node server project ). The goal here is to have changes available from host machine (IDE) in container and automatically reloaded by nodemon. !!Warning!! A common mistake is to bind the root folder of a project. E.g. in case of node context, if we do so, the node_modules folder created/populated in container image by \"RUN npm install\" instruction from Dockerfile will be erased. To avoid this unwanted behavior, it's mostly advised to move the source code files modified through IDE on host machine in a dedicated folder (e.g. src). On host machine: $ mkdir node-server $ cd node-server $ mkdir src $ cd src $ touch app.js $ cd .. src/app.js: const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); Dockerfile (in root folder, \"node-server\"): FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] !! Warning !! In above Dockerfile we use -L option for --legacy-watch because in some containerized environnement, application may not restart automatically after file's change. Build image: $ docker build -t myapp . Start a container with new image version: $ docker run --rm -p 80:80 --mount type=bind,source=\"$(pwd)/src\",target=/app/src myapp Now try to edit 'src/app.js' file on host machine to observe nodemon restart in terminal. You may also observe the changes on your browser at 'localhost' address, after refresh.","title":"Development environment"},{"location":"docker/6-docker-datapersistence/#volumes_1","text":"docker volume - create - inspect - ls - rm - prune old syntax (not advised, c.f. bind) docker run -v <volume-name>:<container-url> image new syntax docker run --mount type=volume,source=<volume-name>,target=<url> image","title":"Volumes"},{"location":"docker/6-docker-datapersistence/#create","text":"","title":"Create"},{"location":"docker/6-docker-datapersistence/#new-volume","text":"$ docker volume create mydata mydata $ docker volume ls DRIVER VOLUME NAME local mydata $ docker volume inspect mydata [ { \"CreatedAt\": \"2021-12-24T06:15:34Z\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/mydata/_data\", \"Name\": \"mydata\", \"Options\": {}, \"Scope\": \"local\" } ] WSL2 volumes are not in /var/lib/docker/volumes/mydata/_data You can find WSL2 volumes under a hidden network share. Open Windows Explorer, and type \\\\wsl$ into the location bar. Hit enter, and it should display your WSL volumes, including the ones for Docker for Windows. WSL2 volumes, in Windows Explorer bar \\\\wsl$\\docker-desktop-data\\version-pack-data\\community\\docker\\volumes","title":"New volume"},{"location":"docker/6-docker-datapersistence/#new-container-with-bind-volume","text":"$ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c touch hello.txt $c echo 123 > hello.txt ctrl+d $ docker rm containername $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c cat hello.txt 123","title":"New container with bind volume"},{"location":"docker/6-docker-datapersistence/#share-backup-restore","text":"","title":"Share Backup Restore"},{"location":"docker/6-docker-datapersistence/#share-volume-between-containers","text":"$ docker run --mount type=volume,source=mydata,target=/data --name firstcont -it alpine sh $c1 cd data In another terminal $ docker run --mount type=volume,source=mydata,target=/data --name secondcont -it alpine sh $c2 cd data $c2 touch new.txt $c1 ls hello.txt new.txt Another way is volume from container $ docker run --volumes-from firstcont --name thirdcont -it alpine sh","title":"Share volume between containers"},{"location":"docker/6-docker-datapersistence/#backup-volume","text":"Compress a volume to a bind folder with tar $ mkdir backup $ docker run --mount type=volume,source=mydata,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -czf /backup/mydata.tar.gz /data","title":"Backup volume"},{"location":"docker/6-docker-datapersistence/#restore-volume","text":"Extract an archive from a bind folder to a volume $ docker volume create restore $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -xf /backup/mydata.tar.gz -C /data To not have a folder data in a folder data, use tar with option --strip-components 1 $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\",target=/backup -it alpine tar -xf /backup/backup.tar --strip-components 1 -C /data Check volume correctly restored $ docker container run -it --rm --mount source=restore,target=/data alpine sh","title":"Restore volume"},{"location":"docker/6-docker-datapersistence/#volume-to-persist-a-database-mongo","text":"For mongo db it consist of mounting a volume with folder /data/db in mongo container $ docker volume create mydb $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer1 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.insertOne({ name: 'jean' }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61caeae2df845609f1835264\") } > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } > exit bye $c exit $ docker container stop mongocontainer1 $ docker container rm mongocontainer1 Container is removed but database is persisted in a volume. $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer2 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" }","title":"Volume to persist a database (mongo)"},{"location":"docker/6-docker-datapersistence/#compass-gui-to-browse-mongo-db","text":"Should run container with opened port (default 27017). If port is already used on host machine, you may use 27018 for example $ docker run -p 27018:27017 --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer3 mongo Enter in connection field: mongodb://localhost:27018","title":"Compass GUI to browse mongo db"},{"location":"docker/6-docker-datapersistence/#tmpfs_1","text":"Rarely used, uniquely to keep data in RAM, e.g. secret or status data, works only on Linux system. $ docker run --mount type=tmpfs,target=/data -it alpine sh $c cd data $c touch secret.txt $c ls secret.txt $c exit $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 58f104d6a051 alpine \"sh\" 2 minutes ago Exited (0) 5 seconds ago musing_wilbur With 'TMPFS' if container is in an 'Exited' status, data aren't persisted. Relaunch container to observe that data aren't available anymore. $ docker start -ai musing_wilbur $c cd data $c ls (empty)","title":"TMPFS"},{"location":"docker/7-docker-network/","text":"Docker - 7 - Network Introduction WAN = Internet LAN = Local docker network: - ls - create - rm - inspect - connect - disconnect - prune - --network | --net 3 methods: - Bridge, sub-segment - Host, merge host machine network - Overlay, Docker Swarm (- MACVLAN) (- Others) Bridge (mainly used) Grouped by sub-segment. Docker as bridge manager. By default a container belongs to named \"bridge\" (Docker0) network. Host (Linux only, rarely used) IP addresses for containers defined by router like for host machine. Containers will be straight forward connected to local network. Overlay (Swarm) To establish communication between Docker Daemons. Bridge $ docker network $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 119b5f46e464 none null local $ docker network inspect bridge ... \"Containers\": {}, ... $ ifconfig ... docker0: ... $ docker run --rm -it alpine sh in a second terminal $ docker network inspect bridge ... \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" } } ... $ docker run --rm -it alpine sh in a third terminal $ docker network inspect bridge \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"76ff8f56718ae5244eabe03092f7a0227aa2e42249bf2ab1c8f91a9faf76c715\": { \"Name\": \"admiring_driscoll\", \"EndpointID\": \"684e6a570db46dadd9bdf53bf383ea069fa626fc16b7ab26c11e604415c00b25\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } } in second terminal $c ping google.ch $c ping 172.17.0.2 Be aware that ip address maybe attributed randomly by Docker. To use name on default network, use --name and --link (deprecated) options on run command then you may ping by name instead of ip address (only for default bridge network). in first terminal $ docker run --rm --name alpine1 -it alpine sh in second terminal $ docker run --rm --link alpine1 -it alpine sh $c ping alpine1 Create bridge Create a network, make two containers communicate through it and use container name instead of ip addresses. Create network, default driver = bridge $ docker network create mynet $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 0a85e3670d62 mynet bridge local 119b5f46e464 none null local Use network with a named (important for name resolution over the network) container $ docker run --rm --network mynet --name server1 -d alpine ping google.ch $ docker inspect mynet \"Containers\": { \"249b952ab5db2ac4f3077e1a7fb89582eedaa02c236a92a7e15fc5cee73d3292\": { \"Name\": \"server1\", \"EndpointID\": \"48284c2119158a9ebf9d67b3eee0c74c58ede079ba173b769f5b791f2f507abb\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.18.0.2/16\", \"IPv6Address\": \"\" } } $ docker run --rm -it --network mynet --name server2 alpine sh $c ping server1 PING server1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.079 ms 64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.166 ms From another terminal $ docker exec -it server1 sh $c ping server2 PING server2 (172.18.0.3): 56 data bytes 64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.125 ms 64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.496 ms Remove network $ docker network rm mynet Remove all network at once $ docker network prune Connect a Node.js server with MongoDB Goal: - display a counter in a browser at 'localhost' address. Architecture: - Image - MongoDB - Image - Node.js - Volumes - mydb { count: x } - Container - server - Container - db - Network - mynet - Port 80 open to listen to request (count++) from a browser at 'localhost' address MongoDB Volume and container $ docker volume create mydb $ docker run --name db --mount type=volume,source=mydb,target=/data/db -d mongo Network and connect (and disconnect from default bridge) $ docker network create mynet $ docker network connect mynet db $ docker network disconnect bridge db Create db and collection to handle and initialize the counter $ docker exec -it db sh $c mongo > use test switched to db test > db.count.insertOne({count:0}) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61cc2517094e32ba7f98bb31\") } > db.count.find() { \"_id\" : ObjectId(\"61cc2517094e32ba7f98bb31\"), \"count\" : 0 } > exit bye $c exit Node server Development Development Environnement setup First step, application development with bind mount. We should use the mongo javascript driver in our application to allow connection to the db. In 'node-server' folder. File 'package.json' add mongo dependencies (browse for \"npm mongodb\" -> MongoDB NodeJS Driver, to check version) { \"dependencies\": { \"express\": \"^4.17.1\", \"mongodb\": \"^3.6.2\", \"nodemon\": \"^2.0.6\", \"console-stamp\": \"^3.0.3\" } } \"console-stamp\" is to add timestamp in logs ^version \u201cCompatible with version\u201d, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0. Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] Build image in 'node-server' folder $ docker build -t node-server . Application is in js file 'node-server/src/app.js' const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); To develop application use a bind mount $ docker run --name server --mount type=bind,source=\"$(pwd)\"/src,target=/app/src -p 80:80 --network mynet node-server Browse to 'localhost'. Observe live change availability by editing \"Hello, world!\" response in 'app.js' file and refreshing 'localhost' page in internet browser. Check that port '80' is published for 'server' container $ docker container port server 80/tcp -> 0.0.0.0:80 Development Server configuration Modify 'app.js' file as follow require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); Node server Production Rebuild node server image with released app.js in it (above development has been erased by bind mount) In 'node-server' folder $ docker build -t node-server . If 'node-server' container is still running, remove it and then $ docker run --name server --network mynet -d -p 80:80 node-server Host C.f. Bridge section for initial setup. Reset 'app.js' to const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); Rebuild 'node-server' image $ docker build -t node-server . Relaunch server but on local network, this time, no need to publish port $ docker run --network host node-server Do not work on WSL (Windows Subsystem for Linux), neither MacOs. To not use any network $ docker run --network none node-server","title":"Docker - 07 - Network"},{"location":"docker/7-docker-network/#docker-7-network","text":"","title":"Docker - 7 - Network"},{"location":"docker/7-docker-network/#introduction","text":"WAN = Internet LAN = Local docker network: - ls - create - rm - inspect - connect - disconnect - prune - --network | --net 3 methods: - Bridge, sub-segment - Host, merge host machine network - Overlay, Docker Swarm (- MACVLAN) (- Others)","title":"Introduction"},{"location":"docker/7-docker-network/#bridge-mainly-used","text":"Grouped by sub-segment. Docker as bridge manager. By default a container belongs to named \"bridge\" (Docker0) network.","title":"Bridge (mainly used)"},{"location":"docker/7-docker-network/#host-linux-only-rarely-used","text":"IP addresses for containers defined by router like for host machine. Containers will be straight forward connected to local network.","title":"Host (Linux only, rarely used)"},{"location":"docker/7-docker-network/#overlay-swarm","text":"To establish communication between Docker Daemons.","title":"Overlay (Swarm)"},{"location":"docker/7-docker-network/#bridge","text":"$ docker network $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 119b5f46e464 none null local $ docker network inspect bridge ... \"Containers\": {}, ... $ ifconfig ... docker0: ... $ docker run --rm -it alpine sh in a second terminal $ docker network inspect bridge ... \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" } } ... $ docker run --rm -it alpine sh in a third terminal $ docker network inspect bridge \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"76ff8f56718ae5244eabe03092f7a0227aa2e42249bf2ab1c8f91a9faf76c715\": { \"Name\": \"admiring_driscoll\", \"EndpointID\": \"684e6a570db46dadd9bdf53bf383ea069fa626fc16b7ab26c11e604415c00b25\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } } in second terminal $c ping google.ch $c ping 172.17.0.2 Be aware that ip address maybe attributed randomly by Docker. To use name on default network, use --name and --link (deprecated) options on run command then you may ping by name instead of ip address (only for default bridge network). in first terminal $ docker run --rm --name alpine1 -it alpine sh in second terminal $ docker run --rm --link alpine1 -it alpine sh $c ping alpine1","title":"Bridge"},{"location":"docker/7-docker-network/#create-bridge","text":"Create a network, make two containers communicate through it and use container name instead of ip addresses. Create network, default driver = bridge $ docker network create mynet $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 0a85e3670d62 mynet bridge local 119b5f46e464 none null local Use network with a named (important for name resolution over the network) container $ docker run --rm --network mynet --name server1 -d alpine ping google.ch $ docker inspect mynet \"Containers\": { \"249b952ab5db2ac4f3077e1a7fb89582eedaa02c236a92a7e15fc5cee73d3292\": { \"Name\": \"server1\", \"EndpointID\": \"48284c2119158a9ebf9d67b3eee0c74c58ede079ba173b769f5b791f2f507abb\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.18.0.2/16\", \"IPv6Address\": \"\" } } $ docker run --rm -it --network mynet --name server2 alpine sh $c ping server1 PING server1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.079 ms 64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.166 ms From another terminal $ docker exec -it server1 sh $c ping server2 PING server2 (172.18.0.3): 56 data bytes 64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.125 ms 64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.496 ms Remove network $ docker network rm mynet Remove all network at once $ docker network prune","title":"Create bridge"},{"location":"docker/7-docker-network/#connect-a-nodejs-server-with-mongodb","text":"Goal: - display a counter in a browser at 'localhost' address. Architecture: - Image - MongoDB - Image - Node.js - Volumes - mydb { count: x } - Container - server - Container - db - Network - mynet - Port 80 open to listen to request (count++) from a browser at 'localhost' address","title":"Connect a Node.js server with MongoDB"},{"location":"docker/7-docker-network/#mongodb","text":"Volume and container $ docker volume create mydb $ docker run --name db --mount type=volume,source=mydb,target=/data/db -d mongo Network and connect (and disconnect from default bridge) $ docker network create mynet $ docker network connect mynet db $ docker network disconnect bridge db Create db and collection to handle and initialize the counter $ docker exec -it db sh $c mongo > use test switched to db test > db.count.insertOne({count:0}) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61cc2517094e32ba7f98bb31\") } > db.count.find() { \"_id\" : ObjectId(\"61cc2517094e32ba7f98bb31\"), \"count\" : 0 } > exit bye $c exit","title":"MongoDB"},{"location":"docker/7-docker-network/#node-server-development","text":"","title":"Node server Development"},{"location":"docker/7-docker-network/#development-environnement-setup","text":"First step, application development with bind mount. We should use the mongo javascript driver in our application to allow connection to the db. In 'node-server' folder. File 'package.json' add mongo dependencies (browse for \"npm mongodb\" -> MongoDB NodeJS Driver, to check version) { \"dependencies\": { \"express\": \"^4.17.1\", \"mongodb\": \"^3.6.2\", \"nodemon\": \"^2.0.6\", \"console-stamp\": \"^3.0.3\" } } \"console-stamp\" is to add timestamp in logs ^version \u201cCompatible with version\u201d, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0. Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] Build image in 'node-server' folder $ docker build -t node-server . Application is in js file 'node-server/src/app.js' const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); To develop application use a bind mount $ docker run --name server --mount type=bind,source=\"$(pwd)\"/src,target=/app/src -p 80:80 --network mynet node-server Browse to 'localhost'. Observe live change availability by editing \"Hello, world!\" response in 'app.js' file and refreshing 'localhost' page in internet browser. Check that port '80' is published for 'server' container $ docker container port server 80/tcp -> 0.0.0.0:80","title":"Development Environnement setup"},{"location":"docker/7-docker-network/#development-server-configuration","text":"Modify 'app.js' file as follow require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80);","title":"Development Server configuration"},{"location":"docker/7-docker-network/#node-server-production","text":"Rebuild node server image with released app.js in it (above development has been erased by bind mount) In 'node-server' folder $ docker build -t node-server . If 'node-server' container is still running, remove it and then $ docker run --name server --network mynet -d -p 80:80 node-server","title":"Node server Production"},{"location":"docker/7-docker-network/#host","text":"C.f. Bridge section for initial setup. Reset 'app.js' to const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); Rebuild 'node-server' image $ docker build -t node-server . Relaunch server but on local network, this time, no need to publish port $ docker run --network host node-server Do not work on WSL (Windows Subsystem for Linux), neither MacOs. To not use any network $ docker run --network none node-server","title":"Host"},{"location":"docker/8-compose-use/","text":"Compose - 8 - Use Docker Compose - Use Introduction Application = - Container Web server + - Container Database Setup: - Ports - Volumes - Network - Environment Docker Compose, talking about service. One Application = (is composed of) Many Services (containers that communicate with each others). Docker Compose is a CLI that read 'docker-compose.yml' file. First, install Docker Compose and check installation and version by typing in a terminal: $ docker-compose version First use 'docker-compose ..' command(s) always refer to folder from where command is launched and context of 'docker-compose.yml' file contained in folder. Yaml format configuration file. Yaml syntax is based on an indented key value format. $ touch docker-compose.yml First, mention version to use to ensure retro-compatibility. To determine which version to specify in 'docker-compose.yml' file header, refer to docker engine version that run on your host machine: $ docker version ... Server: Docker Engine - Community Engine: Version: 20.10.11 ... Then refer to documentation Compose file - Reference and guidelines Second, specify service(s). docker-compose.yml: version: '3.8' services: myalpine: image: alpine $ docker-compose up Alternative to go straight in service's container: $ docker-compose run myapline $c In another console: $ docker-compose ps $ docker-compose ps -a $ docker-compose down Particularity of 'docker-compose down' command is to suppress (don't just stop) all container and network that was launched by previous 'docker-compose up' command. Anonymous volumes are never reused by Docker Compose. It launches new ones each time if declared in configuration. Default command is the one defined in image, for 'alpine' it's '/bin/sh'. To overwrite default command, specify it in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine command: ls Or by adding command directly after service name in run command: $ docker-compose run myalpine ls Or with entry point in exec form (instead of shell) in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine entrypoint: [\"ls\"] Or 'command: [\"ls\"]' instead of 'entrypoint: [\"ls\"]' Custom image $ touch Dockerfile Dockerfile: FROM alpine CMD [\"/bin/sh\"] docker-compose.yml version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: . $ docker-compose build Have a look to VS Code Docker plugin to have a synthetic view of all Docker ecosystem components, containers, images, network, etc. Context and Dockerfile Specify a context and Dockerfile: $ mkdir backend $ cp Dockerfile backend/DockerfileBackend docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend Arguments Passing arguments, e.g. create a folder at build, 'Dockerfile' receive args from 'docker-compose.yml'. DockerfileBackend: FROM alpine ARG FOLDER RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test Note the 'arg' indentation with '-' for an array of values (yaml syntax). test: $ docker-compose build $ docker-compose run b $c ls .. test .. Instead of list (- FOLDER=), e.g. for 'args' you may also use an object instead (FOLDER:). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder test: $ docker-compose build $ docker-compose run b $c ls .. myfolder .. Labels docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test labels: - EMAIL=toto@test.com test: $ docker-compose build $ docker image inspect compose_b:latest | grep EMAIL \"EMAIL\": \"toto@test.com\" Ports docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 Volumes Bind $ mkdir data $ touch data/hello.txt DockerfileBackend.yml: FROM alpine ARG FOLDER WORKDIR /app RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data test: $ docker-compose build $ docker-compose run b $c cd data $c ls $c exit Volumes docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: test: $ docker-compose build $ docker-compose run b [+] Running 1/0 \u283f Volume \"compose_datavolume\" Created $c ls data datavolume myfolder $c exit Volume option external to avoid docker-compose to create volume if it does not exist. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: external: true Before testing remove previously created volumes. test: $ docker-compose run b external volume \"\" not found To create anonymous volume, omit source option. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c ls data datavolume datavolumeanonymous myfolder Docker Compose does not always use the same anonymous volume for a service. Therefore, it is advisable to use: $ docker-compose down -v to remove it. -v, --volumes volumes, Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers. Environment Variables from cli $ docker-compose run b $c env HOSTNAME=0b9907714155 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app Add environnement variable from command line, value from host machine: $ docker-compose run -e USER b $c env | grep USER USER=toto By default, by not specifying a value, docker-compose search on host machine environnement variable and if find one that match, pass it (e.g. here with USER that do exist on host machine and has a value). Add environnement variable from command line with specified value: $ docker-compose run -e USER=tintin b $c env | grep USER USER=tintin from compose file Without specifying a value (comes from host machine). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=toto By specifying a value. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER=tintin build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=tintin from .env file If value of environment variable is not specified, docker compose search for corresponding value in host machine, if not found, search then in '.env' file. .env: NODE_ENV=development docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - NODE_ENV build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep NODE_ENV NODE_ENV=development By specifying an environnement file, all variables contained in it will be imported in container. .env: NODE_ENV=development TEST_ENV=test docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: env_file: - .env build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep _ENV TEST_ENV=test NODE_ENV=development You may have many environnement files. You may specify env file in command line, works only with 'up': $ docker-compose --env-file ./.env up You may use both 'env_file' and 'environnement' for same service. You may specify compose project name instead of current folder with, e.g. in .env file: COMPOSE_PROJECT_NAME=myproject Network Default By default docker compose create a network with folder name as a prefix, or with value of 'COMPOSE_PROJECT_NAME' key in project's environnement variable: $ docker-compose up [+] Running 4/4 \u283f Network myproject_default Created .. Note that containers using the network appear in the list ($ docker network inspect myproject_default) only when they are running. Below, we make a test with ping, note that we use shell form (instead of exec (cause: executable file not found in $PATH: unknown)). docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: command: ping a build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 2/2 \u283f Container myproject_a_1 Recreated 0.2s \u283f Container myproject_b_1 Recreated 0.2s Attaching to a_1, b_1 a_1 | PING b (172.29.0.3): 56 data bytes b_1 | PING a (172.29.0.2): 56 data bytes a_1 | 64 bytes from 172.29.0.3: seq=0 ttl=64 time=188.846 ms b_1 | 64 bytes from 172.29.0.2: seq=0 ttl=64 time=0.152 ms Links Links from a container to another one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 3/2 \u283f Network myproject_default Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (172.31.0.2): 56 data bytes b_1 | 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.078 ms b_1 | 64 bytes from 172.31.0.2: seq=1 ttl=64 time=0.190 ms b_1 | 64 bytes from 172.31.0.2: seq=2 ttl=64 time=0.220 ms a_1 | PING b (172.31.0.3): 56 data bytes a_1 | 64 bytes from 172.31.0.3: seq=0 ttl=64 time=0.407 ms b_1 | 64 bytes from 172.31.0.2: seq=3 ttl=64 time=0.305 ms test to ping a and containerA from b: $ docker-compose up -d $ docker-compose exec b sh $c ping a PING a (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.181 ms .. $c ping containerA PING containerA (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.287 ms Name Give network a name to replace the default one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up [+] Running 3/3 \u283f Network mynetwork Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 2.4s Attaching to a_1, b_1 b_1 | PING containerA (192.168.0.2): 56 data bytes b_1 | 64 bytes from 192.168.0.2: seq=0 ttl=64 time=0.081 ms b_1 | 64 bytes from 192.168.0.2: seq=1 ttl=64 time=0.088 ms b_1 | 64 bytes from 192.168.0.2: seq=2 ttl=64 time=0.122 ms a_1 | PING b (192.168.0.3): 56 data bytes a_1 | 64 bytes from 192.168.0.3: seq=0 ttl=64 time=0.339 ms Networks Link container to many networks with adding list in service configuration. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up service \"b\" refers to undefined network othernetwork: invalid compose project Error due to othernetwork missing. We add it to networks section in configuration file and then to services. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b networks: - 'othernetwork' b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork othernetwork: driver: bridge test: $ docker-compose up [+] Running 3/3 \u283f Network myproject_othernetwork Created 0.0s \u283f Container myproject_a_1 Created 0.1s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (192.168.48.2): 56 data bytes b_1 | 64 bytes from 192.168.48.2: seq=0 ttl=64 time=0.122 ms b_1 | 64 bytes from 192.168.48.2: seq=1 ttl=64 time=0.051 ms b_1 | 64 bytes from 192.168.48.2: seq=2 ttl=64 time=0.196 ms a_1 | PING b (192.168.48.3): 56 data bytes a_1 | 64 bytes from 192.168.48.3: seq=0 ttl=64 time=0.252 ms b_1 | 64 bytes from 192.168.48.2: seq=3 ttl=64 time=0.200 ms Sample application Node.js application that increment a counter in a MongoDB. MongoDB We provide volume to handle db data, so, preamble is to \"manually\" create the needed volume: $ docker volume create mydb docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db volumes: mydb: external: true We run db individually to initialize it: $ docker-compose run -d db 39cf.. $ docker container exec -it 39cf sh $c mongo > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1a03ac9a303a408034aca\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1a03ac9a303a408034aca\"), \"count\" : 0 } > exit bye $c exit $ docker container stop 39cf In MongoDB, volume that contain the database may not be mounted anywhere. MongoDB will specifically search for database in '/data/db' folder. No need to open specific port(s) for containers that run on same network. By default all ports are available for containers that run on same network. Node.js Chapter y Sub chapter y.1 ...","title":"Compose - 08 - Use"},{"location":"docker/8-compose-use/#compose-8-use","text":"Docker Compose - Use","title":"Compose - 8 - Use"},{"location":"docker/8-compose-use/#introduction","text":"Application = - Container Web server + - Container Database Setup: - Ports - Volumes - Network - Environment Docker Compose, talking about service. One Application = (is composed of) Many Services (containers that communicate with each others). Docker Compose is a CLI that read 'docker-compose.yml' file. First, install Docker Compose and check installation and version by typing in a terminal: $ docker-compose version","title":"Introduction"},{"location":"docker/8-compose-use/#first-use","text":"'docker-compose ..' command(s) always refer to folder from where command is launched and context of 'docker-compose.yml' file contained in folder. Yaml format configuration file. Yaml syntax is based on an indented key value format. $ touch docker-compose.yml First, mention version to use to ensure retro-compatibility. To determine which version to specify in 'docker-compose.yml' file header, refer to docker engine version that run on your host machine: $ docker version ... Server: Docker Engine - Community Engine: Version: 20.10.11 ... Then refer to documentation Compose file - Reference and guidelines Second, specify service(s). docker-compose.yml: version: '3.8' services: myalpine: image: alpine $ docker-compose up Alternative to go straight in service's container: $ docker-compose run myapline $c In another console: $ docker-compose ps $ docker-compose ps -a $ docker-compose down Particularity of 'docker-compose down' command is to suppress (don't just stop) all container and network that was launched by previous 'docker-compose up' command. Anonymous volumes are never reused by Docker Compose. It launches new ones each time if declared in configuration. Default command is the one defined in image, for 'alpine' it's '/bin/sh'. To overwrite default command, specify it in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine command: ls Or by adding command directly after service name in run command: $ docker-compose run myalpine ls Or with entry point in exec form (instead of shell) in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine entrypoint: [\"ls\"] Or 'command: [\"ls\"]' instead of 'entrypoint: [\"ls\"]'","title":"First use"},{"location":"docker/8-compose-use/#custom-image","text":"$ touch Dockerfile Dockerfile: FROM alpine CMD [\"/bin/sh\"] docker-compose.yml version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: . $ docker-compose build Have a look to VS Code Docker plugin to have a synthetic view of all Docker ecosystem components, containers, images, network, etc.","title":"Custom image"},{"location":"docker/8-compose-use/#context-and-dockerfile","text":"Specify a context and Dockerfile: $ mkdir backend $ cp Dockerfile backend/DockerfileBackend docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend","title":"Context and Dockerfile"},{"location":"docker/8-compose-use/#arguments","text":"Passing arguments, e.g. create a folder at build, 'Dockerfile' receive args from 'docker-compose.yml'. DockerfileBackend: FROM alpine ARG FOLDER RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test Note the 'arg' indentation with '-' for an array of values (yaml syntax). test: $ docker-compose build $ docker-compose run b $c ls .. test .. Instead of list (- FOLDER=), e.g. for 'args' you may also use an object instead (FOLDER:). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder test: $ docker-compose build $ docker-compose run b $c ls .. myfolder ..","title":"Arguments"},{"location":"docker/8-compose-use/#labels","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test labels: - EMAIL=toto@test.com test: $ docker-compose build $ docker image inspect compose_b:latest | grep EMAIL \"EMAIL\": \"toto@test.com\"","title":"Labels"},{"location":"docker/8-compose-use/#ports","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80","title":"Ports"},{"location":"docker/8-compose-use/#volumes","text":"","title":"Volumes"},{"location":"docker/8-compose-use/#bind","text":"$ mkdir data $ touch data/hello.txt DockerfileBackend.yml: FROM alpine ARG FOLDER WORKDIR /app RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data test: $ docker-compose build $ docker-compose run b $c cd data $c ls $c exit","title":"Bind"},{"location":"docker/8-compose-use/#volumes_1","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: test: $ docker-compose build $ docker-compose run b [+] Running 1/0 \u283f Volume \"compose_datavolume\" Created $c ls data datavolume myfolder $c exit Volume option external to avoid docker-compose to create volume if it does not exist. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: external: true Before testing remove previously created volumes. test: $ docker-compose run b external volume \"\" not found To create anonymous volume, omit source option. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c ls data datavolume datavolumeanonymous myfolder Docker Compose does not always use the same anonymous volume for a service. Therefore, it is advisable to use: $ docker-compose down -v to remove it. -v, --volumes volumes, Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers.","title":"Volumes"},{"location":"docker/8-compose-use/#environment-variables","text":"","title":"Environment Variables"},{"location":"docker/8-compose-use/#from-cli","text":"$ docker-compose run b $c env HOSTNAME=0b9907714155 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app Add environnement variable from command line, value from host machine: $ docker-compose run -e USER b $c env | grep USER USER=toto By default, by not specifying a value, docker-compose search on host machine environnement variable and if find one that match, pass it (e.g. here with USER that do exist on host machine and has a value). Add environnement variable from command line with specified value: $ docker-compose run -e USER=tintin b $c env | grep USER USER=tintin","title":"from cli"},{"location":"docker/8-compose-use/#from-compose-file","text":"Without specifying a value (comes from host machine). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=toto By specifying a value. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER=tintin build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=tintin","title":"from compose file"},{"location":"docker/8-compose-use/#from-env-file","text":"If value of environment variable is not specified, docker compose search for corresponding value in host machine, if not found, search then in '.env' file. .env: NODE_ENV=development docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - NODE_ENV build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep NODE_ENV NODE_ENV=development By specifying an environnement file, all variables contained in it will be imported in container. .env: NODE_ENV=development TEST_ENV=test docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: env_file: - .env build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep _ENV TEST_ENV=test NODE_ENV=development You may have many environnement files. You may specify env file in command line, works only with 'up': $ docker-compose --env-file ./.env up You may use both 'env_file' and 'environnement' for same service. You may specify compose project name instead of current folder with, e.g. in .env file: COMPOSE_PROJECT_NAME=myproject","title":"from .env file"},{"location":"docker/8-compose-use/#network","text":"","title":"Network"},{"location":"docker/8-compose-use/#default","text":"By default docker compose create a network with folder name as a prefix, or with value of 'COMPOSE_PROJECT_NAME' key in project's environnement variable: $ docker-compose up [+] Running 4/4 \u283f Network myproject_default Created .. Note that containers using the network appear in the list ($ docker network inspect myproject_default) only when they are running. Below, we make a test with ping, note that we use shell form (instead of exec (cause: executable file not found in $PATH: unknown)). docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: command: ping a build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 2/2 \u283f Container myproject_a_1 Recreated 0.2s \u283f Container myproject_b_1 Recreated 0.2s Attaching to a_1, b_1 a_1 | PING b (172.29.0.3): 56 data bytes b_1 | PING a (172.29.0.2): 56 data bytes a_1 | 64 bytes from 172.29.0.3: seq=0 ttl=64 time=188.846 ms b_1 | 64 bytes from 172.29.0.2: seq=0 ttl=64 time=0.152 ms","title":"Default"},{"location":"docker/8-compose-use/#links","text":"Links from a container to another one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 3/2 \u283f Network myproject_default Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (172.31.0.2): 56 data bytes b_1 | 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.078 ms b_1 | 64 bytes from 172.31.0.2: seq=1 ttl=64 time=0.190 ms b_1 | 64 bytes from 172.31.0.2: seq=2 ttl=64 time=0.220 ms a_1 | PING b (172.31.0.3): 56 data bytes a_1 | 64 bytes from 172.31.0.3: seq=0 ttl=64 time=0.407 ms b_1 | 64 bytes from 172.31.0.2: seq=3 ttl=64 time=0.305 ms test to ping a and containerA from b: $ docker-compose up -d $ docker-compose exec b sh $c ping a PING a (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.181 ms .. $c ping containerA PING containerA (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.287 ms","title":"Links"},{"location":"docker/8-compose-use/#name","text":"Give network a name to replace the default one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up [+] Running 3/3 \u283f Network mynetwork Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 2.4s Attaching to a_1, b_1 b_1 | PING containerA (192.168.0.2): 56 data bytes b_1 | 64 bytes from 192.168.0.2: seq=0 ttl=64 time=0.081 ms b_1 | 64 bytes from 192.168.0.2: seq=1 ttl=64 time=0.088 ms b_1 | 64 bytes from 192.168.0.2: seq=2 ttl=64 time=0.122 ms a_1 | PING b (192.168.0.3): 56 data bytes a_1 | 64 bytes from 192.168.0.3: seq=0 ttl=64 time=0.339 ms","title":"Name"},{"location":"docker/8-compose-use/#networks","text":"Link container to many networks with adding list in service configuration. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up service \"b\" refers to undefined network othernetwork: invalid compose project Error due to othernetwork missing. We add it to networks section in configuration file and then to services. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b networks: - 'othernetwork' b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork othernetwork: driver: bridge test: $ docker-compose up [+] Running 3/3 \u283f Network myproject_othernetwork Created 0.0s \u283f Container myproject_a_1 Created 0.1s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (192.168.48.2): 56 data bytes b_1 | 64 bytes from 192.168.48.2: seq=0 ttl=64 time=0.122 ms b_1 | 64 bytes from 192.168.48.2: seq=1 ttl=64 time=0.051 ms b_1 | 64 bytes from 192.168.48.2: seq=2 ttl=64 time=0.196 ms a_1 | PING b (192.168.48.3): 56 data bytes a_1 | 64 bytes from 192.168.48.3: seq=0 ttl=64 time=0.252 ms b_1 | 64 bytes from 192.168.48.2: seq=3 ttl=64 time=0.200 ms","title":"Networks"},{"location":"docker/8-compose-use/#sample-application","text":"Node.js application that increment a counter in a MongoDB.","title":"Sample application"},{"location":"docker/8-compose-use/#mongodb","text":"We provide volume to handle db data, so, preamble is to \"manually\" create the needed volume: $ docker volume create mydb docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db volumes: mydb: external: true We run db individually to initialize it: $ docker-compose run -d db 39cf.. $ docker container exec -it 39cf sh $c mongo > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1a03ac9a303a408034aca\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1a03ac9a303a408034aca\"), \"count\" : 0 } > exit bye $c exit $ docker container stop 39cf In MongoDB, volume that contain the database may not be mounted anywhere. MongoDB will specifically search for database in '/data/db' folder. No need to open specific port(s) for containers that run on same network. By default all ports are available for containers that run on same network.","title":"MongoDB"},{"location":"docker/8-compose-use/#nodejs","text":"","title":"Node.js"},{"location":"docker/8-compose-use/#chapter-y","text":"","title":"Chapter y"},{"location":"docker/8-compose-use/#sub-chapter-y1","text":"...","title":"Sub chapter y.1"},{"location":"docker/9-compose-dockerfile/","text":"Compose - 9 - Dockerfile Docker Compose - Dockerfile Chapter y Sub chapter y.1 ...","title":"Compose - 09 - Dockerfile"},{"location":"docker/9-compose-dockerfile/#compose-9-dockerfile","text":"Docker Compose - Dockerfile","title":"Compose - 9 - Dockerfile"},{"location":"docker/9-compose-dockerfile/#chapter-y","text":"","title":"Chapter y"},{"location":"docker/9-compose-dockerfile/#sub-chapter-y1","text":"...","title":"Sub chapter y.1"},{"location":"elasticsearch/elasticsearch/","text":"ElasticSearch Update field Plugin Head Update boolean field with Chrome plugin ElasticSearch Head local: http://localhost:9200/ Other request tab URL http://localhost:9200/index/doc/id to check empty GET to update request _update POST {\"doc\":{\"deleted\":false}} Kibana 5.6 Browse to Dev Tools, Console to get: GET _index/_type/_id to update: POST _index/_type/_id/_update { \"doc\": { \"field\":\"value\" or \"field\":99 or \"field\":false } }","title":"ElasticSearch - Misc"},{"location":"elasticsearch/elasticsearch/#elasticsearch","text":"","title":"ElasticSearch"},{"location":"elasticsearch/elasticsearch/#update-field","text":"","title":"Update field"},{"location":"elasticsearch/elasticsearch/#plugin-head","text":"Update boolean field with Chrome plugin ElasticSearch Head local: http://localhost:9200/ Other request tab URL http://localhost:9200/index/doc/id to check empty GET to update request _update POST {\"doc\":{\"deleted\":false}}","title":"Plugin Head"},{"location":"elasticsearch/elasticsearch/#kibana-56","text":"Browse to Dev Tools, Console to get: GET _index/_type/_id to update: POST _index/_type/_id/_update { \"doc\": { \"field\":\"value\" or \"field\":99 or \"field\":false } }","title":"Kibana 5.6"},{"location":"git/git/","text":"Git cache token to cache token (use token instead of password) (for 15 minutes, by default). src: github $ git config credential.helper cache or for 1 hour $ git config credential.helper 'cache --timeout=3600'","title":"Git - Misc"},{"location":"git/git/#git","text":"","title":"Git"},{"location":"git/git/#cache-token","text":"to cache token (use token instead of password) (for 15 minutes, by default). src: github $ git config credential.helper cache or for 1 hour $ git config credential.helper 'cache --timeout=3600'","title":"cache token"},{"location":"intellij/intellij/","text":"Intellij Search for ; and replace with ;\\r\\n For a file where each values are separated with ';' but need each values on a new line to compare files. replace ; enable regex by ;\\r\\n To revert, do it in Notepad++ with a record sequence","title":"Intellij - Misc"},{"location":"intellij/intellij/#intellij","text":"","title":"Intellij"},{"location":"intellij/intellij/#search-for-and-replace-with-rn","text":"For a file where each values are separated with ';' but need each values on a new line to compare files. replace ; enable regex by ;\\r\\n To revert, do it in Notepad++ with a record sequence","title":"Search for ; and replace with ;\\r\\n"},{"location":"linux/linux/","text":"Linux Compress Decompress Compress (czf) - c compress, -z zip, -f file $ tar -czf /targetfolder/targetfile.tar.gz /sourcefolder Decompress (xzf) - x extract, -z zip, -f file $ tar -xzf targetfile.tar.gz Package List installed $ apt list --installed Info $ apt-cache show packagename Remove $ sudo apt-get --purge autoremove packagename Switch user to root Switch current user to root $ sudo su - Grep lines before after match -B before -A after Stick ne lines just after option $ grep -B2 -A3 pattern infile.txt Copy files from list Copy specific files from a text list of files $ rsync -a sourcefolder --files-from=list.txt destinationfolder Get data between two patterns In error.log . . 05:59:30.024 [nioEventLoopGroup-3-5] ERROR c.l.d.c.ConnectorServerHandlerTCP.parseAndSendMessageTeltonika(177) - class java.util.concurrent.ExecutionException FOR RAW DATA : 0000017d55747fb00003f5380c1be045ce00000000000000000804ef005000c8024503034230fc430f8d440000011007e0fca600 WITH STACKTRACE : {} . . Get data between \"DATA : \" and \" WITH\" (hex raw data) $ cat error.log | sed -nr 's/.*DATA : (.*) WITH.*/\\1/p' Grep patterns from a file -f option, maybe -oF options also $ grep -f patterns_file *.log or $ grep -oFf patterns.txt *.log If result's count's not OK, check by not found pattern (-h option to hide filename in output) $ grep -hoFf patterns.txt *.log | grep -vFf - patterns.txt For list of file For list of file in current folder, do operation. Here we want to have file name, cat content and separate result with a new line $ ll *.txt 1.txt 2.txt 3.txt 4.txt 5.txt $ for f in {2..4}.txt; do echo \"$f\"; cat \"$f\"; printf \"\\n\"; done 2.txt jkl mno pqr 3.txt stu vwx yza 4.txt bcd efg hij Search between timestamp $ sed -rne '/10:50/,/11:05/ p' file Put existing time range in file (10:50 - 11:05). Highlight search result $ grep --color=always -z pattern file | less -R always to transmit color through pipe -z to show everything, not only the matching pattern -R to avoid showing esc char instead of color Delete history 1003 25-04-2016 17:54:52 echo \"Command 1\" 1004 25-04-2016 17:54:54 echo \"Command 2\" 1005 25-04-2016 17:54:57 echo \"Command 3\" 1006 25-04-2016 17:54:59 echo \"Command 4\" 1007 25-04-2016 17:55:01 echo \"Command 5\" 1008 25-04-2016 17:55:03 echo \"Command 6\" 1009 25-04-2016 17:55:07 echo \"Command 7\" 1010 25-04-2016 17:55:09 echo \"Command 8\" 1011 25-04-2016 17:55:11 echo \"Command 9\" 1012 25-04-2016 17:55:14 echo \"Command 10\" $ for h in $(seq 1006 1008); do history -d 1006; done Where is a program How to know where reside a program, e.g. ls? $ which ls /usr/bin/ls $ env $ env | grep PATH Difference Difference of 2 commands output $ diff <(ls test1) <(ls test2) Difference of sorted lists $ sort ok.txt > okSorted.txt $ sort all.txt > allSorted.txt $ diff --new-line-format=\"\" --unchanged-line-format=\"\" allSorted.txt okSorted.txt Mean of a column test.txt (warning on empty lines (maybe at the end)) 1 3 7 $ cat test.txt | awk '{ total += $1 } END { print total/NR }' 3.66667 Median of a column test.txt (warning on empty lines (maybe at the end)) 1 3 7 11 22 45 71 median.awk #/usr/bin/env awk { count[NR] = $1; } END { if (NR % 2) { print count[(NR + 1) / 2]; } else { print (count[(NR / 2)] + count[(NR / 2) + 1]) / 2.0; } } $ cat test.txt | awk -f median.awk 11 Check equal number of values below and above median $ cat test.txt | awk '{if($1 < 11) print $1}' | wc -l 3 $ cat test.txt | awk '{if($1 > 11) print $1}' | wc -l 3 Get nth column from file Get nth column from file with field separated values test.txt column 1 row 1;column 2 row 1;column 3 row 1 column 1 row 2;column 2 row 2;column 3 row 2 column 1 row 3;column 2 row 3;column 3 row 3 $ cat test.txt | awk -F ';' '{print $2}' column 2 row 1 column 2 row 2 column 2 row 3 Conditional $ cat test.txt | awk -F ';' '{if($1 == \"column 1 row 2\") print $2}' column 2 row 2 List files Sorted by sizes and human readable $ ll -S -h Uniq values in a file Uniq values in a file, sorted and counted (first sort is mandatory) test.txt 1 71 3 7 22 1 11 22 45 71 22 $ cat test.txt | sort | uniq -c 2 1 1 11 3 22 1 3 1 45 1 7 2 71 sorted output $ cat test.txt | sort | uniq -c | sort 1 11 1 3 1 45 1 7 2 1 2 71 3 22 revert sorted output $ cat test.txt | sort | uniq -c | sort -r 3 22 2 71 2 1 1 7 1 45 1 3 1 11","title":"Linux - Misc"},{"location":"linux/linux/#linux","text":"","title":"Linux"},{"location":"linux/linux/#compress-decompress","text":"","title":"Compress Decompress"},{"location":"linux/linux/#compress-czf","text":"- c compress, -z zip, -f file $ tar -czf /targetfolder/targetfile.tar.gz /sourcefolder","title":"Compress (czf)"},{"location":"linux/linux/#decompress-xzf","text":"- x extract, -z zip, -f file $ tar -xzf targetfile.tar.gz","title":"Decompress (xzf)"},{"location":"linux/linux/#package","text":"","title":"Package"},{"location":"linux/linux/#list-installed","text":"$ apt list --installed","title":"List installed"},{"location":"linux/linux/#info","text":"$ apt-cache show packagename","title":"Info"},{"location":"linux/linux/#remove","text":"$ sudo apt-get --purge autoremove packagename","title":"Remove"},{"location":"linux/linux/#switch-user-to-root","text":"Switch current user to root $ sudo su -","title":"Switch user to root"},{"location":"linux/linux/#grep-lines-before-after-match","text":"-B before -A after Stick ne lines just after option $ grep -B2 -A3 pattern infile.txt","title":"Grep lines before after match"},{"location":"linux/linux/#copy-files-from-list","text":"Copy specific files from a text list of files $ rsync -a sourcefolder --files-from=list.txt destinationfolder","title":"Copy files from list"},{"location":"linux/linux/#get-data-between-two-patterns","text":"In error.log . . 05:59:30.024 [nioEventLoopGroup-3-5] ERROR c.l.d.c.ConnectorServerHandlerTCP.parseAndSendMessageTeltonika(177) - class java.util.concurrent.ExecutionException FOR RAW DATA : 0000017d55747fb00003f5380c1be045ce00000000000000000804ef005000c8024503034230fc430f8d440000011007e0fca600 WITH STACKTRACE : {} . . Get data between \"DATA : \" and \" WITH\" (hex raw data) $ cat error.log | sed -nr 's/.*DATA : (.*) WITH.*/\\1/p'","title":"Get data between two patterns"},{"location":"linux/linux/#grep-patterns-from-a-file","text":"-f option, maybe -oF options also $ grep -f patterns_file *.log or $ grep -oFf patterns.txt *.log If result's count's not OK, check by not found pattern (-h option to hide filename in output) $ grep -hoFf patterns.txt *.log | grep -vFf - patterns.txt","title":"Grep patterns from a file"},{"location":"linux/linux/#for-list-of-file","text":"For list of file in current folder, do operation. Here we want to have file name, cat content and separate result with a new line $ ll *.txt 1.txt 2.txt 3.txt 4.txt 5.txt $ for f in {2..4}.txt; do echo \"$f\"; cat \"$f\"; printf \"\\n\"; done 2.txt jkl mno pqr 3.txt stu vwx yza 4.txt bcd efg hij","title":"For list of file"},{"location":"linux/linux/#search-between-timestamp","text":"$ sed -rne '/10:50/,/11:05/ p' file Put existing time range in file (10:50 - 11:05).","title":"Search between timestamp"},{"location":"linux/linux/#highlight-search-result","text":"$ grep --color=always -z pattern file | less -R always to transmit color through pipe -z to show everything, not only the matching pattern -R to avoid showing esc char instead of color","title":"Highlight search result"},{"location":"linux/linux/#delete-history","text":"1003 25-04-2016 17:54:52 echo \"Command 1\" 1004 25-04-2016 17:54:54 echo \"Command 2\" 1005 25-04-2016 17:54:57 echo \"Command 3\" 1006 25-04-2016 17:54:59 echo \"Command 4\" 1007 25-04-2016 17:55:01 echo \"Command 5\" 1008 25-04-2016 17:55:03 echo \"Command 6\" 1009 25-04-2016 17:55:07 echo \"Command 7\" 1010 25-04-2016 17:55:09 echo \"Command 8\" 1011 25-04-2016 17:55:11 echo \"Command 9\" 1012 25-04-2016 17:55:14 echo \"Command 10\" $ for h in $(seq 1006 1008); do history -d 1006; done","title":"Delete history"},{"location":"linux/linux/#where-is-a-program","text":"How to know where reside a program, e.g. ls? $ which ls /usr/bin/ls $ env $ env | grep PATH","title":"Where is a program"},{"location":"linux/linux/#difference","text":"Difference of 2 commands output $ diff <(ls test1) <(ls test2) Difference of sorted lists $ sort ok.txt > okSorted.txt $ sort all.txt > allSorted.txt $ diff --new-line-format=\"\" --unchanged-line-format=\"\" allSorted.txt okSorted.txt","title":"Difference"},{"location":"linux/linux/#mean-of-a-column","text":"test.txt (warning on empty lines (maybe at the end)) 1 3 7 $ cat test.txt | awk '{ total += $1 } END { print total/NR }' 3.66667","title":"Mean of a column"},{"location":"linux/linux/#median-of-a-column","text":"test.txt (warning on empty lines (maybe at the end)) 1 3 7 11 22 45 71 median.awk #/usr/bin/env awk { count[NR] = $1; } END { if (NR % 2) { print count[(NR + 1) / 2]; } else { print (count[(NR / 2)] + count[(NR / 2) + 1]) / 2.0; } } $ cat test.txt | awk -f median.awk 11 Check equal number of values below and above median $ cat test.txt | awk '{if($1 < 11) print $1}' | wc -l 3 $ cat test.txt | awk '{if($1 > 11) print $1}' | wc -l 3","title":"Median of a column"},{"location":"linux/linux/#get-nth-column-from-file","text":"Get nth column from file with field separated values test.txt column 1 row 1;column 2 row 1;column 3 row 1 column 1 row 2;column 2 row 2;column 3 row 2 column 1 row 3;column 2 row 3;column 3 row 3 $ cat test.txt | awk -F ';' '{print $2}' column 2 row 1 column 2 row 2 column 2 row 3","title":"Get nth column from file"},{"location":"linux/linux/#conditional","text":"$ cat test.txt | awk -F ';' '{if($1 == \"column 1 row 2\") print $2}' column 2 row 2","title":"Conditional"},{"location":"linux/linux/#list-files","text":"Sorted by sizes and human readable $ ll -S -h","title":"List files"},{"location":"linux/linux/#uniq-values-in-a-file","text":"Uniq values in a file, sorted and counted (first sort is mandatory) test.txt 1 71 3 7 22 1 11 22 45 71 22 $ cat test.txt | sort | uniq -c 2 1 1 11 3 22 1 3 1 45 1 7 2 71 sorted output $ cat test.txt | sort | uniq -c | sort 1 11 1 3 1 45 1 7 2 1 2 71 3 22 revert sorted output $ cat test.txt | sort | uniq -c | sort -r 3 22 2 71 2 1 1 7 1 45 1 3 1 11","title":"Uniq values in a file"},{"location":"mkdocs/mkdocs/","text":"MkDocs Installation $ pip install mkdocs check $ mkdocs --version Initialize current folder $ mkdocs new . Build documentation $ mkdocs build Deploy to github First synchronize current folder with corresponding github repository. $ mkdocs gh-deploy Material for MkDocs (theme) Installation $ pip install mkdocs-material Configuration Simply add the following lines to mkdocs.yml to enable the theme. theme: name: material Link A double dash section title like below ## Node server project Should be referenced like below to be used in a link: #node-server-project To link this section from another markdown file: [Node server project](otherFile.md#node-server-project)","title":"MkDocs - Misc"},{"location":"mkdocs/mkdocs/#mkdocs","text":"","title":"MkDocs"},{"location":"mkdocs/mkdocs/#installation","text":"$ pip install mkdocs check $ mkdocs --version","title":"Installation"},{"location":"mkdocs/mkdocs/#initialize-current-folder","text":"$ mkdocs new .","title":"Initialize current folder"},{"location":"mkdocs/mkdocs/#build-documentation","text":"$ mkdocs build","title":"Build documentation"},{"location":"mkdocs/mkdocs/#deploy-to-github","text":"First synchronize current folder with corresponding github repository. $ mkdocs gh-deploy","title":"Deploy to github"},{"location":"mkdocs/mkdocs/#material-for-mkdocs-theme","text":"","title":"Material for MkDocs (theme)"},{"location":"mkdocs/mkdocs/#installation_1","text":"$ pip install mkdocs-material","title":"Installation"},{"location":"mkdocs/mkdocs/#configuration","text":"Simply add the following lines to mkdocs.yml to enable the theme. theme: name: material","title":"Configuration"},{"location":"mkdocs/mkdocs/#link","text":"A double dash section title like below ## Node server project Should be referenced like below to be used in a link: #node-server-project To link this section from another markdown file: [Node server project](otherFile.md#node-server-project)","title":"Link"},{"location":"mongodb/mongodb/","text":"MongoDB Clear console > cls","title":"MongoDB - Misc"},{"location":"mongodb/mongodb/#mongodb","text":"","title":"MongoDB"},{"location":"mongodb/mongodb/#clear-console","text":"> cls","title":"Clear console"},{"location":"vscode/vscode/","text":"VS Code Switch terminals Alt+up/down left/right arrows to switch between split terminals. Code snippet shortcut Ctrl+space Console code block in markdown file: Ctrl+space, then select fenced codeblock, then select console $ ... Move line Alt + Up/down keys Duplicate line If you want to copy the line to the line above itself, press Shift + Alt + Up Arrow Key. If you want to copy the line to the line below itself, press Shift + Alt + Down Arrow Key. Column select Mouse Shift + Alt then click and drag Keyboard Ctrl + Shift + Alt then use arrow keys","title":"VS Code - Misc"},{"location":"vscode/vscode/#vs-code","text":"","title":"VS Code"},{"location":"vscode/vscode/#switch-terminals","text":"Alt+up/down left/right arrows to switch between split terminals.","title":"Switch terminals"},{"location":"vscode/vscode/#code-snippet-shortcut","text":"Ctrl+space Console code block in markdown file: Ctrl+space, then select fenced codeblock, then select console $ ...","title":"Code snippet shortcut"},{"location":"vscode/vscode/#move-line","text":"Alt + Up/down keys","title":"Move line"},{"location":"vscode/vscode/#duplicate-line","text":"If you want to copy the line to the line above itself, press Shift + Alt + Up Arrow Key. If you want to copy the line to the line below itself, press Shift + Alt + Down Arrow Key.","title":"Duplicate line"},{"location":"vscode/vscode/#column-select","text":"Mouse Shift + Alt then click and drag Keyboard Ctrl + Shift + Alt then use arrow keys","title":"Column select"},{"location":"windows/windows/","text":"Windows find process that uses a port Open CMD prompt as admin C:\\> netstat -ano -p tcp | find \"50307\" Last column shows the PID that uses the port C:\\> netstat --help -a Displays all connections and listening ports. -n Displays addresses and port numbers in numerical form. -o Displays the owning process ID associated with each connection. In PowerShell C:\\> Get-Process -Id (Get-NetTCPConnection -LocalPort 50307).OwningProcess grep equivalent find \"50307\" or findstr 50307 C:\\> netstat -ano -p tcp | findstr 50307 kill process C:\\> taskkill /F /PID pid_number","title":"Windows - Misc"},{"location":"windows/windows/#windows","text":"","title":"Windows"},{"location":"windows/windows/#find-process-that-uses-a-port","text":"Open CMD prompt as admin C:\\> netstat -ano -p tcp | find \"50307\" Last column shows the PID that uses the port C:\\> netstat --help -a Displays all connections and listening ports. -n Displays addresses and port numbers in numerical form. -o Displays the owning process ID associated with each connection. In PowerShell C:\\> Get-Process -Id (Get-NetTCPConnection -LocalPort 50307).OwningProcess","title":"find process that uses a port"},{"location":"windows/windows/#grep-equivalent","text":"find \"50307\" or findstr 50307 C:\\> netstat -ano -p tcp | findstr 50307","title":"grep equivalent"},{"location":"windows/windows/#kill-process","text":"C:\\> taskkill /F /PID pid_number","title":"kill process"}]}