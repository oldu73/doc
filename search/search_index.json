{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to doc Hello, doc ;)","title":"Home"},{"location":"#welcome-to-doc","text":"Hello, doc ;)","title":"Welcome to doc"},{"location":"docker/1-docker-misc/","text":"Docker - 01 - Misc $ = console $c = console inside container","title":"Docker - 01 - Misc"},{"location":"docker/1-docker-misc/#docker-01-misc","text":"$ = console $c = console inside container","title":"Docker - 01 - Misc"},{"location":"docker/10-compose-services/","text":"Compose - 10 - Services Docker Compose - Services Use of Docker Compose with many services. In this chapter we setup a complete development/production environnement close to what we may found in real life projects, sclable and so on. Project architecture Introduction to project architecture: React (Application), could be Vue.js or Angular, would be the same. NGINX (Http request). Node.js (API). MongoDB (database). Developpement NGINX as reverse proxy follow requests: != /api + == /sockjs-node (websocket for live reload feature) -> React. == /api -> Node.js -> MongoDB. Production NGINX as reverse proxy (on big application may also be used as a load balancer) follow requests: != /api -> another NGINX that handle React production build output ('build' folder). == /api -> Node.js -> MongoDB. Setup mkdir fullstack cd fullstack React applicatiion: mkdir client Node.js applicatiion: mkdir api MongoDB database: mkdir db NGINX as a reverse proxy, in charge of dispatching http requests: mkdir reverse-proxy Docker Compose: touch docker-compose.dev.yml touch docker-compose.prod.yml Client configuration Setting up the client configuration cd client npx create-react-app client mv client/* . rm -rf client rm -rf node_modules touch Dockerfile.dev /fullstack/client/Dockerfile.dev: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] /fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 From 'fullstack' folder, we'll let '--build' option to ensure building images before starting containers: code . docker-compose -f docker-compose.dev.yml up --build Test by browsing at localhost:3000 We add a function to '/fullstack/client/src/App.js' file in order to get a counter from api (not ready yet but we prepare here the application in advance). /fullstack/client/src/App.js: import logo from './logo.svg'; import './App.css'; import { useState, useEffect } from 'react'; function App() { const [count, setCount] = useState(); useEffect(() => { async function fetchCount() { try { const response = await fetch('/api/count') if (response.ok) { setCount(await response.json()); } } catch (e) { console.log(e); } } fetchCount(); }, []); return ( <div className=\"App\"> <header className=\"App-header\"> <img src={logo} className=\"App-logo\" alt=\"logo\" /> <p> Edit <code>src/App.js</code> and save to reload. </p> <p> Count : { count } </p> <a className=\"App-link\" href=\"https://reactjs.org\" target=\"_blank\" rel=\"noopener noreferrer\" > Learn React </a> </header> </div> ); } export default App; In Docker Compose logs we may observe succesfull compilation: . . client_1 | webpack 5.65.0 compiled successfully in 191 ms Test again by browsing at localhost:3000 Stop/remove stack: docker-compose -f docker-compose.dev.yml down Note: - webpack is exclusively devoted for development. Set up Node.js API From project root folder: - .../fullstack cd api npm init -y npm i express nodemon mongodb mkdir src cd src touch index.js index.js (from previous node server project) const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); .../fullstack/docker-compose.dev.yml version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 ../fullstack/api touch Dockerfile .../fullstack/api/Dockerfile FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [\"npm\", \"start\"] .../fullstack/api/package.json { \"name\": \"api\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"start\": \"nodemon ./src/index.js\", \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.2\", \"mongodb\": \"^4.3.0\", \"nodemon\": \"^2.0.15\" } } Test API in a terminal from .../fullstack/ folder code . docker-compose -f docker-compose.dev.yml run api Set up database service Add db service to Docker Compose configuration file. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db volumes: dbtest: Initialize database container. From '.../fullstack' folder: docker-compose -f docker-compose.dev.yml run db Now it should be launch and we connect on it in a second treminal: docker container exec -it fullstack_db_run_c97d6cfbd602 sh mongo use test db.count.insertOne({ count: 0 }) exit exit Now it's OK, we may close second terminal and 'Ctrl+c' database container. We may test application with (from '.../fullstack' folder): (code . // it's always better to have VS Code started from application root folder) docker-compose -f docker-compose.dev.yml up Test application by broswsing to http://localhost:3001/api/count We may also observe that React is running by browsing to http://localhost:3000/ Then 'Ctrl-c' to stop stack. Set up the NGINX reverse proxy From '.../fullstack/reverse-proxy' folder: mkdir conf touch conf/dev.conf touch Dockerfile.dev .../fullstack/reverse-proxy/Dockerfile.dev: FROM nginx:latest COPY ./conf/dev.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/dev.conf: server { listen 80; location / { proxy_pass http://client:3000; } location /api { proxy_pass http://api; } location /sockjs-node { proxy_pass http://client:3000; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } } No need to specify port for api because inside stack (network), not from a host point of view, it's listenning on default http port ('80'). Among HTTP standards, by default some 'headers' called 'hop-by-hop' aren't passed by proxy to server and then avoid live reload to work. To fix this, the 'sockjs-node' is a needed technical part to make live reload works. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.dev ports: - 80:80 depends_on: - api - db volumes: dbtest: Test, everything is supposed to work: docker-compose -f docker-compose.dev.yml up --build In a second terminal: docker-compose -f docker-compose.dev.yml ps NAME COMMAND SERVICE STATUS PORTS fullstack_api_1 \"docker-entrypoint.s\u2026\" api running 0.0.0.0:3001->80/tcp fullstack_client_1 \"docker-entrypoint.s\u2026\" client running 0.0.0.0:3000->3000/tcp fullstack_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp fullstack_reverse-proxy_1 \"/docker-entrypoint.\u2026\" reverse-proxy running 0.0.0.0:80->80/tcp We may obeserve then the 4 components composing our application are running. And test by browsing to http://localhost/ , note that there's not need to specify port this time thanks to NGINX that do his job as a reverse proxy by distributing requests through our application by listening on default http port ('80'). By refreshing the page, you also may observe counter increasing. To test live reload edit file '.../fullstack/client/src/App.js' and observe live changes in browser window (even without refreshing the page). We now have a full functionnal development stack that maybe up with only one command: docker-compose -f docker-compose.dev.yml up Set up production configuration Reset Docker environnemnt (if needed): docker system prune -a docker volume prune Client From folder '.../fullstack/client': touch Dockerfile.prod .../fullstack/client/Dockerfile.prod FROM node:alpine as build WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . RUN npm run build FROM nginx:latest COPY --from=build /app/build /usr/share/nginx/html EXPOSE 80 ! Be aware of RUN npm run build, NOT CMD! .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped Start VS Code in '.../fullstack' folder with 'code .' command and then: docker-compose -f docker-compose.prod.yml run -p 80:80 client Browse to http://localhost/ to validate React application is running. API In '.../fullstack/api/src/index.js' notice mongodb connection URL with MONGO_USERNAME and MONGO_PWD credentials that comes from process (production) environnement: const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); In '.../fullstack/api' folder: touch .env .../fullstack/api/.env: MONGO_USERNAME=paul MONGO_PWD=123 We don't want that secret informations to be copied in container: touch .dockerignore .../fullstack/api/.dockerignore: .env .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped Test API with (tanks to \"console.log(process.env)\" in \".../fullstack/api/src/index.js\" we may observe environment variables): docker-compose -f docker-compose.prod.yml run api { . . . MONGO_USERNAME: 'paul', . . MONGO_PWD: '123', . NODE_ENV: 'production', . . } Hit 'Ctrl+c' to stop. DB Secure the database by providing root username and password through an environment file. From folder '.../fullstack/db': touch .env Get credential synthax from 'Environment Variables' section in Mongo image on Docker Hub . In file '.../fullstack/db/.env' add credentials: MONGO_INITDB_ROOT_USERNAME=admin MONGO_INITDB_ROOT_PASSWORD=password Provide environment file (for root user credentials) and external volume for db service in docker compose configuration file. Set up db service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Create volume 'dbprod': docker volume create dbprod Run 'db' container in detached mode from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml run -d db Initialize database by connecting to it with root user credentials. docker container exec -it fullstack_db_run_e9fa9328e2b8 sh mongo use admin db.auth({ user: 'admin', pwd: 'password' }) Create the needed user for API access, the one described in '.env' envrionement file that reside in '.../fullstack/api' folder. db.createUser({ user: 'paul', pwd: '123', roles: [{ role: 'readWrite', db: 'test' }] }) Setup collection for 'count'. use test db.count.insertOne({ count: 0 }) exit exit docker stop fullstack_db_run_e9fa9328e2b8 Now db is ready and API may communicate with it. To test, lauch complete stack with port 80 open for 'api' service (only for testing, because after, in this production context, this is the reverse proxy role to communicate on port 80). .../fullstack/docker-compose.prod.yml: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped ports: - 80:80 db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Launch full stack: docker-compose -f docker-compose.prod.yml up (--build) Browse to localhost/api/count and refresh page to observe counter incrementing. Hit 'Ctrl+c' to stop. Remove port 80 for 'api' service in 'docker-compose.prod.yml' file. Reverse proxy Production configuration file in '.../fullstack/reverse-proxy/conf' folder: touch prod.conf Production Docker file in '.../fullstack/reverse-proxy' folder: touch Dockerfile.prod .../fullstack/reverse-proxy/Dockerfile.prod: FROM nginx:latest COPY ./conf/prod.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/prod.conf: server { listen 80; location / { proxy_pass http://client; } location /api { proxy_pass http://api; } } Add 'reverse-proxy' service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Test, from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml down -v docker-compose -f docker-compose.prod.yml up --build Browse to localhost and refresh page to observe counter incrementing.","title":"Compose - 10 - Services"},{"location":"docker/10-compose-services/#compose-10-services","text":"Docker Compose - Services Use of Docker Compose with many services. In this chapter we setup a complete development/production environnement close to what we may found in real life projects, sclable and so on.","title":"Compose - 10 - Services"},{"location":"docker/10-compose-services/#project-architecture","text":"Introduction to project architecture: React (Application), could be Vue.js or Angular, would be the same. NGINX (Http request). Node.js (API). MongoDB (database).","title":"Project architecture"},{"location":"docker/10-compose-services/#developpement","text":"NGINX as reverse proxy follow requests: != /api + == /sockjs-node (websocket for live reload feature) -> React. == /api -> Node.js -> MongoDB.","title":"Developpement"},{"location":"docker/10-compose-services/#production","text":"NGINX as reverse proxy (on big application may also be used as a load balancer) follow requests: != /api -> another NGINX that handle React production build output ('build' folder). == /api -> Node.js -> MongoDB.","title":"Production"},{"location":"docker/10-compose-services/#setup","text":"mkdir fullstack cd fullstack React applicatiion: mkdir client Node.js applicatiion: mkdir api MongoDB database: mkdir db NGINX as a reverse proxy, in charge of dispatching http requests: mkdir reverse-proxy Docker Compose: touch docker-compose.dev.yml touch docker-compose.prod.yml","title":"Setup"},{"location":"docker/10-compose-services/#client-configuration","text":"Setting up the client configuration cd client npx create-react-app client mv client/* . rm -rf client rm -rf node_modules touch Dockerfile.dev /fullstack/client/Dockerfile.dev: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] /fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 From 'fullstack' folder, we'll let '--build' option to ensure building images before starting containers: code . docker-compose -f docker-compose.dev.yml up --build Test by browsing at localhost:3000 We add a function to '/fullstack/client/src/App.js' file in order to get a counter from api (not ready yet but we prepare here the application in advance). /fullstack/client/src/App.js: import logo from './logo.svg'; import './App.css'; import { useState, useEffect } from 'react'; function App() { const [count, setCount] = useState(); useEffect(() => { async function fetchCount() { try { const response = await fetch('/api/count') if (response.ok) { setCount(await response.json()); } } catch (e) { console.log(e); } } fetchCount(); }, []); return ( <div className=\"App\"> <header className=\"App-header\"> <img src={logo} className=\"App-logo\" alt=\"logo\" /> <p> Edit <code>src/App.js</code> and save to reload. </p> <p> Count : { count } </p> <a className=\"App-link\" href=\"https://reactjs.org\" target=\"_blank\" rel=\"noopener noreferrer\" > Learn React </a> </header> </div> ); } export default App; In Docker Compose logs we may observe succesfull compilation: . . client_1 | webpack 5.65.0 compiled successfully in 191 ms Test again by browsing at localhost:3000 Stop/remove stack: docker-compose -f docker-compose.dev.yml down Note: - webpack is exclusively devoted for development.","title":"Client configuration"},{"location":"docker/10-compose-services/#set-up-nodejs-api","text":"From project root folder: - .../fullstack cd api npm init -y npm i express nodemon mongodb mkdir src cd src touch index.js index.js (from previous node server project) const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); .../fullstack/docker-compose.dev.yml version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 ../fullstack/api touch Dockerfile .../fullstack/api/Dockerfile FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . EXPOSE 80 CMD [\"npm\", \"start\"] .../fullstack/api/package.json { \"name\": \"api\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"start\": \"nodemon ./src/index.js\", \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"express\": \"^4.17.2\", \"mongodb\": \"^4.3.0\", \"nodemon\": \"^2.0.15\" } } Test API in a terminal from .../fullstack/ folder code . docker-compose -f docker-compose.dev.yml run api","title":"Set up Node.js API"},{"location":"docker/10-compose-services/#set-up-database-service","text":"Add db service to Docker Compose configuration file. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db volumes: dbtest: Initialize database container. From '.../fullstack' folder: docker-compose -f docker-compose.dev.yml run db Now it should be launch and we connect on it in a second treminal: docker container exec -it fullstack_db_run_c97d6cfbd602 sh mongo use test db.count.insertOne({ count: 0 }) exit exit Now it's OK, we may close second terminal and 'Ctrl+c' database container. We may test application with (from '.../fullstack' folder): (code . // it's always better to have VS Code started from application root folder) docker-compose -f docker-compose.dev.yml up Test application by broswsing to http://localhost:3001/api/count We may also observe that React is running by browsing to http://localhost:3000/ Then 'Ctrl-c' to stop stack.","title":"Set up database service"},{"location":"docker/10-compose-services/#set-up-the-nginx-reverse-proxy","text":"From '.../fullstack/reverse-proxy' folder: mkdir conf touch conf/dev.conf touch Dockerfile.dev .../fullstack/reverse-proxy/Dockerfile.dev: FROM nginx:latest COPY ./conf/dev.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/dev.conf: server { listen 80; location / { proxy_pass http://client:3000; } location /api { proxy_pass http://api; } location /sockjs-node { proxy_pass http://client:3000; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } } No need to specify port for api because inside stack (network), not from a host point of view, it's listenning on default http port ('80'). Among HTTP standards, by default some 'headers' called 'hop-by-hop' aren't passed by proxy to server and then avoid live reload to work. To fix this, the 'sockjs-node' is a needed technical part to make live reload works. .../fullstack/docker-compose.dev.yml: version: \"3.8\" services: client: build: context: ./client dockerfile: Dockerfile.dev volumes: - type: bind source: ./client target: /app - type: volume target: /app/node_modules ports: - 3000:3000 api: build: context: ./api dockerfile: Dockerfile volumes: - type: bind source: ./api/src target: /app/src ports: - 3001:80 db: image: mongo volumes: - type: volume source: dbtest target: /data/db reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.dev ports: - 80:80 depends_on: - api - db volumes: dbtest: Test, everything is supposed to work: docker-compose -f docker-compose.dev.yml up --build In a second terminal: docker-compose -f docker-compose.dev.yml ps NAME COMMAND SERVICE STATUS PORTS fullstack_api_1 \"docker-entrypoint.s\u2026\" api running 0.0.0.0:3001->80/tcp fullstack_client_1 \"docker-entrypoint.s\u2026\" client running 0.0.0.0:3000->3000/tcp fullstack_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp fullstack_reverse-proxy_1 \"/docker-entrypoint.\u2026\" reverse-proxy running 0.0.0.0:80->80/tcp We may obeserve then the 4 components composing our application are running. And test by browsing to http://localhost/ , note that there's not need to specify port this time thanks to NGINX that do his job as a reverse proxy by distributing requests through our application by listening on default http port ('80'). By refreshing the page, you also may observe counter increasing. To test live reload edit file '.../fullstack/client/src/App.js' and observe live changes in browser window (even without refreshing the page). We now have a full functionnal development stack that maybe up with only one command: docker-compose -f docker-compose.dev.yml up","title":"Set up the NGINX reverse proxy"},{"location":"docker/10-compose-services/#set-up-production-configuration","text":"Reset Docker environnemnt (if needed): docker system prune -a docker volume prune","title":"Set up production configuration"},{"location":"docker/10-compose-services/#client","text":"From folder '.../fullstack/client': touch Dockerfile.prod .../fullstack/client/Dockerfile.prod FROM node:alpine as build WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . RUN npm run build FROM nginx:latest COPY --from=build /app/build /usr/share/nginx/html EXPOSE 80 ! Be aware of RUN npm run build, NOT CMD! .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped Start VS Code in '.../fullstack' folder with 'code .' command and then: docker-compose -f docker-compose.prod.yml run -p 80:80 client Browse to http://localhost/ to validate React application is running.","title":"Client"},{"location":"docker/10-compose-services/#api","text":"In '.../fullstack/api/src/index.js' notice mongodb connection URL with MONGO_USERNAME and MONGO_PWD credentials that comes from process (production) environnement: const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; const MongUrl = process.env.NODE_ENV === 'production' ? `mongodb://${ process.env.MONGO_USERNAME }:${ process.env.MONGO_PWD }@db` : `mongodb://db` console.log(process.env) // to have environnement variables in logs MongoClient.connect(MongUrl, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/api/count', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.all('*', (req, res) => { res.status(404).end(); }); app.listen(80); In '.../fullstack/api' folder: touch .env .../fullstack/api/.env: MONGO_USERNAME=paul MONGO_PWD=123 We don't want that secret informations to be copied in container: touch .dockerignore .../fullstack/api/.dockerignore: .env .../fullstack/docker-compose.prod.yml version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped Test API with (tanks to \"console.log(process.env)\" in \".../fullstack/api/src/index.js\" we may observe environment variables): docker-compose -f docker-compose.prod.yml run api { . . . MONGO_USERNAME: 'paul', . . MONGO_PWD: '123', . NODE_ENV: 'production', . . } Hit 'Ctrl+c' to stop.","title":"API"},{"location":"docker/10-compose-services/#db","text":"Secure the database by providing root username and password through an environment file. From folder '.../fullstack/db': touch .env Get credential synthax from 'Environment Variables' section in Mongo image on Docker Hub . In file '.../fullstack/db/.env' add credentials: MONGO_INITDB_ROOT_USERNAME=admin MONGO_INITDB_ROOT_PASSWORD=password Provide environment file (for root user credentials) and external volume for db service in docker compose configuration file. Set up db service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Create volume 'dbprod': docker volume create dbprod Run 'db' container in detached mode from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml run -d db Initialize database by connecting to it with root user credentials. docker container exec -it fullstack_db_run_e9fa9328e2b8 sh mongo use admin db.auth({ user: 'admin', pwd: 'password' }) Create the needed user for API access, the one described in '.env' envrionement file that reside in '.../fullstack/api' folder. db.createUser({ user: 'paul', pwd: '123', roles: [{ role: 'readWrite', db: 'test' }] }) Setup collection for 'count'. use test db.count.insertOne({ count: 0 }) exit exit docker stop fullstack_db_run_e9fa9328e2b8 Now db is ready and API may communicate with it. To test, lauch complete stack with port 80 open for 'api' service (only for testing, because after, in this production context, this is the reverse proxy role to communicate on port 80). .../fullstack/docker-compose.prod.yml: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped ports: - 80:80 db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped volumes: dbprod: external: true Launch full stack: docker-compose -f docker-compose.prod.yml up (--build) Browse to localhost/api/count and refresh page to observe counter incrementing. Hit 'Ctrl+c' to stop. Remove port 80 for 'api' service in 'docker-compose.prod.yml' file.","title":"DB"},{"location":"docker/10-compose-services/#reverse-proxy","text":"Production configuration file in '.../fullstack/reverse-proxy/conf' folder: touch prod.conf Production Docker file in '.../fullstack/reverse-proxy' folder: touch Dockerfile.prod .../fullstack/reverse-proxy/Dockerfile.prod: FROM nginx:latest COPY ./conf/prod.conf /etc/nginx/conf.d/default.conf EXPOSE 80 .../fullstack/reverse-proxy/conf/prod.conf: server { listen 80; location / { proxy_pass http://client; } location /api { proxy_pass http://api; } } Add 'reverse-proxy' service in '.../fullstack/docker-compose.prod.yml' file: version: '3.8' services: client: build: context: ./client dockerfile: Dockerfile.prod restart: unless-stopped api: build: context: ./api dockerfile: Dockerfile env_file: - ./api/.env environment: NODE_ENV: production restart: unless-stopped depends_on: - db db: image: mongo volumes: - type: volume source: dbprod target: /data/db env_file: - ./db/.env restart: unless-stopped reverse-proxy: build: context: ./reverse-proxy dockerfile: Dockerfile.prod ports: - 80:80 restart: unless-stopped depends_on: - api - db - client volumes: dbprod: external: true Test, from '.../fullstack' folder: docker-compose -f docker-compose.prod.yml down -v docker-compose -f docker-compose.prod.yml up --build Browse to localhost and refresh page to observe counter incrementing.","title":"Reverse proxy"},{"location":"docker/11-compose-production/","text":"Compose - 11 - Production Docker Compose - Production Almost same components as the ones presented/used in preceding chapter Docker Compose - Services . This time all those component are going to be set to work in production, on a real server. Project components Introduction to project components: Certbot , to get your site on https:// (encrypted communications) with TLS certificate (little lock before address in Internet browser). NGINX (Http request and reverse proxy). React (Application), could be Vue.js or Angular, would be the same. PM2 , process manager (load balancer) for Node.js. Node.js (API), to get better performance it's advised to get one running instance of Node.js by CPU core (on host server). MongoDB (database), only one instance here (scale is out of scope here). GitLab ... Project architecture React (build) / / NGINX / / !=/api / --Certbot (ssl/https) -- NGINX --/ \\ \\ =/api \\ \\ NGINX as reverse proxy (on big application may also be used as a load balancer) follow requests: != /api -> another NGINX that handle React production build output ('build' folder). == /api -> Node.js -> MongoDB. Chapter y Sub chapter y.1 ... NGINX React Node.js webpack Docker Compose MongoDB Certbot PM2","title":"Compose - 11 - Production"},{"location":"docker/11-compose-production/#compose-11-production","text":"Docker Compose - Production Almost same components as the ones presented/used in preceding chapter Docker Compose - Services . This time all those component are going to be set to work in production, on a real server.","title":"Compose - 11 - Production"},{"location":"docker/11-compose-production/#project-components","text":"Introduction to project components: Certbot , to get your site on https:// (encrypted communications) with TLS certificate (little lock before address in Internet browser). NGINX (Http request and reverse proxy). React (Application), could be Vue.js or Angular, would be the same. PM2 , process manager (load balancer) for Node.js. Node.js (API), to get better performance it's advised to get one running instance of Node.js by CPU core (on host server). MongoDB (database), only one instance here (scale is out of scope here). GitLab ...","title":"Project components"},{"location":"docker/11-compose-production/#project-architecture","text":"React (build) / / NGINX / / !=/api / --Certbot (ssl/https) -- NGINX --/ \\ \\ =/api \\ \\ NGINX as reverse proxy (on big application may also be used as a load balancer) follow requests: != /api -> another NGINX that handle React production build output ('build' folder). == /api -> Node.js -> MongoDB.","title":"Project architecture"},{"location":"docker/11-compose-production/#chapter-y","text":"","title":"Chapter y"},{"location":"docker/11-compose-production/#sub-chapter-y1","text":"... NGINX React Node.js webpack Docker Compose MongoDB Certbot PM2","title":"Sub chapter y.1"},{"location":"docker/2-docker-basis/","text":"Docker - 02 - Basis Node Command to launch node with app.js in folder app CMD [\"node\", \"app/app.js\"] Then from terminal, build command with -t argument to name:tag image . to mention path of Dockerfile in current directory: $ docker build -t node-test-001:latest . To check: $ docker images (or $ docker image ls) To test: $ docker run node-test-001 Hello, world! To auto delete container after execution, use \u2013rm option: $ docker run --rm node-test-001 Hello, world! Check if node is installed on host machine: $ node --version v14.16.1 Test app.js on host machine (if node is installed): $ node app.js Hello, world! VS Code VS Code install Microsoft Docker extension Docker file in short My image -> Docker file =: Base image Modification Action Add Alpine package Add/del Alpine package A base image (e.g. Alpine) is not based on any other image. Add or del package in Alpine $c apk update $c apk add grep $c apk del grep Running container Running container as a running process To demonstrate running container is just a running process on host machine $ docker run -d redis In contrary of a virtual machine (VM) a container is \"just\" a running process sharing Linux kernel on host machine. SRC: - https://stackoverflow.com/questions/64787125/why-doesnt-htop-show-my-docker-processes-using-wsl2 To see running process on WSL use command prompt (would be \"$ sudo ps -ef | grep redis\" on a Linux machine): C:\\> wsl -d docker-desktop top (or C:\\> wsl -d docker-desktop ps -ef) If you want htop, you need to install it first: C:\\> wsl -d docker-desktop apk update C:\\> wsl -d docker-desktop apk add htop ... 0% redis-server *:6379 To kill a process on host machine, WSL: C:\\> wsl -d docker-desktop killall redis-server To kill a process on host machine, Linux: $ sudo killall redis-server Running: C:\\> wsl -d docker-desktop htop See that container isn't running anymore: $ docker container ls Disk usage Show docker disk usage $ docker system df Show detailed information on space usage, -v, --verbose docker system df -v Consumed resource to see live consuming resources of running containers: $ docker container stats Inspect to inspect all configuration of a container $ docker container inspect alpinetest001 Running process Show running process in a container from host $ docker container top alpinetest001 See the difference from inside the container $ docker attach alpine001 update $c apk update add bash $c apk add bash test bash $c bash $c echo $0 bash ctrl+p+q $ docker exec -it alpinetest001 bash if ps not present, install it with: $c apk update && apk add procps then: $c ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 16:15 pts/0 00:00:00 /bin/sh root 16 1 0 16:27 pts/0 00:00:00 bash root 17 0 0 16:28 pts/1 00:00:00 bash root 31 17 0 16:33 pts/1 00:00:00 ps -ef sh and bash does not have parent process ID (PPID) = '0' because of container isolation, container does not see running processes of host machine neither the ones belonging to other containers. Modified file Show modified file in a container: A = added, D = deleted, C = modified $ docker container diff alpinetest001 A /test A /test/test1.txt A /test/test2.txt C /root A /root/.ash_history Copy file copy file from host to container, docker cp path container:path docker cp test1.txt alpinetest001:test copy file from container to host, docker cp container:path path docker cp alpinetest001:test/test2.txt . Execute command in container Execute a command in a container without using terminal $ docker container exec alpine001 mkdir testdir $ docker container exec alpine001 touch /testdir/hello.txt other e.g. $ docker run -d --name redis001 redis $ docker exec -it redis001 redis-cli redis command: set cle 42 get cle exit Get shell in container Get a shell, in a no matter which running container it is: $ docker exec -it redis001 bash $c echo $0 bash if bash not installed in container (e.g. with alpine) you may use sh instead: (if both presents, both works (e.g. redis) $ docker exec -it redis001 sh $c echo $0 sh $ docker run -it -d --name alpine001 alpine $ docker exec -it alpine001 bash OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \"bash\": executable file not found in $PATH: unknown $ docker exec -it alpine001 sh $c echo $0 sh Pause/unpause a container $ docker container start -ai alpine001 $ docker container pause alpine001 $ docker container unpause alpine001 Rename a container rename a container named \"beautiful_leakey\" $ docker container rename beautiful_leakey alpine001 not allowed to rename image Postgres with environnement variable $ docker run -d --name mongo mongo $ docker run -d --name redis redis $ docker run -d --name postgres postgres $ docker logs postgres Error: ... $ docker container rm postgres $ docker container run --name postgres -d -e POSTGRES_HOST_AUTH_METHOD=trust postgres Stop container Stop all running container at once docker stop $(docker ps -aq) Suppress all !Suppress all not used (stopped container(s) and not used for the rest)! $ docker system prune -a Remove image $ docker image rm NAME_OR_ID remove unused images (dangling = image is not tagged and no other image depends on it) $ docker image prune -a Remove container try to remove a running container Launch a background test named redis container with: $ docker run --name test -d redis then try to remove it with: $ docker container rm test Error - Stop the container before attempting removal or force remove Force remove running container: $ docker container rm -f test $ docker run --name test1 -d redis $ docker run --name test2 -d redis $ docker run --name test3 -d redis $ docker container rm -f test1 test2 test3 remove all stopped container $ docker container prune Image, images $ docker images $ docker image ls redis Help to get help, simply type: $ docker help on a command: $ docker ps --help Redis $ docker run redis $ docker run -d redis Alpine $ docker run alpine -i, interactive mode $ docker run -i alpine $c ls . . dev etc home . . . exit -t, terminal -> prompt $ docker run -it alpine (= docker run -it alpine sh) $c echo $0 // check which shell (/bin/sh) $c apk update $c apk add bash $c bash $c echo $0 // check which shell (bash) start in foreground mode $ docker run alpine ping google.ch $ docker run alpine echo hello start in background mode (-d = detach (!= daemon)) $ docker run -d alpine ping google.fr 3593... docker logs 3593... $ docker logs 8e86... --follow Available image show available image(s) $ docker images None running container check none running container with (-a show all containers (default shows just running)): $ docker container ls -a Ubuntu $ docker run -it ubuntu bash $c cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"20.04.3 LTS (Focal Fossa)\" ... to exit container and stop it $c ctrl + d then to start/stop it again, e.g container name is 'trusting_yalow' $ docker start trusting_yalow $ docker stop trusting_yalow then to bash into it $ docker attach trusting_yalow to detach from a docker container without stopping it $c ctrl + p + q Hello, world! $ docker run hello-world Info $ docker info","title":"Docker - 02 - Basis"},{"location":"docker/2-docker-basis/#docker-02-basis","text":"","title":"Docker - 02 - Basis"},{"location":"docker/2-docker-basis/#node","text":"Command to launch node with app.js in folder app CMD [\"node\", \"app/app.js\"] Then from terminal, build command with -t argument to name:tag image . to mention path of Dockerfile in current directory: $ docker build -t node-test-001:latest . To check: $ docker images (or $ docker image ls) To test: $ docker run node-test-001 Hello, world! To auto delete container after execution, use \u2013rm option: $ docker run --rm node-test-001 Hello, world! Check if node is installed on host machine: $ node --version v14.16.1 Test app.js on host machine (if node is installed): $ node app.js Hello, world!","title":"Node"},{"location":"docker/2-docker-basis/#vs-code","text":"VS Code install Microsoft Docker extension","title":"VS Code"},{"location":"docker/2-docker-basis/#docker-file-in-short","text":"My image -> Docker file =: Base image Modification Action","title":"Docker file in short"},{"location":"docker/2-docker-basis/#add-alpine-package","text":"Add/del Alpine package A base image (e.g. Alpine) is not based on any other image. Add or del package in Alpine $c apk update $c apk add grep $c apk del grep","title":"Add Alpine package"},{"location":"docker/2-docker-basis/#running-container","text":"Running container as a running process To demonstrate running container is just a running process on host machine $ docker run -d redis In contrary of a virtual machine (VM) a container is \"just\" a running process sharing Linux kernel on host machine. SRC: - https://stackoverflow.com/questions/64787125/why-doesnt-htop-show-my-docker-processes-using-wsl2 To see running process on WSL use command prompt (would be \"$ sudo ps -ef | grep redis\" on a Linux machine): C:\\> wsl -d docker-desktop top (or C:\\> wsl -d docker-desktop ps -ef) If you want htop, you need to install it first: C:\\> wsl -d docker-desktop apk update C:\\> wsl -d docker-desktop apk add htop ... 0% redis-server *:6379 To kill a process on host machine, WSL: C:\\> wsl -d docker-desktop killall redis-server To kill a process on host machine, Linux: $ sudo killall redis-server Running: C:\\> wsl -d docker-desktop htop See that container isn't running anymore: $ docker container ls","title":"Running container"},{"location":"docker/2-docker-basis/#disk-usage","text":"Show docker disk usage $ docker system df Show detailed information on space usage, -v, --verbose docker system df -v","title":"Disk usage"},{"location":"docker/2-docker-basis/#consumed-resource","text":"to see live consuming resources of running containers: $ docker container stats","title":"Consumed resource"},{"location":"docker/2-docker-basis/#inspect","text":"to inspect all configuration of a container $ docker container inspect alpinetest001","title":"Inspect"},{"location":"docker/2-docker-basis/#running-process","text":"Show running process in a container from host $ docker container top alpinetest001 See the difference from inside the container $ docker attach alpine001 update $c apk update add bash $c apk add bash test bash $c bash $c echo $0 bash ctrl+p+q $ docker exec -it alpinetest001 bash if ps not present, install it with: $c apk update && apk add procps then: $c ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 16:15 pts/0 00:00:00 /bin/sh root 16 1 0 16:27 pts/0 00:00:00 bash root 17 0 0 16:28 pts/1 00:00:00 bash root 31 17 0 16:33 pts/1 00:00:00 ps -ef sh and bash does not have parent process ID (PPID) = '0' because of container isolation, container does not see running processes of host machine neither the ones belonging to other containers.","title":"Running process"},{"location":"docker/2-docker-basis/#modified-file","text":"Show modified file in a container: A = added, D = deleted, C = modified $ docker container diff alpinetest001 A /test A /test/test1.txt A /test/test2.txt C /root A /root/.ash_history","title":"Modified file"},{"location":"docker/2-docker-basis/#copy-file","text":"copy file from host to container, docker cp path container:path docker cp test1.txt alpinetest001:test copy file from container to host, docker cp container:path path docker cp alpinetest001:test/test2.txt .","title":"Copy file"},{"location":"docker/2-docker-basis/#execute-command-in-container","text":"Execute a command in a container without using terminal $ docker container exec alpine001 mkdir testdir $ docker container exec alpine001 touch /testdir/hello.txt other e.g. $ docker run -d --name redis001 redis $ docker exec -it redis001 redis-cli redis command: set cle 42 get cle exit","title":"Execute command in container"},{"location":"docker/2-docker-basis/#get-shell-in-container","text":"Get a shell, in a no matter which running container it is: $ docker exec -it redis001 bash $c echo $0 bash if bash not installed in container (e.g. with alpine) you may use sh instead: (if both presents, both works (e.g. redis) $ docker exec -it redis001 sh $c echo $0 sh $ docker run -it -d --name alpine001 alpine $ docker exec -it alpine001 bash OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \"bash\": executable file not found in $PATH: unknown $ docker exec -it alpine001 sh $c echo $0 sh","title":"Get shell in container"},{"location":"docker/2-docker-basis/#pauseunpause-a-container","text":"$ docker container start -ai alpine001 $ docker container pause alpine001 $ docker container unpause alpine001","title":"Pause/unpause a container"},{"location":"docker/2-docker-basis/#rename-a-container","text":"rename a container named \"beautiful_leakey\" $ docker container rename beautiful_leakey alpine001 not allowed to rename image","title":"Rename a container"},{"location":"docker/2-docker-basis/#postgres-with-environnement-variable","text":"$ docker run -d --name mongo mongo $ docker run -d --name redis redis $ docker run -d --name postgres postgres $ docker logs postgres Error: ... $ docker container rm postgres $ docker container run --name postgres -d -e POSTGRES_HOST_AUTH_METHOD=trust postgres","title":"Postgres with environnement variable"},{"location":"docker/2-docker-basis/#stop-container","text":"Stop all running container at once docker stop $(docker ps -aq)","title":"Stop container"},{"location":"docker/2-docker-basis/#suppress-all","text":"!Suppress all not used (stopped container(s) and not used for the rest)! $ docker system prune -a","title":"Suppress all"},{"location":"docker/2-docker-basis/#remove-image","text":"$ docker image rm NAME_OR_ID remove unused images (dangling = image is not tagged and no other image depends on it) $ docker image prune -a","title":"Remove image"},{"location":"docker/2-docker-basis/#remove-container","text":"try to remove a running container Launch a background test named redis container with: $ docker run --name test -d redis then try to remove it with: $ docker container rm test Error - Stop the container before attempting removal or force remove Force remove running container: $ docker container rm -f test $ docker run --name test1 -d redis $ docker run --name test2 -d redis $ docker run --name test3 -d redis $ docker container rm -f test1 test2 test3 remove all stopped container $ docker container prune","title":"Remove container"},{"location":"docker/2-docker-basis/#image-images","text":"$ docker images $ docker image ls redis","title":"Image, images"},{"location":"docker/2-docker-basis/#help","text":"to get help, simply type: $ docker help on a command: $ docker ps --help","title":"Help"},{"location":"docker/2-docker-basis/#redis","text":"$ docker run redis $ docker run -d redis","title":"Redis"},{"location":"docker/2-docker-basis/#alpine","text":"$ docker run alpine -i, interactive mode $ docker run -i alpine $c ls . . dev etc home . . . exit -t, terminal -> prompt $ docker run -it alpine (= docker run -it alpine sh) $c echo $0 // check which shell (/bin/sh) $c apk update $c apk add bash $c bash $c echo $0 // check which shell (bash) start in foreground mode $ docker run alpine ping google.ch $ docker run alpine echo hello start in background mode (-d = detach (!= daemon)) $ docker run -d alpine ping google.fr 3593... docker logs 3593... $ docker logs 8e86... --follow","title":"Alpine"},{"location":"docker/2-docker-basis/#available-image","text":"show available image(s) $ docker images","title":"Available image"},{"location":"docker/2-docker-basis/#none-running-container","text":"check none running container with (-a show all containers (default shows just running)): $ docker container ls -a","title":"None running container"},{"location":"docker/2-docker-basis/#ubuntu","text":"$ docker run -it ubuntu bash $c cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"20.04.3 LTS (Focal Fossa)\" ... to exit container and stop it $c ctrl + d then to start/stop it again, e.g container name is 'trusting_yalow' $ docker start trusting_yalow $ docker stop trusting_yalow then to bash into it $ docker attach trusting_yalow to detach from a docker container without stopping it $c ctrl + p + q","title":"Ubuntu"},{"location":"docker/2-docker-basis/#hello-world","text":"$ docker run hello-world","title":"Hello, world!"},{"location":"docker/2-docker-basis/#info","text":"$ docker info","title":"Info"},{"location":"docker/3-docker-dockerfile/","text":"Docker - 03 - Docker File Image Variants $ docker pull node:slim node:latest = 992MB VS node:slim = 242MB tag tag to tag image after build $ docker image tag mynode:latest mynode:1.0 history Show the history of an image $ docker history mynode:latest IMAGE CREATED CREATED BY SIZE COMMENT 1a8f184ef896 8 minutes ago sh 42.4MB 14119a10abf4 2 months ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 2 months ago /bin/sh -c #(nop) ADD file:aad4290d27580cc1a\u2026 5.6MB logs $ docker container logs redis-4.0-001 -f to follow -t timestamp COMMIT Snapshot a container to image $ docker run -it alpine sh # mkdir app open a new terminal to copy app.js \"manually\" to app folder $ docker container cp app.js ed6:/app/ then from inside container install node.js $c apk add --update nodejs then quit container and from host terminal $ docker container commit -c 'CMD [\"node\", \"/app/app.js\"]' ed6 mynode $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode latest 1a8f184ef896 6 seconds ago 48MB .. $ docker run --rm mynode hello node-test-010 LABEL LABEL to add meta information LABEL MAINTAINER=oldu73@gmail.com LABEL version=1.0 $ docker build -t node10 . $ docker image inspect node10:latest | less /oldu .. \"MAINTAINER\": \"oldu73@gmail.com\", \"version\": \"1.0\" } .. ENV key value Usable in container, available as environment variable: ENV environment=production $ docker build -t node10 . $ docker run -it node10 sh /app $c env HOSTNAME=ac68969910b7 SHLVL=1 HOME=/root environment=production TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app ARG Argument available at build time only: ARG folder ARG file then WORKDIR $folder COPY $file . then $ docker build --build-arg folder=/app --build-arg file=app.js -t node-test-008 . then if you try to retriev ARGs by typing env inside the container you do not retrieve it because they are available only at build time: $ docker run --rm -it node-test-008 sh /app # env HOSTNAME=22cc31c49889 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app You may also put a default value: ARG folder=/app then $ docker build --build-arg file=app.js -t node-test-008 . Override entry point You can still override the entry point with the --entrypoint option: $ docker run --rm --entrypoint=\"echo\" node:test \"Hi, earth ;)\" or $ docker run -it --entrypoint=\"/bin/sh\" node:test Docker default entry point By default, Docker has a default entry point which is \"/bin/sh -c\" but does not have a default command. $ man sh -> /-c -c Read commands from the command_string operand instead of from the standard input. Special parameter 0 will be set from the command_name operand and the positional parameters ($1, $2, etc.) set from the remaining argument operands. ENTRYPOINT and CMD May have ENTRYPOINT and CMD: ENTRYPOINT [\"echo\"] CMD [\"hello\"] $ docker run --rm node:test hello then you may override hello in run parameter: $ docker run --rm node:test world world exec form [] exec form -> recommended .. shell form, like you would type the command in a terminal ENTRYPOINT instead CMD ENTRYPOINT instead CMD avoid availability for end user to replace Dockerfile CMD by typing one at the end of run terminal command: ENTRYPOINT [\"node\", \"app.js\"] in Dockerfile, then: $ docker run --rm node:test Bonjour or $ docker run --rm node:test echo test Bonjour same same ;-), echo test at the end is not taking under consideration Command at the end of run Typing a command at the end of the run command replace the one in Dockerfile: $ docker run --rm node:test echo test test even if \"CMD [\"node\", \"app.js\"]\" in Dockerfile Remove dangling images Remove dangling ( ) images: $ docker image prune For removing dangling and ununsed images: $ docker image prune -a Docker build no output Docker build not showing any output from commands(Dockerfile RUN): Dockerfile .. RUN echo hello Don't show anything in console at build. Use legacy mode by adding 'DOCKER_BUILDKIT=0' in front of docker build: $ DOCKER_BUILDKIT=0 docker build -t test:latest . .. Step 2/2 : RUN echo hello ---> Running in 3d9c96daa522 hello or (new fashion) with \"--progress=plain --no-cache\" after build command: $ docker build --progress=plain --no-cache -t node-test-007:latest . [3/5] RUN echo \"Hello, world!\" sha256:54040767d950b92027e2e377a0938fd42b89a34fa5d76e3ce281deacda0f1959 0.281 Hello, world! DONE 0.3s List only container names To list only names of all containers: $ docker ps -a --format='{{.Names}}' ENV 'ENV', environment variable: Dockerfile: - Base image - Test environment variable FROM alpine ENV DIR=/app WORKDIR ${DIR}/back then.. $ docker build -t node-test-006:latest . then.. $ docker run -it node-test-006 sh $c pwd /app/back RUN RUN exist in 'exec' and 'shell' mode (which is 'sh' by default). exec: RUN [\"/bin/bash\", \"-c\", \"echo Bonjour !\"] shell: RUN echo \"Bonjour !\" CMD Remove CMD line to test container in interactive mode, then build: $ docker build -t node-test-005:test . Launch a container in interactive mode with sh as shell. Don't forget to mention image tag after ':' as long as it ain't 'latest', and to mention the shell at the end, 'sh': $ docker run -it node-test-005:test sh /app $c As we can see, we are directly in 'app' folder. And by typing 'echo $0' to check shell is indeed, 'sh': $c echo $0 sh And check 'node' version: $c node --version v14.18.1 And test 'app.js' (in app.js -> console.log('Hi test 005');): $c node app.js Hi test 005 WORKDIR WORKDIR define working directory in image: WORKDIR /app Then, for COPY command, no need to specify destination directory: COPY ./app.js . Also for CMD: CMD [\"node\", \"app.js\"] WORKDIR can be changed during the Dockerfile by being filled in again. WORKDIR can create folders if they do not exist (this saves us a mkdir). FROM Only one FROM command by Dockerfile VS Code Dockerfile command VS Code, in a Dockerfile, hit ctrl+space to get a list of available commands. Shortcut available due to Docker Microsoft extension installed in VS Code. ADD source destination ADD source destination, similar to COPY but from URL or compressed file. If it's a compressed file it will be automatically uncompressed. Copy context Dockerfile context is current folder. Could not COPY file from parent folder. Remove image with pattern Remove all images that contain a pattern: $ docker image rm $(docker images --format \"{{.Repository}}\" | grep node-test-00) Optimize cache Optimizing cache. Only the RUN, COPY, and ADD instructions create new layers and increase the size of an image. It is therefore necessary to avoid multiplying the RUN commands, and try to group all the necessary commands in a single RUN instruction (multi-line separator '\\'): FROM ubuntu ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update && apt-get install -y \\ git \\ nodejs \\ && rm -rf /var/lib/apt/lists/* It's recommended to put one installation by line, alphabetically sorted. !! It is mandatory to put apt-get update and apt-get install in the same RUN statement. Otherwise you will have serious cache problems.!! For images using Ubuntu or Debian, it is recommended to remove /var/lib/apt/ lists which contains the APT cache with all available packages in order to reduce the size of the image. ENV DEBIAN_FRONTEND=noninteractive allows us to specify to the Debian Package Manager (APT) that we are in a non-interactive environment for the installation. This avoids the prompts requested by some programs during installation (eg Git). Invalidate cache !Important! Invalidate cache at build. If you have following instruction in Dockerfile it will be run only once at first build then cached: RUN apt update && apt dist-upgrade -y To not use a cache, you have to do: docker build --no-cache -t test . Inspect Go template docker inspect with Go template for format parameter. e.g. to retrieve CMD: $ docker inspect --format='{{.Config.Cmd}}' node-test-001 [node app/app.js] Show the history of an image: $ docker image history node-test-001 Image size node image = 900 MB/3 min VS alpine + node install = 50 MB/30 sec => ??? First build of node based image takes around 3 minutes. Intermediate steps are cached by Docker. Second build of node based image takes now only around 3 seconds. Dockerfile build image Docker file, steps to build an image. Instructions: - FROM // pull image from docker hub \\ = layer - RUN // add node / new image/running intermediate container - COPY / = layer new image/running intermediate container - CMD constructed image resulting from the different images, layers, and intermediate containers You can't run commands in an image, so you need intermediate container. Dockerfile context !! Warning !! Create a Dockerfile then build image in a dedicated folder for your application Otherwise, all files/folders contained in where you build image will be sent to the daemon at build time as the context. It is for this reason that you must create the Dockerfile in the folder of your application, or here to test, in a separate folder. If you create your Dockerfile directly in the root / directory, your entire hard drive is sent as context to the daemon! APK apk = Alpine Package Management It is the equivalent of APT for Debian distributions and therefore in particular for Ubuntu apk add --update actually allows you to do apk update first, then apk add. Debian equivalent of: apt update && apt install && lets you do something based on whether the previous command completed successfully - that's why you tend to see it chained as do_something && do_something_else_that_depended_on_something. Furthermore, you also have || which is the logical or, and also ; which is just a separator which doesn't care what happen to the command before. Dockerfile Create a new folder docker-test. Open it with VS Code. In this example we gonna crate a node image (based on Alpine, not on official node image) to simply test console log in a js file. Create a new file named, with VS Code, 'app.js' and type in it: console.log('Hello, world!'); Then, create a new file, in folder, with VS Code, named: Dockerfile Base image Install node Copy js file from local folder to container. If folder does not exist, it will be created. Type following commands in newly created Dockerfile file (exactly respect the case and do not add any extensions): FROM alpine RUN apk add --update nodejs COPY ./app.js /app/","title":"Docker - 03 - Docker File"},{"location":"docker/3-docker-dockerfile/#docker-03-docker-file","text":"","title":"Docker - 03 - Docker File"},{"location":"docker/3-docker-dockerfile/#image-variants","text":"$ docker pull node:slim node:latest = 992MB VS node:slim = 242MB","title":"Image Variants"},{"location":"docker/3-docker-dockerfile/#tag","text":"tag to tag image after build $ docker image tag mynode:latest mynode:1.0","title":"tag"},{"location":"docker/3-docker-dockerfile/#history","text":"Show the history of an image $ docker history mynode:latest IMAGE CREATED CREATED BY SIZE COMMENT 1a8f184ef896 8 minutes ago sh 42.4MB 14119a10abf4 2 months ago /bin/sh -c #(nop) CMD [\"/bin/sh\"] 0B <missing> 2 months ago /bin/sh -c #(nop) ADD file:aad4290d27580cc1a\u2026 5.6MB","title":"history"},{"location":"docker/3-docker-dockerfile/#logs","text":"$ docker container logs redis-4.0-001 -f to follow -t timestamp","title":"logs"},{"location":"docker/3-docker-dockerfile/#commit","text":"Snapshot a container to image $ docker run -it alpine sh # mkdir app open a new terminal to copy app.js \"manually\" to app folder $ docker container cp app.js ed6:/app/ then from inside container install node.js $c apk add --update nodejs then quit container and from host terminal $ docker container commit -c 'CMD [\"node\", \"/app/app.js\"]' ed6 mynode $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode latest 1a8f184ef896 6 seconds ago 48MB .. $ docker run --rm mynode hello node-test-010","title":"COMMIT"},{"location":"docker/3-docker-dockerfile/#label","text":"LABEL to add meta information LABEL MAINTAINER=oldu73@gmail.com LABEL version=1.0 $ docker build -t node10 . $ docker image inspect node10:latest | less /oldu .. \"MAINTAINER\": \"oldu73@gmail.com\", \"version\": \"1.0\" } ..","title":"LABEL"},{"location":"docker/3-docker-dockerfile/#env","text":"key value Usable in container, available as environment variable: ENV environment=production $ docker build -t node10 . $ docker run -it node10 sh /app $c env HOSTNAME=ac68969910b7 SHLVL=1 HOME=/root environment=production TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app","title":"ENV"},{"location":"docker/3-docker-dockerfile/#arg","text":"Argument available at build time only: ARG folder ARG file then WORKDIR $folder COPY $file . then $ docker build --build-arg folder=/app --build-arg file=app.js -t node-test-008 . then if you try to retriev ARGs by typing env inside the container you do not retrieve it because they are available only at build time: $ docker run --rm -it node-test-008 sh /app # env HOSTNAME=22cc31c49889 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app You may also put a default value: ARG folder=/app then $ docker build --build-arg file=app.js -t node-test-008 .","title":"ARG"},{"location":"docker/3-docker-dockerfile/#override-entry-point","text":"You can still override the entry point with the --entrypoint option: $ docker run --rm --entrypoint=\"echo\" node:test \"Hi, earth ;)\" or $ docker run -it --entrypoint=\"/bin/sh\" node:test","title":"Override entry point"},{"location":"docker/3-docker-dockerfile/#docker-default-entry-point","text":"By default, Docker has a default entry point which is \"/bin/sh -c\" but does not have a default command. $ man sh -> /-c -c Read commands from the command_string operand instead of from the standard input. Special parameter 0 will be set from the command_name operand and the positional parameters ($1, $2, etc.) set from the remaining argument operands.","title":"Docker default entry point"},{"location":"docker/3-docker-dockerfile/#entrypoint-and-cmd","text":"May have ENTRYPOINT and CMD: ENTRYPOINT [\"echo\"] CMD [\"hello\"] $ docker run --rm node:test hello then you may override hello in run parameter: $ docker run --rm node:test world world","title":"ENTRYPOINT and CMD"},{"location":"docker/3-docker-dockerfile/#exec-form","text":"[] exec form -> recommended .. shell form, like you would type the command in a terminal","title":"exec form"},{"location":"docker/3-docker-dockerfile/#entrypoint-instead-cmd","text":"ENTRYPOINT instead CMD avoid availability for end user to replace Dockerfile CMD by typing one at the end of run terminal command: ENTRYPOINT [\"node\", \"app.js\"] in Dockerfile, then: $ docker run --rm node:test Bonjour or $ docker run --rm node:test echo test Bonjour same same ;-), echo test at the end is not taking under consideration","title":"ENTRYPOINT instead CMD"},{"location":"docker/3-docker-dockerfile/#command-at-the-end-of-run","text":"Typing a command at the end of the run command replace the one in Dockerfile: $ docker run --rm node:test echo test test even if \"CMD [\"node\", \"app.js\"]\" in Dockerfile","title":"Command at the end of run"},{"location":"docker/3-docker-dockerfile/#remove-dangling-images","text":"Remove dangling ( ) images: $ docker image prune For removing dangling and ununsed images: $ docker image prune -a","title":"Remove dangling images"},{"location":"docker/3-docker-dockerfile/#docker-build-no-output","text":"Docker build not showing any output from commands(Dockerfile RUN): Dockerfile .. RUN echo hello Don't show anything in console at build. Use legacy mode by adding 'DOCKER_BUILDKIT=0' in front of docker build: $ DOCKER_BUILDKIT=0 docker build -t test:latest . .. Step 2/2 : RUN echo hello ---> Running in 3d9c96daa522 hello or (new fashion) with \"--progress=plain --no-cache\" after build command: $ docker build --progress=plain --no-cache -t node-test-007:latest . [3/5] RUN echo \"Hello, world!\" sha256:54040767d950b92027e2e377a0938fd42b89a34fa5d76e3ce281deacda0f1959 0.281 Hello, world! DONE 0.3s","title":"Docker build no output"},{"location":"docker/3-docker-dockerfile/#list-only-container-names","text":"To list only names of all containers: $ docker ps -a --format='{{.Names}}'","title":"List only container names"},{"location":"docker/3-docker-dockerfile/#env_1","text":"'ENV', environment variable: Dockerfile: - Base image - Test environment variable FROM alpine ENV DIR=/app WORKDIR ${DIR}/back then.. $ docker build -t node-test-006:latest . then.. $ docker run -it node-test-006 sh $c pwd /app/back","title":"ENV"},{"location":"docker/3-docker-dockerfile/#run","text":"RUN exist in 'exec' and 'shell' mode (which is 'sh' by default). exec: RUN [\"/bin/bash\", \"-c\", \"echo Bonjour !\"] shell: RUN echo \"Bonjour !\"","title":"RUN"},{"location":"docker/3-docker-dockerfile/#cmd","text":"Remove CMD line to test container in interactive mode, then build: $ docker build -t node-test-005:test . Launch a container in interactive mode with sh as shell. Don't forget to mention image tag after ':' as long as it ain't 'latest', and to mention the shell at the end, 'sh': $ docker run -it node-test-005:test sh /app $c As we can see, we are directly in 'app' folder. And by typing 'echo $0' to check shell is indeed, 'sh': $c echo $0 sh And check 'node' version: $c node --version v14.18.1 And test 'app.js' (in app.js -> console.log('Hi test 005');): $c node app.js Hi test 005","title":"CMD"},{"location":"docker/3-docker-dockerfile/#workdir","text":"WORKDIR define working directory in image: WORKDIR /app Then, for COPY command, no need to specify destination directory: COPY ./app.js . Also for CMD: CMD [\"node\", \"app.js\"] WORKDIR can be changed during the Dockerfile by being filled in again. WORKDIR can create folders if they do not exist (this saves us a mkdir).","title":"WORKDIR"},{"location":"docker/3-docker-dockerfile/#from","text":"Only one FROM command by Dockerfile","title":"FROM"},{"location":"docker/3-docker-dockerfile/#vs-code-dockerfile-command","text":"VS Code, in a Dockerfile, hit ctrl+space to get a list of available commands. Shortcut available due to Docker Microsoft extension installed in VS Code.","title":"VS Code Dockerfile command"},{"location":"docker/3-docker-dockerfile/#add-source-destination","text":"ADD source destination, similar to COPY but from URL or compressed file. If it's a compressed file it will be automatically uncompressed.","title":"ADD source destination"},{"location":"docker/3-docker-dockerfile/#copy-context","text":"Dockerfile context is current folder. Could not COPY file from parent folder.","title":"Copy context"},{"location":"docker/3-docker-dockerfile/#remove-image-with-pattern","text":"Remove all images that contain a pattern: $ docker image rm $(docker images --format \"{{.Repository}}\" | grep node-test-00)","title":"Remove image with pattern"},{"location":"docker/3-docker-dockerfile/#optimize-cache","text":"Optimizing cache. Only the RUN, COPY, and ADD instructions create new layers and increase the size of an image. It is therefore necessary to avoid multiplying the RUN commands, and try to group all the necessary commands in a single RUN instruction (multi-line separator '\\'): FROM ubuntu ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update && apt-get install -y \\ git \\ nodejs \\ && rm -rf /var/lib/apt/lists/* It's recommended to put one installation by line, alphabetically sorted. !! It is mandatory to put apt-get update and apt-get install in the same RUN statement. Otherwise you will have serious cache problems.!! For images using Ubuntu or Debian, it is recommended to remove /var/lib/apt/ lists which contains the APT cache with all available packages in order to reduce the size of the image. ENV DEBIAN_FRONTEND=noninteractive allows us to specify to the Debian Package Manager (APT) that we are in a non-interactive environment for the installation. This avoids the prompts requested by some programs during installation (eg Git).","title":"Optimize cache"},{"location":"docker/3-docker-dockerfile/#invalidate-cache","text":"!Important! Invalidate cache at build. If you have following instruction in Dockerfile it will be run only once at first build then cached: RUN apt update && apt dist-upgrade -y To not use a cache, you have to do: docker build --no-cache -t test .","title":"Invalidate cache"},{"location":"docker/3-docker-dockerfile/#inspect-go-template","text":"docker inspect with Go template for format parameter. e.g. to retrieve CMD: $ docker inspect --format='{{.Config.Cmd}}' node-test-001 [node app/app.js]","title":"Inspect Go template"},{"location":"docker/3-docker-dockerfile/#_1","text":"Show the history of an image: $ docker image history node-test-001","title":""},{"location":"docker/3-docker-dockerfile/#image-size","text":"node image = 900 MB/3 min VS alpine + node install = 50 MB/30 sec => ??? First build of node based image takes around 3 minutes. Intermediate steps are cached by Docker. Second build of node based image takes now only around 3 seconds.","title":"Image size"},{"location":"docker/3-docker-dockerfile/#dockerfile-build-image","text":"Docker file, steps to build an image. Instructions: - FROM // pull image from docker hub \\ = layer - RUN // add node / new image/running intermediate container - COPY / = layer new image/running intermediate container - CMD constructed image resulting from the different images, layers, and intermediate containers You can't run commands in an image, so you need intermediate container.","title":"Dockerfile build image"},{"location":"docker/3-docker-dockerfile/#dockerfile-context","text":"!! Warning !! Create a Dockerfile then build image in a dedicated folder for your application Otherwise, all files/folders contained in where you build image will be sent to the daemon at build time as the context. It is for this reason that you must create the Dockerfile in the folder of your application, or here to test, in a separate folder. If you create your Dockerfile directly in the root / directory, your entire hard drive is sent as context to the daemon!","title":"Dockerfile context"},{"location":"docker/3-docker-dockerfile/#apk","text":"apk = Alpine Package Management It is the equivalent of APT for Debian distributions and therefore in particular for Ubuntu apk add --update actually allows you to do apk update first, then apk add. Debian equivalent of: apt update && apt install && lets you do something based on whether the previous command completed successfully - that's why you tend to see it chained as do_something && do_something_else_that_depended_on_something. Furthermore, you also have || which is the logical or, and also ; which is just a separator which doesn't care what happen to the command before.","title":"APK"},{"location":"docker/3-docker-dockerfile/#dockerfile","text":"Create a new folder docker-test. Open it with VS Code. In this example we gonna crate a node image (based on Alpine, not on official node image) to simply test console log in a js file. Create a new file named, with VS Code, 'app.js' and type in it: console.log('Hello, world!'); Then, create a new file, in folder, with VS Code, named: Dockerfile Base image Install node Copy js file from local folder to container. If folder does not exist, it will be created. Type following commands in newly created Dockerfile file (exactly respect the case and do not add any extensions): FROM alpine RUN apk add --update nodejs COPY ./app.js /app/","title":"Dockerfile"},{"location":"docker/4-docker-dockerhub/","text":"Docker - 04 - Docker Hub export/import for container docker container export/import $ docker build -t mynode . $ docker run -it mynode sh $c touch hello.txt $c exit $ docker container ps -a CONTAINER ID IMAGE 3d8e43e502b0 mynode $ docker container export -o mycontainer.tar 3d8 $ tar -tvf mycontainer.tar $ docker container rm 3d8 $ docker image import mycontainer.tar nodetest $ docker images REPOSITORY TAG nodetest latest $ docker image inspect nodetest:latest Only one layer because exporting a container is like creating an image from a file system. It's not possible to relaunch a container directly from another exported container. You must first create an image with import. tar for image docker image save/load <-> tar $ docker build -t mynode:0.1 . $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode 0.1 c68e7a86d468 8 seconds ago 48MB $ docker image save -o monimage.tar mynode (to compress with gzip: docker save mon_image | gzip > mon_image.tar.gz) $ tar -tvf monimage.tar $ docker image prune -a $ docker image load < monimage.tar or $ docker image load -i mon_image.tar $ docker run --rm mynode:0.1 hello node-test-012 Encrypt identifiers Encrypt your identifiers GNU/Linux $ sudo apt install pass $ gpg2 --gen-key Enter your name and email when requested. Then do: $ wget https://github.com/docker/docker-credential-helpers/releases/download/v0.6.3/docker-credential-pass-v0.6.3-amd64.tar.gz && tar -xf docker-credential-pass-v0.6.3-amd64.tar.gz && chmod +x docker-credential-pass && sudo mv docker-credential-pass /usr/local/bin/ $ pass init \"YOUR NAME\" $ nano ~/.docker/config.json then: { \"credsStore\": \"pass\" } $ docker login Push image Push image to docker hub $ docker login $ docker build -t oldu73/mynode . $ docker image push oldu73/mynode $ docker image prune -a $ docker run --rm oldu73/mynode $ docker logout Docker hub docker image pull docker image push docker image pull/push / :[tag] docker search https://hub.docker.com/ $ docker pull node $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE node latest 7220633f01cd 7 days ago 992MB $ docker run -it --rm node sh $c ls $c node -v1 $c mkdir app $c cd app $c echo \"console.log('Hello, world!');\" > app.js $c node app.js","title":"Docker - 04 - Docker Hub"},{"location":"docker/4-docker-dockerhub/#docker-04-docker-hub","text":"","title":"Docker - 04 - Docker Hub"},{"location":"docker/4-docker-dockerhub/#exportimport","text":"for container docker container export/import $ docker build -t mynode . $ docker run -it mynode sh $c touch hello.txt $c exit $ docker container ps -a CONTAINER ID IMAGE 3d8e43e502b0 mynode $ docker container export -o mycontainer.tar 3d8 $ tar -tvf mycontainer.tar $ docker container rm 3d8 $ docker image import mycontainer.tar nodetest $ docker images REPOSITORY TAG nodetest latest $ docker image inspect nodetest:latest Only one layer because exporting a container is like creating an image from a file system. It's not possible to relaunch a container directly from another exported container. You must first create an image with import.","title":"export/import"},{"location":"docker/4-docker-dockerhub/#tar","text":"for image docker image save/load <-> tar $ docker build -t mynode:0.1 . $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE mynode 0.1 c68e7a86d468 8 seconds ago 48MB $ docker image save -o monimage.tar mynode (to compress with gzip: docker save mon_image | gzip > mon_image.tar.gz) $ tar -tvf monimage.tar $ docker image prune -a $ docker image load < monimage.tar or $ docker image load -i mon_image.tar $ docker run --rm mynode:0.1 hello node-test-012","title":"tar"},{"location":"docker/4-docker-dockerhub/#encrypt-identifiers","text":"Encrypt your identifiers GNU/Linux $ sudo apt install pass $ gpg2 --gen-key Enter your name and email when requested. Then do: $ wget https://github.com/docker/docker-credential-helpers/releases/download/v0.6.3/docker-credential-pass-v0.6.3-amd64.tar.gz && tar -xf docker-credential-pass-v0.6.3-amd64.tar.gz && chmod +x docker-credential-pass && sudo mv docker-credential-pass /usr/local/bin/ $ pass init \"YOUR NAME\" $ nano ~/.docker/config.json then: { \"credsStore\": \"pass\" } $ docker login","title":"Encrypt identifiers"},{"location":"docker/4-docker-dockerhub/#push-image","text":"Push image to docker hub $ docker login $ docker build -t oldu73/mynode . $ docker image push oldu73/mynode $ docker image prune -a $ docker run --rm oldu73/mynode $ docker logout","title":"Push image"},{"location":"docker/4-docker-dockerhub/#docker-hub","text":"docker image pull docker image push docker image pull/push / :[tag] docker search https://hub.docker.com/ $ docker pull node $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE node latest 7220633f01cd 7 days ago 992MB $ docker run -it --rm node sh $c ls $c node -v1 $c mkdir app $c cd app $c echo \"console.log('Hello, world!');\" > app.js $c node app.js","title":"Docker hub"},{"location":"docker/5-docker-nodeserver/","text":"Docker - 05 - Node Server Node Server Image Stats Show resource usage statistic Maybe tried with Node server project running $ docker run --rm -d --name appnode -p 80:80 myapp Then $ docker stats After, open a browser at http://localhost/ address Click a lot on refresh button to see CPU % growing in stats terminal's live view. Detach mode -d option $ docker run --rm -d --name appnode -p 80:80 myapp --rm to remove container automatically after stop Then to go back inside running detached container $ docker exec -it appnode sh .dockerignore In current project folder, create a new file named \".dockerignore\" Add also a sample text file \"hello.txt\" file that maybe contain \"to be ignored\" sentence. Re-build image $ docker build -t myapp . Launch it in interactive mode with sh $ docker run --rm -it myapp sh ls/cat hello.txt file in container output respectively presence/content of hello.txt file. Now list hello.txt file in .dockerignore file # for current folder hello.txt # for first level of folder */hello.txt # for everywhere **/hello.txt # exception with ! **/*.txt !README.txt Re-build image Re-launch it in interactive mode ls output does not contain hello.txt file anymore Optimization Let's say we change listening port of Node server project from 80 to 70 file app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(70); Re-build image $ docker build -t myapp . => [4/4] RUN npm install 7.1s What we observe here is that NPM install is run again although only listening port in app.js has been modified. To avoid this behavior, Docker file should be modified accordingly. Split COPY instruction in two, before and after \"RUN npm install\" to not invalidate cache for dependencies (package.json). Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"app.js\"] And now, on build image after changing listening port in app.js $ docker build -t myapp . => [4/4] RUN npm install 0.0s Redirect port Redirect port from host to container docker run ... -p <hostport>:<containerport> ... -p option: -p, --publish list Publish a container's port(s) to the host To fix Node server project, add missing port redirection to run command: $ docker run --rm -p 80:80 myapp Many containers may listen on same port number because they're isolated. $ docker run --rm -d -p 81:80 myapp $ docker run --rm -d -p 82:80 myapp On the other hand, on the host, only one forwarding on a port is possible. One port = one application! Without opening port, a container may access to Internet. Outgoing traffic is possible. By default, all incoming traffic is blocked, all ports are closed by default. Port http 80 https 443 ssh 22 Node server project Node server project to return a minimal page in a browser at localhost address, with Express (which is a Node.js framework) Our image should have Node.js and its npm package manager. It should have several dependencies: nodemon and express. And it will have to launch the app contained in app.js by default. For the project, we'll create a new Dockerfile in a folder. In the same folder we will also have a package.json file (which allows you to manage the dependencies used) and an app.js file (which will contain our application). In the package.json file therefore have our two dependencies. In the app.js file we just have an Express route which will send in JSON format the character string \"Hello, world!\" for all routes. folder: - /mnt/c/tmp/docker/node-server $ touch package.json edit package.json { \"dependencies\": { \"nodemon\": \"2.0.14\", \"express\": \"4.17.1\" } } $ touch app.js edit app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); $ touch Dockerfile Browse a bit docker hub and look for alpine tagged image more lighter (169MB) than the official one (latest) (992MB) FROM node:alpine WORKDIR /app COPY . . RUN npm install CMD [\"nodemon\", \"app.js\"] then.. $ docker build -t myapp . $ docker image ls $ docker run --rm myapp path error to debug, run in interactive mode with sh to override Dockerfile CMD $ docker run --rm -it myapp sh /app $c env /app $c nodemon sh: nodemon: not found $c cd node_modules/.bin/ /app/node_modules/.bin # ls is-ci mime nodemon /app $c ./node_modules/.bin/nodemon app.js Fix the Docker file with adding value to image's path .. ENV PATH=$PATH:/app/node_modules/.bin .. $ docker build -t myapp . $ docker run --rm -it myapp sh /app $c env | grep PATH PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin /app $c nodemon app.js Now it's OK $ docker run --rm myapp Try \"localhost\" in a browser -> does not work and it's normal because default behavior does not allow to communicate with a container.","title":"Docker - 05 - Node Server"},{"location":"docker/5-docker-nodeserver/#docker-05-node-server","text":"Node Server Image","title":"Docker - 05 - Node Server"},{"location":"docker/5-docker-nodeserver/#stats","text":"Show resource usage statistic Maybe tried with Node server project running $ docker run --rm -d --name appnode -p 80:80 myapp Then $ docker stats After, open a browser at http://localhost/ address Click a lot on refresh button to see CPU % growing in stats terminal's live view.","title":"Stats"},{"location":"docker/5-docker-nodeserver/#detach-mode","text":"-d option $ docker run --rm -d --name appnode -p 80:80 myapp --rm to remove container automatically after stop Then to go back inside running detached container $ docker exec -it appnode sh","title":"Detach mode"},{"location":"docker/5-docker-nodeserver/#dockerignore","text":"In current project folder, create a new file named \".dockerignore\" Add also a sample text file \"hello.txt\" file that maybe contain \"to be ignored\" sentence. Re-build image $ docker build -t myapp . Launch it in interactive mode with sh $ docker run --rm -it myapp sh ls/cat hello.txt file in container output respectively presence/content of hello.txt file. Now list hello.txt file in .dockerignore file # for current folder hello.txt # for first level of folder */hello.txt # for everywhere **/hello.txt # exception with ! **/*.txt !README.txt Re-build image Re-launch it in interactive mode ls output does not contain hello.txt file anymore","title":".dockerignore"},{"location":"docker/5-docker-nodeserver/#optimization","text":"Let's say we change listening port of Node server project from 80 to 70 file app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(70); Re-build image $ docker build -t myapp . => [4/4] RUN npm install 7.1s What we observe here is that NPM install is run again although only listening port in app.js has been modified. To avoid this behavior, Docker file should be modified accordingly. Split COPY instruction in two, before and after \"RUN npm install\" to not invalidate cache for dependencies (package.json). Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"app.js\"] And now, on build image after changing listening port in app.js $ docker build -t myapp . => [4/4] RUN npm install 0.0s","title":"Optimization"},{"location":"docker/5-docker-nodeserver/#redirect-port","text":"Redirect port from host to container docker run ... -p <hostport>:<containerport> ... -p option: -p, --publish list Publish a container's port(s) to the host To fix Node server project, add missing port redirection to run command: $ docker run --rm -p 80:80 myapp Many containers may listen on same port number because they're isolated. $ docker run --rm -d -p 81:80 myapp $ docker run --rm -d -p 82:80 myapp On the other hand, on the host, only one forwarding on a port is possible. One port = one application! Without opening port, a container may access to Internet. Outgoing traffic is possible. By default, all incoming traffic is blocked, all ports are closed by default.","title":"Redirect port"},{"location":"docker/5-docker-nodeserver/#port","text":"http 80 https 443 ssh 22","title":"Port"},{"location":"docker/5-docker-nodeserver/#node-server-project","text":"Node server project to return a minimal page in a browser at localhost address, with Express (which is a Node.js framework) Our image should have Node.js and its npm package manager. It should have several dependencies: nodemon and express. And it will have to launch the app contained in app.js by default. For the project, we'll create a new Dockerfile in a folder. In the same folder we will also have a package.json file (which allows you to manage the dependencies used) and an app.js file (which will contain our application). In the package.json file therefore have our two dependencies. In the app.js file we just have an Express route which will send in JSON format the character string \"Hello, world!\" for all routes. folder: - /mnt/c/tmp/docker/node-server $ touch package.json edit package.json { \"dependencies\": { \"nodemon\": \"2.0.14\", \"express\": \"4.17.1\" } } $ touch app.js edit app.js const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); $ touch Dockerfile Browse a bit docker hub and look for alpine tagged image more lighter (169MB) than the official one (latest) (992MB) FROM node:alpine WORKDIR /app COPY . . RUN npm install CMD [\"nodemon\", \"app.js\"] then.. $ docker build -t myapp . $ docker image ls $ docker run --rm myapp path error to debug, run in interactive mode with sh to override Dockerfile CMD $ docker run --rm -it myapp sh /app $c env /app $c nodemon sh: nodemon: not found $c cd node_modules/.bin/ /app/node_modules/.bin # ls is-ci mime nodemon /app $c ./node_modules/.bin/nodemon app.js Fix the Docker file with adding value to image's path .. ENV PATH=$PATH:/app/node_modules/.bin .. $ docker build -t myapp . $ docker run --rm -it myapp sh /app $c env | grep PATH PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin /app $c nodemon app.js Now it's OK $ docker run --rm myapp Try \"localhost\" in a browser -> does not work and it's normal because default behavior does not allow to communicate with a container.","title":"Node server project"},{"location":"docker/6-docker-datapersistence/","text":"Docker - 06 - Data Persistence Introduction Container = - writable layer (this layer is deleted if the container no longer exists) - image layer(s) (read) Writable layers use UnionFS, slow read write performance, not adapted to host database. To persist data, 3 possibilities: Volumes On Filesystem but managed by Docker, accessible through Docker CLI), mostly advised to use (in /var/lib/docker/volumes/ (not on WSL) but never access it directly. Volumes are stored on but isolated from host machine. Create a volume with Docker CLI command docker volume create Bind mount Manged by Filesystem and accessible from outside of Docker, not recommended. Bind mounts are regular folder and files stored on host machine. TMPFS Temporary File System -> RAM. TMPFS are used to store temporary not persisted data, sensitive information like secret. Bind mount Adapted for: - Sharing configuration files between host and container. - Development environment to share source code and alow live reload. Recommend syntax docker run --mount type=bind,source=<url>,target=<url> image $ mkdir data $ cd data $ touch hello.txt $ cd .. $ docker run --mount type=bind,source=\"$(pwd)\"/data,target=/data -it alpine sh $c ls .. data .. $c cd data $c ls hello.txt Search for Mounts section with inspect CLI command to see mounting details: docker container inspect containerName Development environment Set up of a development environnement for a node server application (c.f. Node server project ). The goal here is to have changes available from host machine (IDE) in container and automatically reloaded by nodemon. !!Warning!! A common mistake is to bind the root folder of a project. E.g. in case of node context, if we do so, the node_modules folder created/populated in container image by \"RUN npm install\" instruction from Dockerfile will be erased. To avoid this unwanted behavior, it's mostly advised to move the source code files modified through IDE on host machine in a dedicated folder (e.g. src). On host machine: $ mkdir node-server $ cd node-server $ mkdir src $ cd src $ touch app.js $ cd .. src/app.js: const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); Dockerfile (in root folder, \"node-server\"): FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] !! Warning !! In above Dockerfile we use -L option for --legacy-watch because in some containerized environnement, application may not restart automatically after file's change. Build image: $ docker build -t myapp . Start a container with new image version: $ docker run --rm -p 80:80 --mount type=bind,source=\"$(pwd)/src\",target=/app/src myapp Now try to edit 'src/app.js' file on host machine to observe nodemon restart in terminal. You may also observe the changes on your browser at 'localhost' address, after refresh. Volumes docker volume - create - inspect - ls - rm - prune old syntax (not advised, c.f. bind) docker run -v <volume-name>:<container-url> image new syntax docker run --mount type=volume,source=<volume-name>,target=<url> image Create New volume $ docker volume create mydata mydata $ docker volume ls DRIVER VOLUME NAME local mydata $ docker volume inspect mydata [ { \"CreatedAt\": \"2021-12-24T06:15:34Z\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/mydata/_data\", \"Name\": \"mydata\", \"Options\": {}, \"Scope\": \"local\" } ] WSL2 volumes are not in /var/lib/docker/volumes/mydata/_data You can find WSL2 volumes under a hidden network share. Open Windows Explorer, and type \\\\wsl$ into the location bar. Hit enter, and it should display your WSL volumes, including the ones for Docker for Windows. WSL2 volumes, in Windows Explorer bar \\\\wsl$\\docker-desktop-data\\version-pack-data\\community\\docker\\volumes New container with bind volume $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c touch hello.txt $c echo 123 > hello.txt ctrl+d $ docker rm containername $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c cat hello.txt 123 Share Backup Restore Share volume between containers $ docker run --mount type=volume,source=mydata,target=/data --name firstcont -it alpine sh $c1 cd data In another terminal $ docker run --mount type=volume,source=mydata,target=/data --name secondcont -it alpine sh $c2 cd data $c2 touch new.txt $c1 ls hello.txt new.txt Another way is volume from container $ docker run --volumes-from firstcont --name thirdcont -it alpine sh Backup volume Compress a volume to a bind folder with tar $ mkdir backup $ docker run --mount type=volume,source=mydata,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -czf /backup/mydata.tar.gz /data Restore volume Extract an archive from a bind folder to a volume $ docker volume create restore $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -xf /backup/mydata.tar.gz -C /data To not have a folder data in a folder data, use tar with option --strip-components 1 $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\",target=/backup -it alpine tar -xf /backup/backup.tar --strip-components 1 -C /data Check volume correctly restored $ docker container run -it --rm --mount source=restore,target=/data alpine sh Volume to persist a database (mongo) For mongo db it consist of mounting a volume with folder /data/db in mongo container $ docker volume create mydb $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer1 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.insertOne({ name: 'jean' }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61caeae2df845609f1835264\") } > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } > exit bye $c exit $ docker container stop mongocontainer1 $ docker container rm mongocontainer1 Container is removed but database is persisted in a volume. $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer2 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } Compass GUI to browse mongo db Should run container with opened port (default 27017). If port is already used on host machine, you may use 27018 for example $ docker run -p 27018:27017 --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer3 mongo Enter in connection field: mongodb://localhost:27018 TMPFS Rarely used, uniquely to keep data in RAM, e.g. secret or status data, works only on Linux system. $ docker run --mount type=tmpfs,target=/data -it alpine sh $c cd data $c touch secret.txt $c ls secret.txt $c exit $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 58f104d6a051 alpine \"sh\" 2 minutes ago Exited (0) 5 seconds ago musing_wilbur With 'TMPFS' if container is in an 'Exited' status, data aren't persisted. Relaunch container to observe that data aren't available anymore. $ docker start -ai musing_wilbur $c cd data $c ls (empty)","title":"Docker - 06 - Data Persistence"},{"location":"docker/6-docker-datapersistence/#docker-06-data-persistence","text":"","title":"Docker - 06 - Data Persistence"},{"location":"docker/6-docker-datapersistence/#introduction","text":"Container = - writable layer (this layer is deleted if the container no longer exists) - image layer(s) (read) Writable layers use UnionFS, slow read write performance, not adapted to host database. To persist data, 3 possibilities:","title":"Introduction"},{"location":"docker/6-docker-datapersistence/#volumes","text":"On Filesystem but managed by Docker, accessible through Docker CLI), mostly advised to use (in /var/lib/docker/volumes/ (not on WSL) but never access it directly. Volumes are stored on but isolated from host machine. Create a volume with Docker CLI command docker volume create","title":"Volumes"},{"location":"docker/6-docker-datapersistence/#bind-mount","text":"Manged by Filesystem and accessible from outside of Docker, not recommended. Bind mounts are regular folder and files stored on host machine.","title":"Bind mount"},{"location":"docker/6-docker-datapersistence/#tmpfs","text":"Temporary File System -> RAM. TMPFS are used to store temporary not persisted data, sensitive information like secret.","title":"TMPFS"},{"location":"docker/6-docker-datapersistence/#bind-mount_1","text":"Adapted for: - Sharing configuration files between host and container. - Development environment to share source code and alow live reload. Recommend syntax docker run --mount type=bind,source=<url>,target=<url> image $ mkdir data $ cd data $ touch hello.txt $ cd .. $ docker run --mount type=bind,source=\"$(pwd)\"/data,target=/data -it alpine sh $c ls .. data .. $c cd data $c ls hello.txt Search for Mounts section with inspect CLI command to see mounting details: docker container inspect containerName","title":"Bind mount"},{"location":"docker/6-docker-datapersistence/#development-environment","text":"Set up of a development environnement for a node server application (c.f. Node server project ). The goal here is to have changes available from host machine (IDE) in container and automatically reloaded by nodemon. !!Warning!! A common mistake is to bind the root folder of a project. E.g. in case of node context, if we do so, the node_modules folder created/populated in container image by \"RUN npm install\" instruction from Dockerfile will be erased. To avoid this unwanted behavior, it's mostly advised to move the source code files modified through IDE on host machine in a dedicated folder (e.g. src). On host machine: $ mkdir node-server $ cd node-server $ mkdir src $ cd src $ touch app.js $ cd .. src/app.js: const express = require('express'); const app = express(); app.get('*', (req, res) => { res.status(200).json('Hello, world!'); }) app.listen(80); Dockerfile (in root folder, \"node-server\"): FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] !! Warning !! In above Dockerfile we use -L option for --legacy-watch because in some containerized environnement, application may not restart automatically after file's change. Build image: $ docker build -t myapp . Start a container with new image version: $ docker run --rm -p 80:80 --mount type=bind,source=\"$(pwd)/src\",target=/app/src myapp Now try to edit 'src/app.js' file on host machine to observe nodemon restart in terminal. You may also observe the changes on your browser at 'localhost' address, after refresh.","title":"Development environment"},{"location":"docker/6-docker-datapersistence/#volumes_1","text":"docker volume - create - inspect - ls - rm - prune old syntax (not advised, c.f. bind) docker run -v <volume-name>:<container-url> image new syntax docker run --mount type=volume,source=<volume-name>,target=<url> image","title":"Volumes"},{"location":"docker/6-docker-datapersistence/#create","text":"","title":"Create"},{"location":"docker/6-docker-datapersistence/#new-volume","text":"$ docker volume create mydata mydata $ docker volume ls DRIVER VOLUME NAME local mydata $ docker volume inspect mydata [ { \"CreatedAt\": \"2021-12-24T06:15:34Z\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/mydata/_data\", \"Name\": \"mydata\", \"Options\": {}, \"Scope\": \"local\" } ] WSL2 volumes are not in /var/lib/docker/volumes/mydata/_data You can find WSL2 volumes under a hidden network share. Open Windows Explorer, and type \\\\wsl$ into the location bar. Hit enter, and it should display your WSL volumes, including the ones for Docker for Windows. WSL2 volumes, in Windows Explorer bar \\\\wsl$\\docker-desktop-data\\version-pack-data\\community\\docker\\volumes","title":"New volume"},{"location":"docker/6-docker-datapersistence/#new-container-with-bind-volume","text":"$ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c touch hello.txt $c echo 123 > hello.txt ctrl+d $ docker rm containername $ docker run --mount type=volume,source=mydata,target=/data -it alpine sh $c cd data $c cat hello.txt 123","title":"New container with bind volume"},{"location":"docker/6-docker-datapersistence/#share-backup-restore","text":"","title":"Share Backup Restore"},{"location":"docker/6-docker-datapersistence/#share-volume-between-containers","text":"$ docker run --mount type=volume,source=mydata,target=/data --name firstcont -it alpine sh $c1 cd data In another terminal $ docker run --mount type=volume,source=mydata,target=/data --name secondcont -it alpine sh $c2 cd data $c2 touch new.txt $c1 ls hello.txt new.txt Another way is volume from container $ docker run --volumes-from firstcont --name thirdcont -it alpine sh","title":"Share volume between containers"},{"location":"docker/6-docker-datapersistence/#backup-volume","text":"Compress a volume to a bind folder with tar $ mkdir backup $ docker run --mount type=volume,source=mydata,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -czf /backup/mydata.tar.gz /data","title":"Backup volume"},{"location":"docker/6-docker-datapersistence/#restore-volume","text":"Extract an archive from a bind folder to a volume $ docker volume create restore $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\"/backup,target=/backup alpine tar -xf /backup/mydata.tar.gz -C /data To not have a folder data in a folder data, use tar with option --strip-components 1 $ docker run --mount type=volume,source=restore,target=/data --mount type=bind,source=\"$(pwd)\",target=/backup -it alpine tar -xf /backup/backup.tar --strip-components 1 -C /data Check volume correctly restored $ docker container run -it --rm --mount source=restore,target=/data alpine sh","title":"Restore volume"},{"location":"docker/6-docker-datapersistence/#volume-to-persist-a-database-mongo","text":"For mongo db it consist of mounting a volume with folder /data/db in mongo container $ docker volume create mydb $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer1 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.insertOne({ name: 'jean' }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61caeae2df845609f1835264\") } > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" } > exit bye $c exit $ docker container stop mongocontainer1 $ docker container rm mongocontainer1 Container is removed but database is persisted in a volume. $ docker run --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer2 mongo $ docker exec -it mongocontainer1 sh $c mongo > use test switched to db test > db.user.findOne() { \"_id\" : ObjectId(\"61caeae2df845609f1835264\"), \"name\" : \"jean\" }","title":"Volume to persist a database (mongo)"},{"location":"docker/6-docker-datapersistence/#compass-gui-to-browse-mongo-db","text":"Should run container with opened port (default 27017). If port is already used on host machine, you may use 27018 for example $ docker run -p 27018:27017 --mount type=volume,source=mydb,target=/data/db -d --name mongocontainer3 mongo Enter in connection field: mongodb://localhost:27018","title":"Compass GUI to browse mongo db"},{"location":"docker/6-docker-datapersistence/#tmpfs_1","text":"Rarely used, uniquely to keep data in RAM, e.g. secret or status data, works only on Linux system. $ docker run --mount type=tmpfs,target=/data -it alpine sh $c cd data $c touch secret.txt $c ls secret.txt $c exit $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 58f104d6a051 alpine \"sh\" 2 minutes ago Exited (0) 5 seconds ago musing_wilbur With 'TMPFS' if container is in an 'Exited' status, data aren't persisted. Relaunch container to observe that data aren't available anymore. $ docker start -ai musing_wilbur $c cd data $c ls (empty)","title":"TMPFS"},{"location":"docker/7-docker-network/","text":"Docker - 07 - Network Introduction WAN = Internet LAN = Local docker network: - ls - create - rm - inspect - connect - disconnect - prune - --network | --net 3 methods: - Bridge, sub-segment - Host, merge host machine network - Overlay, Docker Swarm (- MACVLAN) (- Others) Bridge (mainly used) Grouped by sub-segment. Docker as bridge manager. By default a container belongs to named \"bridge\" (Docker0) network. Host (Linux only, rarely used) IP addresses for containers defined by router like for host machine. Containers will be straight forward connected to local network. Overlay (Swarm) To establish communication between Docker Daemons. Bridge $ docker network $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 119b5f46e464 none null local $ docker network inspect bridge ... \"Containers\": {}, ... $ ifconfig ... docker0: ... $ docker run --rm -it alpine sh in a second terminal $ docker network inspect bridge ... \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" } } ... $ docker run --rm -it alpine sh in a third terminal $ docker network inspect bridge \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"76ff8f56718ae5244eabe03092f7a0227aa2e42249bf2ab1c8f91a9faf76c715\": { \"Name\": \"admiring_driscoll\", \"EndpointID\": \"684e6a570db46dadd9bdf53bf383ea069fa626fc16b7ab26c11e604415c00b25\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } } in second terminal $c ping google.ch $c ping 172.17.0.2 Be aware that ip address maybe attributed randomly by Docker. To use name on default network, use --name and --link (deprecated) options on run command then you may ping by name instead of ip address (only for default bridge network). in first terminal $ docker run --rm --name alpine1 -it alpine sh in second terminal $ docker run --rm --link alpine1 -it alpine sh $c ping alpine1 Create bridge Create a network, make two containers communicate through it and use container name instead of ip addresses. Create network, default driver = bridge $ docker network create mynet $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 0a85e3670d62 mynet bridge local 119b5f46e464 none null local Use network with a named (important for name resolution over the network) container $ docker run --rm --network mynet --name server1 -d alpine ping google.ch $ docker inspect mynet \"Containers\": { \"249b952ab5db2ac4f3077e1a7fb89582eedaa02c236a92a7e15fc5cee73d3292\": { \"Name\": \"server1\", \"EndpointID\": \"48284c2119158a9ebf9d67b3eee0c74c58ede079ba173b769f5b791f2f507abb\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.18.0.2/16\", \"IPv6Address\": \"\" } } $ docker run --rm -it --network mynet --name server2 alpine sh $c ping server1 PING server1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.079 ms 64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.166 ms From another terminal $ docker exec -it server1 sh $c ping server2 PING server2 (172.18.0.3): 56 data bytes 64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.125 ms 64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.496 ms Remove network $ docker network rm mynet Remove all network at once $ docker network prune Connect a Node.js server with MongoDB Goal: - display a counter in a browser at 'localhost' address. Architecture: - Image - MongoDB - Image - Node.js - Volumes - mydb { count: x } - Container - server - Container - db - Network - mynet - Port 80 open to listen to request (count++) from a browser at 'localhost' address MongoDB Volume and container $ docker volume create mydb $ docker run --name db --mount type=volume,source=mydb,target=/data/db -d mongo Network and connect (and disconnect from default bridge) $ docker network create mynet $ docker network connect mynet db $ docker network disconnect bridge db Create db and collection to handle and initialize the counter $ docker exec -it db sh $c mongo > use test switched to db test > db.count.insertOne({count:0}) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61cc2517094e32ba7f98bb31\") } > db.count.find() { \"_id\" : ObjectId(\"61cc2517094e32ba7f98bb31\"), \"count\" : 0 } > exit bye $c exit Node server Development Development Environnement setup First step, application development with bind mount. We should use the mongo javascript driver in our application to allow connection to the db. In 'node-server' folder. File 'package.json' add mongo dependencies (browse for \"npm mongodb\" -> MongoDB NodeJS Driver, to check version) { \"dependencies\": { \"express\": \"^4.17.1\", \"mongodb\": \"^3.6.2\", \"nodemon\": \"^2.0.6\", \"console-stamp\": \"^3.0.3\" } } \"console-stamp\" is to add timestamp in logs ^version \u201cCompatible with version\u201d, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0. Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] Build image in 'node-server' folder $ docker build -t node-server . Application is in js file 'node-server/src/app.js' const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); To develop application use a bind mount $ docker run --name server --mount type=bind,source=\"$(pwd)\"/src,target=/app/src -p 80:80 --network mynet node-server Browse to 'localhost'. Observe live change availability by editing \"Hello, world!\" response in 'app.js' file and refreshing 'localhost' page in internet browser. Check that port '80' is published for 'server' container $ docker container port server 80/tcp -> 0.0.0.0:80 Development Server configuration Modify 'app.js' file as follow require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); Node server Production Rebuild node server image with released app.js in it (above development has been erased by bind mount) In 'node-server' folder $ docker build -t node-server . If 'node-server' container is still running, remove it and then $ docker run --name server --network mynet -d -p 80:80 node-server Host C.f. Bridge section for initial setup. Reset 'app.js' to const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); Rebuild 'node-server' image $ docker build -t node-server . Relaunch server but on local network, this time, no need to publish port $ docker run --network host node-server Do not work on WSL (Windows Subsystem for Linux), neither MacOs. To not use any network $ docker run --network none node-server","title":"Docker - 07 - Network"},{"location":"docker/7-docker-network/#docker-07-network","text":"","title":"Docker - 07 - Network"},{"location":"docker/7-docker-network/#introduction","text":"WAN = Internet LAN = Local docker network: - ls - create - rm - inspect - connect - disconnect - prune - --network | --net 3 methods: - Bridge, sub-segment - Host, merge host machine network - Overlay, Docker Swarm (- MACVLAN) (- Others)","title":"Introduction"},{"location":"docker/7-docker-network/#bridge-mainly-used","text":"Grouped by sub-segment. Docker as bridge manager. By default a container belongs to named \"bridge\" (Docker0) network.","title":"Bridge (mainly used)"},{"location":"docker/7-docker-network/#host-linux-only-rarely-used","text":"IP addresses for containers defined by router like for host machine. Containers will be straight forward connected to local network.","title":"Host (Linux only, rarely used)"},{"location":"docker/7-docker-network/#overlay-swarm","text":"To establish communication between Docker Daemons.","title":"Overlay (Swarm)"},{"location":"docker/7-docker-network/#bridge","text":"$ docker network $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 119b5f46e464 none null local $ docker network inspect bridge ... \"Containers\": {}, ... $ ifconfig ... docker0: ... $ docker run --rm -it alpine sh in a second terminal $ docker network inspect bridge ... \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" } } ... $ docker run --rm -it alpine sh in a third terminal $ docker network inspect bridge \"Containers\": { \"04d3d4540a17d21ea7db83779e8de1716e6e3a4122e1f2c2f66c60d25a094656\": { \"Name\": \"stoic_wozniak\", \"EndpointID\": \"2ed11c55d850ed3cc4eec221f705dad2a9679a016934cd991cd96da86d2dfcbd\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"76ff8f56718ae5244eabe03092f7a0227aa2e42249bf2ab1c8f91a9faf76c715\": { \"Name\": \"admiring_driscoll\", \"EndpointID\": \"684e6a570db46dadd9bdf53bf383ea069fa626fc16b7ab26c11e604415c00b25\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } } in second terminal $c ping google.ch $c ping 172.17.0.2 Be aware that ip address maybe attributed randomly by Docker. To use name on default network, use --name and --link (deprecated) options on run command then you may ping by name instead of ip address (only for default bridge network). in first terminal $ docker run --rm --name alpine1 -it alpine sh in second terminal $ docker run --rm --link alpine1 -it alpine sh $c ping alpine1","title":"Bridge"},{"location":"docker/7-docker-network/#create-bridge","text":"Create a network, make two containers communicate through it and use container name instead of ip addresses. Create network, default driver = bridge $ docker network create mynet $ docker network ls NETWORK ID NAME DRIVER SCOPE 266b7ae5e9d7 bridge bridge local ada5f50a5c41 host host local 0a85e3670d62 mynet bridge local 119b5f46e464 none null local Use network with a named (important for name resolution over the network) container $ docker run --rm --network mynet --name server1 -d alpine ping google.ch $ docker inspect mynet \"Containers\": { \"249b952ab5db2ac4f3077e1a7fb89582eedaa02c236a92a7e15fc5cee73d3292\": { \"Name\": \"server1\", \"EndpointID\": \"48284c2119158a9ebf9d67b3eee0c74c58ede079ba173b769f5b791f2f507abb\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.18.0.2/16\", \"IPv6Address\": \"\" } } $ docker run --rm -it --network mynet --name server2 alpine sh $c ping server1 PING server1 (172.18.0.2): 56 data bytes 64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.079 ms 64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.166 ms From another terminal $ docker exec -it server1 sh $c ping server2 PING server2 (172.18.0.3): 56 data bytes 64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.125 ms 64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.496 ms Remove network $ docker network rm mynet Remove all network at once $ docker network prune","title":"Create bridge"},{"location":"docker/7-docker-network/#connect-a-nodejs-server-with-mongodb","text":"Goal: - display a counter in a browser at 'localhost' address. Architecture: - Image - MongoDB - Image - Node.js - Volumes - mydb { count: x } - Container - server - Container - db - Network - mynet - Port 80 open to listen to request (count++) from a browser at 'localhost' address","title":"Connect a Node.js server with MongoDB"},{"location":"docker/7-docker-network/#mongodb","text":"Volume and container $ docker volume create mydb $ docker run --name db --mount type=volume,source=mydb,target=/data/db -d mongo Network and connect (and disconnect from default bridge) $ docker network create mynet $ docker network connect mynet db $ docker network disconnect bridge db Create db and collection to handle and initialize the counter $ docker exec -it db sh $c mongo > use test switched to db test > db.count.insertOne({count:0}) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61cc2517094e32ba7f98bb31\") } > db.count.find() { \"_id\" : ObjectId(\"61cc2517094e32ba7f98bb31\"), \"count\" : 0 } > exit bye $c exit","title":"MongoDB"},{"location":"docker/7-docker-network/#node-server-development","text":"","title":"Node server Development"},{"location":"docker/7-docker-network/#development-environnement-setup","text":"First step, application development with bind mount. We should use the mongo javascript driver in our application to allow connection to the db. In 'node-server' folder. File 'package.json' add mongo dependencies (browse for \"npm mongodb\" -> MongoDB NodeJS Driver, to check version) { \"dependencies\": { \"express\": \"^4.17.1\", \"mongodb\": \"^3.6.2\", \"nodemon\": \"^2.0.6\", \"console-stamp\": \"^3.0.3\" } } \"console-stamp\" is to add timestamp in logs ^version \u201cCompatible with version\u201d, will update you to all future minor/patch versions, without incrementing the major version. ^2.3.4 will use releases from 2.3.4 to <3.0.0. Dockerfile FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] Build image in 'node-server' folder $ docker build -t node-server . Application is in js file 'node-server/src/app.js' const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); To develop application use a bind mount $ docker run --name server --mount type=bind,source=\"$(pwd)\"/src,target=/app/src -p 80:80 --network mynet node-server Browse to 'localhost'. Observe live change availability by editing \"Hello, world!\" response in 'app.js' file and refreshing 'localhost' page in internet browser. Check that port '80' is published for 'server' container $ docker container port server 80/tcp -> 0.0.0.0:80","title":"Development Environnement setup"},{"location":"docker/7-docker-network/#development-server-configuration","text":"Modify 'app.js' file as follow require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80);","title":"Development Server configuration"},{"location":"docker/7-docker-network/#node-server-production","text":"Rebuild node server image with released app.js in it (above development has been erased by bind mount) In 'node-server' folder $ docker build -t node-server . If 'node-server' container is still running, remove it and then $ docker run --name server --network mynet -d -p 80:80 node-server","title":"Node server Production"},{"location":"docker/7-docker-network/#host","text":"C.f. Bridge section for initial setup. Reset 'app.js' to const express = require(\"express\"); const app = express(); app.get(\"*\", (req, res) => { res.status(200).json(\"Hello, world!\"); }); app.listen(80); Rebuild 'node-server' image $ docker build -t node-server . Relaunch server but on local network, this time, no need to publish port $ docker run --network host node-server Do not work on WSL (Windows Subsystem for Linux), neither MacOs. To not use any network $ docker run --network none node-server","title":"Host"},{"location":"docker/8-compose-use/","text":"Compose - 08 - Use Docker Compose - Use Introduction Application = - Container Web server + - Container Database Setup: - Ports - Volumes - Network - Environment Docker Compose, talking about service. One Application = (is composed of) Many Services (containers that communicate with each others). Docker Compose is a CLI that read 'docker-compose.yml' file. First, install Docker Compose and check installation and version by typing in a terminal: $ docker-compose version First use 'docker-compose ..' command(s) always refer to folder from where command is launched and context of 'docker-compose.yml' file contained in folder. Yaml format configuration file. Yaml syntax is based on an indented key value format. $ touch docker-compose.yml First, mention version to use to ensure retro-compatibility. To determine which version to specify in 'docker-compose.yml' file header, refer to docker engine version that run on your host machine: $ docker version ... Server: Docker Engine - Community Engine: Version: 20.10.11 ... Then refer to documentation Compose file - Reference and guidelines Second, specify service(s). docker-compose.yml: version: '3.8' services: myalpine: image: alpine $ docker-compose up Alternative to go straight in service's container: $ docker-compose run myapline $c In another console: $ docker-compose ps $ docker-compose ps -a $ docker-compose down Particularity of 'docker-compose down' command is to suppress (don't just stop) all container and network that was launched by previous 'docker-compose up' command. Anonymous volumes are never reused by Docker Compose. It launches new ones each time if declared in configuration. Default command is the one defined in image, for 'alpine' it's '/bin/sh'. To overwrite default command, specify it in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine command: ls Or by adding command directly after service name in run command: $ docker-compose run myalpine ls Or with entry point in exec form (instead of shell) in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine entrypoint: [\"ls\"] Or 'command: [\"ls\"]' instead of 'entrypoint: [\"ls\"]' Custom image $ touch Dockerfile Dockerfile: FROM alpine CMD [\"/bin/sh\"] docker-compose.yml version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: . $ docker-compose build Have a look to VS Code Docker plugin to have a synthetic view of all Docker ecosystem components, containers, images, network, etc. Context and Dockerfile Specify a context and Dockerfile: $ mkdir backend $ cp Dockerfile backend/DockerfileBackend docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend Arguments Passing arguments, e.g. create a folder at build, 'Dockerfile' receive args from 'docker-compose.yml'. DockerfileBackend: FROM alpine ARG FOLDER RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test Note the 'arg' indentation with '-' for an array of values (yaml syntax). test: $ docker-compose build $ docker-compose run b $c ls .. test .. Instead of list (- FOLDER=), e.g. for 'args' you may also use an object instead (FOLDER:). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder test: $ docker-compose build $ docker-compose run b $c ls .. myfolder .. Labels docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test labels: - EMAIL=toto@test.com test: $ docker-compose build $ docker image inspect compose_b:latest | grep EMAIL \"EMAIL\": \"toto@test.com\" Ports docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 Volumes Bind $ mkdir data $ touch data/hello.txt DockerfileBackend.yml: FROM alpine ARG FOLDER WORKDIR /app RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data test: $ docker-compose build $ docker-compose run b $c cd data $c ls $c exit Volumes docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: test: $ docker-compose build $ docker-compose run b [+] Running 1/0 \u283f Volume \"compose_datavolume\" Created $c ls data datavolume myfolder $c exit Volume option external to avoid docker-compose to create volume if it does not exist. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: external: true Before testing remove previously created volumes. test: $ docker-compose run b external volume \"\" not found To create anonymous volume, omit source option. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c ls data datavolume datavolumeanonymous myfolder Docker Compose does not always use the same anonymous volume for a service. Therefore, it is advisable to use: $ docker-compose down -v to remove it. -v, --volumes volumes, Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers. Environment Variables from cli $ docker-compose run b $c env HOSTNAME=0b9907714155 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app Add environnement variable from command line, value from host machine: $ docker-compose run -e USER b $c env | grep USER USER=toto By default, by not specifying a value, docker-compose search on host machine environnement variable and if find one that match, pass it (e.g. here with USER that do exist on host machine and has a value). Add environnement variable from command line with specified value: $ docker-compose run -e USER=tintin b $c env | grep USER USER=tintin from compose file Without specifying a value (comes from host machine). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=toto By specifying a value. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER=tintin build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=tintin from .env file If value of environment variable is not specified, docker compose search for corresponding value in host machine, if not found, search then in '.env' file. .env: NODE_ENV=development docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - NODE_ENV build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep NODE_ENV NODE_ENV=development By specifying an environnement file, all variables contained in it will be imported in container. .env: NODE_ENV=development TEST_ENV=test docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: env_file: - .env build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep _ENV TEST_ENV=test NODE_ENV=development You may have many environnement files. You may specify env file in command line, works only with 'up': $ docker-compose --env-file ./.env up You may use both 'env_file' and 'environnement' for same service. You may specify compose project name instead of current folder with, e.g. in .env file: COMPOSE_PROJECT_NAME=myproject Network Default By default docker compose create a network with folder name as a prefix, or with value of 'COMPOSE_PROJECT_NAME' key in project's environnement variable: $ docker-compose up [+] Running 4/4 \u283f Network myproject_default Created .. Note that containers using the network appear in the list ($ docker network inspect myproject_default) only when they are running. Below, we make a test with ping, note that we use shell form (instead of exec (cause: executable file not found in $PATH: unknown)). docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: command: ping a build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 2/2 \u283f Container myproject_a_1 Recreated 0.2s \u283f Container myproject_b_1 Recreated 0.2s Attaching to a_1, b_1 a_1 | PING b (172.29.0.3): 56 data bytes b_1 | PING a (172.29.0.2): 56 data bytes a_1 | 64 bytes from 172.29.0.3: seq=0 ttl=64 time=188.846 ms b_1 | 64 bytes from 172.29.0.2: seq=0 ttl=64 time=0.152 ms Links Links from a container to another one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 3/2 \u283f Network myproject_default Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (172.31.0.2): 56 data bytes b_1 | 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.078 ms b_1 | 64 bytes from 172.31.0.2: seq=1 ttl=64 time=0.190 ms b_1 | 64 bytes from 172.31.0.2: seq=2 ttl=64 time=0.220 ms a_1 | PING b (172.31.0.3): 56 data bytes a_1 | 64 bytes from 172.31.0.3: seq=0 ttl=64 time=0.407 ms b_1 | 64 bytes from 172.31.0.2: seq=3 ttl=64 time=0.305 ms test to ping a and containerA from b: $ docker-compose up -d $ docker-compose exec b sh $c ping a PING a (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.181 ms .. $c ping containerA PING containerA (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.287 ms Name Give network a name to replace the default one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up [+] Running 3/3 \u283f Network mynetwork Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 2.4s Attaching to a_1, b_1 b_1 | PING containerA (192.168.0.2): 56 data bytes b_1 | 64 bytes from 192.168.0.2: seq=0 ttl=64 time=0.081 ms b_1 | 64 bytes from 192.168.0.2: seq=1 ttl=64 time=0.088 ms b_1 | 64 bytes from 192.168.0.2: seq=2 ttl=64 time=0.122 ms a_1 | PING b (192.168.0.3): 56 data bytes a_1 | 64 bytes from 192.168.0.3: seq=0 ttl=64 time=0.339 ms Networks Link container to many networks with adding list in service configuration. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up service \"b\" refers to undefined network othernetwork: invalid compose project Error due to othernetwork missing. We add it to networks section in configuration file and then to services. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b networks: - 'othernetwork' b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork othernetwork: driver: bridge test: $ docker-compose up [+] Running 3/3 \u283f Network myproject_othernetwork Created 0.0s \u283f Container myproject_a_1 Created 0.1s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (192.168.48.2): 56 data bytes b_1 | 64 bytes from 192.168.48.2: seq=0 ttl=64 time=0.122 ms b_1 | 64 bytes from 192.168.48.2: seq=1 ttl=64 time=0.051 ms b_1 | 64 bytes from 192.168.48.2: seq=2 ttl=64 time=0.196 ms a_1 | PING b (192.168.48.3): 56 data bytes a_1 | 64 bytes from 192.168.48.3: seq=0 ttl=64 time=0.252 ms b_1 | 64 bytes from 192.168.48.2: seq=3 ttl=64 time=0.200 ms Sample application Node.js application that increment a counter in a MongoDB. MongoDB We provide volume to handle db data, so, preamble is to \"manually\" create the needed volume: $ docker volume create mydb docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db volumes: mydb: external: true We run db individually to initialize it: $ docker-compose run -d db 39cf.. $ docker container exec -it 39cf sh $c mongo > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1a03ac9a303a408034aca\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1a03ac9a303a408034aca\"), \"count\" : 0 } > exit bye $c exit $ docker container stop 39cf In MongoDB, volume that contain the database may not be mounted anywhere. MongoDB will specifically search for database in '/data/db' folder. No need to open specific port(s) for containers that run on same network. By default all ports are available for containers that run on same network. Node.js Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true \\src\\app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); In a terminal: $ docker-compose up .. server_1 | [02.01.2022 17:10.30.697] [LOG] CONNEXION DB OK! .. In a browser: http://localhost/ Authentication We add authentication through environnement variable to MongoDB. Clear docker environnement and recreate database volume: $ docker container prune $ docker volume prune $ docker volume create mydb Have a look to MongoDB official image on Docker Hub What's interesting us here is to set the two following environnement variables: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD $ touch .env .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true In a terminal, set up db with authenticated user and then create a new user 'tintin' with password '456' and role 'readWrite' on db 'test': $ docker-compose run -d db bad88.. $ docker exec -it bad88 sh $c mongo > use test > db.count.insertOne({ count: 0 }) .. error.. command insert requires authentication.. > use admin > db.auth({ user: 'toto', pwd: '123' }) 1 > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1e40276df2cfd1b903a8f\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1e40276df2cfd1b903a8f\"), \"count\" : 0 } > use admin switched to db admin > db.createUser({ user: 'tintin', pwd: '456', roles: [{ role: 'readWrite', db: 'test' }] }) Successfully added user: { \"user\" : \"tintin\", \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"test\" } ] } > exit bye $c exit $ docker stop bad88 Check that connection to db is OK ('CONNECTION DB OK!' in logs), but we cannot access data (trying to refresh 'localhost' in Internet browser), due to unauthenticated connection: $ docker-compose up .. server_1 | [02.01.2022 19:47.14.606] [LOG] CONNECTION DB OK! .. server_1 | MongoError: command findAndModify requires authentication .. We can authenticate with many different ways. By specifying (hard coded) user password directly in 'app.js' file ('mongodb://tintin:456@db'). We also add a 'console.log(process)' to have environnement variables in logs. app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process) // to have environnement variables in logs MongoClient.connect('mongodb://tintin:456@db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); server_1 logs (to see environnement variables): .. server_1 | env: { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'fbdb8ee68893', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | PWD: '/app' server_1 | } .. By refreshing Internet browser's page at localhost address, we may observer that application is now running fine. Now we stop application by hitting 'Ctrl+c'. Below is described a second manner (more secure, therefor, advised to use) to authenticate to 'db' service from 'sever' service through environnement variables. .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 MONGO_USER_NAME=tintin MONGO_USER_PASSWORD=456 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); ! Be aware of literal evaluation with use of ` character to surround mongodb connection URL instead of ' character like before. To test, type below command in a terminal and refresh Internet browser's page at 'localhost' address: $ docker-compose up .. server_1 | [02.01.2022 20:32.25.069] [LOG] { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'e9e18205ee72', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | MONGO_USER_PASSWORD: '456', server_1 | PWD: '/app', server_1 | MONGO_USER_NAME: 'tintin' server_1 | } .. Depends and Restart Depends Specify containers up priority order (depends_on). E.g. in our application we want that server (Node.js application) start only once database (MongoDB) container is up. docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db volumes: mydb: external: true In a terminal, type below command and you may observe, in logs, that, first, we have database logs, then server logs: $ docker-compose up Attaching to db_1, server_1 db_1 | .. db_1 | .. .. server_1 | .. server_1 | .. .. Restart restart: - \"no\" (between quotes because without it has a yaml signification), default value, never restart automatically. - always restart if container stop from inside or Docker daemon restart, but not with a 'docker-compose stop' command. - on-failure restart container only on quit with error code. - unless-stopped always restart unless stopped manually with a 'docker-compose stop' command. To test it we add a '/err' route to the server to exit the process (process.exit(errorCode)). app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(0); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); For testing purpose (different restart modes) avoid using nodemon. Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"node\", \"src/app.js\"] Terminal: $ docker-compose down $ docker-compose build --no-cache no docker-compose.yml (restart: \"no\"): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: \"no\" volumes: mydb: external: true Test: $ docker-compose down $ docker-compose up Navigate in Internet browser to: http://localhost/err You may observe in logs: .. server_1 exited with code 0 .. In another terminal: $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS 63c2040a78c6 node-server_server \"docker-entrypoint.s\u2026\" About a minute ago Exited (0) About a minute ago 2d8b795bf1ed mongo \"docker-entrypoint.s\u2026\" 7 minutes ago Up About a minute And server isn't available anymore. always docker-compose.yml (restart: always): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: always volumes: mydb: external: true Terminal: $ docker-compose up In an Internet browser, navigate alternatively to following addresses and observe in logs server exit and restart automatically: http://localhost/ http://localhost/err Terminal: .. server_1 | [03.01.2022 16:24.28.780] [LOG] CONNECTION DB OK! .. server_1 exited with code 0 .. server_1 | [03.01.2022 16:27.10.339] [LOG] CONNECTION DB OK! .. In another terminal: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp If we \"manually\" stop 'server' container from another terminal with below command: $ docker-compose stop server And then restart the Docker daemon, we may observe the 'server' that has restart automatically due to his 'always' restart policy and 'db' is down because, for now, he hasn't any restart policy defined in docker-compose yaml configuration file. on-failure docker-compose.yml (restart: on-failure): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: on-failure volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '0' = no error, therefore container does not restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (0) Modify exit code of 'err' route to app.js with '1', app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(1); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '1' = error, therefore container restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp unless-stopped Will always restart except if stopped \"manually\" with 'docker-compose stop server', then restart Docker daemon, then stopped 'server' container will not restart. docker-compose.yml (restart: unless-stopped): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: unless-stopped volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Restart Docker daemon, then: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db exited (255) 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) We may observe that 'server' container hasn't restarted automatically due to fact it has been \"manually\" stopped before Docker daemon restart. Note that you can change the restart configuration of an already running container by doing: $ docker container update --restart unless-stopped ID Other commands First: $ docker-compose up -d logs View output from containers: $ docker-compose logs .. db_1 | .. server_1 | .. .. To follow -f option, to show timestamps -t options: $ docker-compose logs -f -t 'Ctrl+c' does not stop containers, stop only logs display: $ Ctrl+c $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp top Display the running processes: $ docker-compose top misc Stop a container: $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Remove a stopped container: $ docker-compose rm server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp Remove a running container (+ -f to avoid confirm's need): $ docker-compose rm -s server Remove anonym volumes belonging to container: $ docker-compose rm -v db After removing a container, to get it back (+ -d): $ docker-compose up Port mapping information and entering ip allowed (0.0.0.0 for all entering ip address allowed): $ docker-compose port server 80 0.0.0.0:80 Means, outside port 80 is mapped to inside port 80 and all ip addresses allowed. config Let see environnement variables replaced with found values and configuration that will then be used to build the stack: $ docker-compose config services: db: environment: MONGO_INITDB_ROOT_PASSWORD: \"123\" MONGO_INITDB_ROOT_USERNAME: toto image: mongo restart: unless-stopped volumes: - type: volume source: mydb target: /data/db server: build: context: . depends_on: db: condition: service_started environment: MONGO_USER_NAME: tintin MONGO_USER_PASSWORD: \"456\" ports: - mode: ingress target: 80 published: 80 protocol: tcp restart: unless-stopped volumes: - type: bind source: /mnt/c/git/doc/test/docker/node-server/src target: /app/src volumes: mydb: name: mydb external: true pull push pull: get latest images of containers that compose the stack. push: if image has been modified with custom Dockerfile, let us push it to Docker Hub.","title":"Compose - 08 - Use"},{"location":"docker/8-compose-use/#compose-08-use","text":"Docker Compose - Use","title":"Compose - 08 - Use"},{"location":"docker/8-compose-use/#introduction","text":"Application = - Container Web server + - Container Database Setup: - Ports - Volumes - Network - Environment Docker Compose, talking about service. One Application = (is composed of) Many Services (containers that communicate with each others). Docker Compose is a CLI that read 'docker-compose.yml' file. First, install Docker Compose and check installation and version by typing in a terminal: $ docker-compose version","title":"Introduction"},{"location":"docker/8-compose-use/#first-use","text":"'docker-compose ..' command(s) always refer to folder from where command is launched and context of 'docker-compose.yml' file contained in folder. Yaml format configuration file. Yaml syntax is based on an indented key value format. $ touch docker-compose.yml First, mention version to use to ensure retro-compatibility. To determine which version to specify in 'docker-compose.yml' file header, refer to docker engine version that run on your host machine: $ docker version ... Server: Docker Engine - Community Engine: Version: 20.10.11 ... Then refer to documentation Compose file - Reference and guidelines Second, specify service(s). docker-compose.yml: version: '3.8' services: myalpine: image: alpine $ docker-compose up Alternative to go straight in service's container: $ docker-compose run myapline $c In another console: $ docker-compose ps $ docker-compose ps -a $ docker-compose down Particularity of 'docker-compose down' command is to suppress (don't just stop) all container and network that was launched by previous 'docker-compose up' command. Anonymous volumes are never reused by Docker Compose. It launches new ones each time if declared in configuration. Default command is the one defined in image, for 'alpine' it's '/bin/sh'. To overwrite default command, specify it in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine command: ls Or by adding command directly after service name in run command: $ docker-compose run myalpine ls Or with entry point in exec form (instead of shell) in 'docker-compose.yml' file: version: '3.8' services: myalpine: image: alpine entrypoint: [\"ls\"] Or 'command: [\"ls\"]' instead of 'entrypoint: [\"ls\"]'","title":"First use"},{"location":"docker/8-compose-use/#custom-image","text":"$ touch Dockerfile Dockerfile: FROM alpine CMD [\"/bin/sh\"] docker-compose.yml version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: . $ docker-compose build Have a look to VS Code Docker plugin to have a synthetic view of all Docker ecosystem components, containers, images, network, etc.","title":"Custom image"},{"location":"docker/8-compose-use/#context-and-dockerfile","text":"Specify a context and Dockerfile: $ mkdir backend $ cp Dockerfile backend/DockerfileBackend docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend","title":"Context and Dockerfile"},{"location":"docker/8-compose-use/#arguments","text":"Passing arguments, e.g. create a folder at build, 'Dockerfile' receive args from 'docker-compose.yml'. DockerfileBackend: FROM alpine ARG FOLDER RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test Note the 'arg' indentation with '-' for an array of values (yaml syntax). test: $ docker-compose build $ docker-compose run b $c ls .. test .. Instead of list (- FOLDER=), e.g. for 'args' you may also use an object instead (FOLDER:). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder test: $ docker-compose build $ docker-compose run b $c ls .. myfolder ..","title":"Arguments"},{"location":"docker/8-compose-use/#labels","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: - FOLDER=test labels: - EMAIL=toto@test.com test: $ docker-compose build $ docker image inspect compose_b:latest | grep EMAIL \"EMAIL\": \"toto@test.com\"","title":"Labels"},{"location":"docker/8-compose-use/#ports","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80","title":"Ports"},{"location":"docker/8-compose-use/#volumes","text":"","title":"Volumes"},{"location":"docker/8-compose-use/#bind","text":"$ mkdir data $ touch data/hello.txt DockerfileBackend.yml: FROM alpine ARG FOLDER WORKDIR /app RUN mkdir $FOLDER CMD [\"/bin/sh\"] docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data test: $ docker-compose build $ docker-compose run b $c cd data $c ls $c exit","title":"Bind"},{"location":"docker/8-compose-use/#volumes_1","text":"docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: test: $ docker-compose build $ docker-compose run b [+] Running 1/0 \u283f Volume \"compose_datavolume\" Created $c ls data datavolume myfolder $c exit Volume option external to avoid docker-compose to create volume if it does not exist. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume volumes: datavolume: external: true Before testing remove previously created volumes. test: $ docker-compose run b external volume \"\" not found To create anonymous volume, omit source option. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c ls data datavolume datavolumeanonymous myfolder Docker Compose does not always use the same anonymous volume for a service. Therefore, it is advisable to use: $ docker-compose down -v to remove it. -v, --volumes volumes, Remove named volumes declared in the volumes section of the Compose file and anonymous volumes attached to containers.","title":"Volumes"},{"location":"docker/8-compose-use/#environment-variables","text":"","title":"Environment Variables"},{"location":"docker/8-compose-use/#from-cli","text":"$ docker-compose run b $c env HOSTNAME=0b9907714155 SHLVL=1 HOME=/root TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PWD=/app Add environnement variable from command line, value from host machine: $ docker-compose run -e USER b $c env | grep USER USER=toto By default, by not specifying a value, docker-compose search on host machine environnement variable and if find one that match, pass it (e.g. here with USER that do exist on host machine and has a value). Add environnement variable from command line with specified value: $ docker-compose run -e USER=tintin b $c env | grep USER USER=tintin","title":"from cli"},{"location":"docker/8-compose-use/#from-compose-file","text":"Without specifying a value (comes from host machine). docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=toto By specifying a value. docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - USER=tintin build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep USER USER=tintin","title":"from compose file"},{"location":"docker/8-compose-use/#from-env-file","text":"If value of environment variable is not specified, docker compose search for corresponding value in host machine, if not found, search then in '.env' file. .env: NODE_ENV=development docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: environment: - NODE_ENV build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep NODE_ENV NODE_ENV=development By specifying an environnement file, all variables contained in it will be imported in container. .env: NODE_ENV=development TEST_ENV=test docker-compose.yml: version: '3.8' services: a: image: alpine command: [\"ls\"] b: env_file: - .env build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose build $ docker-compose run b $c env | grep _ENV TEST_ENV=test NODE_ENV=development You may have many environnement files. You may specify env file in command line, works only with 'up': $ docker-compose --env-file ./.env up You may use both 'env_file' and 'environnement' for same service. You may specify compose project name instead of current folder with, e.g. in .env file: COMPOSE_PROJECT_NAME=myproject","title":"from .env file"},{"location":"docker/8-compose-use/#network","text":"","title":"Network"},{"location":"docker/8-compose-use/#default","text":"By default docker compose create a network with folder name as a prefix, or with value of 'COMPOSE_PROJECT_NAME' key in project's environnement variable: $ docker-compose up [+] Running 4/4 \u283f Network myproject_default Created .. Note that containers using the network appear in the list ($ docker network inspect myproject_default) only when they are running. Below, we make a test with ping, note that we use shell form (instead of exec (cause: executable file not found in $PATH: unknown)). docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: command: ping a build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 2/2 \u283f Container myproject_a_1 Recreated 0.2s \u283f Container myproject_b_1 Recreated 0.2s Attaching to a_1, b_1 a_1 | PING b (172.29.0.3): 56 data bytes b_1 | PING a (172.29.0.2): 56 data bytes a_1 | 64 bytes from 172.29.0.3: seq=0 ttl=64 time=188.846 ms b_1 | 64 bytes from 172.29.0.2: seq=0 ttl=64 time=0.152 ms","title":"Default"},{"location":"docker/8-compose-use/#links","text":"Links from a container to another one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: test: $ docker-compose up [+] Running 3/2 \u283f Network myproject_default Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (172.31.0.2): 56 data bytes b_1 | 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.078 ms b_1 | 64 bytes from 172.31.0.2: seq=1 ttl=64 time=0.190 ms b_1 | 64 bytes from 172.31.0.2: seq=2 ttl=64 time=0.220 ms a_1 | PING b (172.31.0.3): 56 data bytes a_1 | 64 bytes from 172.31.0.3: seq=0 ttl=64 time=0.407 ms b_1 | 64 bytes from 172.31.0.2: seq=3 ttl=64 time=0.305 ms test to ping a and containerA from b: $ docker-compose up -d $ docker-compose exec b sh $c ping a PING a (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.181 ms .. $c ping containerA PING containerA (172.31.0.2): 56 data bytes 64 bytes from 172.31.0.2: seq=0 ttl=64 time=0.287 ms","title":"Links"},{"location":"docker/8-compose-use/#name","text":"Give network a name to replace the default one. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up [+] Running 3/3 \u283f Network mynetwork Created 0.0s \u283f Container myproject_a_1 Created 0.8s \u283f Container myproject_b_1 Created 2.4s Attaching to a_1, b_1 b_1 | PING containerA (192.168.0.2): 56 data bytes b_1 | 64 bytes from 192.168.0.2: seq=0 ttl=64 time=0.081 ms b_1 | 64 bytes from 192.168.0.2: seq=1 ttl=64 time=0.088 ms b_1 | 64 bytes from 192.168.0.2: seq=2 ttl=64 time=0.122 ms a_1 | PING b (192.168.0.3): 56 data bytes a_1 | 64 bytes from 192.168.0.3: seq=0 ttl=64 time=0.339 ms","title":"Name"},{"location":"docker/8-compose-use/#networks","text":"Link container to many networks with adding list in service configuration. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork test: $ docker-compose up service \"b\" refers to undefined network othernetwork: invalid compose project Error due to othernetwork missing. We add it to networks section in configuration file and then to services. docker-compose.yml: version: '3.8' services: a: image: alpine command: ping b networks: - 'othernetwork' b: links: - \"a:containerA\" command: ping containerA build: context: ./backend dockerfile: DockerfileBackend args: FOLDER: myfolder labels: - EMAIL=toto@test.com ports: - 80:80 volumes: - type: bind source: ./data target: /app/data - type: volume source: datavolume target: /app/datavolume - type: volume target: /app/datavolumeanonymous networks: - 'othernetwork' volumes: datavolume: networks: default: name: mynetwork othernetwork: driver: bridge test: $ docker-compose up [+] Running 3/3 \u283f Network myproject_othernetwork Created 0.0s \u283f Container myproject_a_1 Created 0.1s \u283f Container myproject_b_1 Created 0.1s Attaching to a_1, b_1 b_1 | PING containerA (192.168.48.2): 56 data bytes b_1 | 64 bytes from 192.168.48.2: seq=0 ttl=64 time=0.122 ms b_1 | 64 bytes from 192.168.48.2: seq=1 ttl=64 time=0.051 ms b_1 | 64 bytes from 192.168.48.2: seq=2 ttl=64 time=0.196 ms a_1 | PING b (192.168.48.3): 56 data bytes a_1 | 64 bytes from 192.168.48.3: seq=0 ttl=64 time=0.252 ms b_1 | 64 bytes from 192.168.48.2: seq=3 ttl=64 time=0.200 ms","title":"Networks"},{"location":"docker/8-compose-use/#sample-application","text":"Node.js application that increment a counter in a MongoDB.","title":"Sample application"},{"location":"docker/8-compose-use/#mongodb","text":"We provide volume to handle db data, so, preamble is to \"manually\" create the needed volume: $ docker volume create mydb docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db volumes: mydb: external: true We run db individually to initialize it: $ docker-compose run -d db 39cf.. $ docker container exec -it 39cf sh $c mongo > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1a03ac9a303a408034aca\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1a03ac9a303a408034aca\"), \"count\" : 0 } > exit bye $c exit $ docker container stop 39cf In MongoDB, volume that contain the database may not be mounted anywhere. MongoDB will specifically search for database in '/data/db' folder. No need to open specific port(s) for containers that run on same network. By default all ports are available for containers that run on same network.","title":"MongoDB"},{"location":"docker/8-compose-use/#nodejs","text":"Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"nodemon\", \"-L\", \"src/app.js\"] docker-compose.yml: version: '3.8' services: db: image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true \\src\\app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; MongoClient.connect('mongodb://db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNEXION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); In a terminal: $ docker-compose up .. server_1 | [02.01.2022 17:10.30.697] [LOG] CONNEXION DB OK! .. In a browser: http://localhost/","title":"Node.js"},{"location":"docker/8-compose-use/#authentication","text":"We add authentication through environnement variable to MongoDB. Clear docker environnement and recreate database volume: $ docker container prune $ docker volume prune $ docker volume create mydb Have a look to MongoDB official image on Docker Hub What's interesting us here is to set the two following environnement variables: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD $ touch .env .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true In a terminal, set up db with authenticated user and then create a new user 'tintin' with password '456' and role 'readWrite' on db 'test': $ docker-compose run -d db bad88.. $ docker exec -it bad88 sh $c mongo > use test > db.count.insertOne({ count: 0 }) .. error.. command insert requires authentication.. > use admin > db.auth({ user: 'toto', pwd: '123' }) 1 > use test > db.count.insertOne({ count: 0 }) { \"acknowledged\" : true, \"insertedId\" : ObjectId(\"61d1e40276df2cfd1b903a8f\") } > db.count.findOne() { \"_id\" : ObjectId(\"61d1e40276df2cfd1b903a8f\"), \"count\" : 0 } > use admin switched to db admin > db.createUser({ user: 'tintin', pwd: '456', roles: [{ role: 'readWrite', db: 'test' }] }) Successfully added user: { \"user\" : \"tintin\", \"roles\" : [ { \"role\" : \"readWrite\", \"db\" : \"test\" } ] } > exit bye $c exit $ docker stop bad88 Check that connection to db is OK ('CONNECTION DB OK!' in logs), but we cannot access data (trying to refresh 'localhost' in Internet browser), due to unauthenticated connection: $ docker-compose up .. server_1 | [02.01.2022 19:47.14.606] [LOG] CONNECTION DB OK! .. server_1 | MongoError: command findAndModify requires authentication .. We can authenticate with many different ways. By specifying (hard coded) user password directly in 'app.js' file ('mongodb://tintin:456@db'). We also add a 'console.log(process)' to have environnement variables in logs. app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process) // to have environnement variables in logs MongoClient.connect('mongodb://tintin:456@db', { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); server_1 logs (to see environnement variables): .. server_1 | env: { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'fbdb8ee68893', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | PWD: '/app' server_1 | } .. By refreshing Internet browser's page at localhost address, we may observer that application is now running fine. Now we stop application by hitting 'Ctrl+c'. Below is described a second manner (more secure, therefor, advised to use) to authenticate to 'db' service from 'sever' service through environnement variables. .env: MONGO_INITDB_ROOT_USERNAME=toto MONGO_INITDB_ROOT_PASSWORD=123 MONGO_USER_NAME=tintin MONGO_USER_PASSWORD=456 docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src volumes: mydb: external: true app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); ! Be aware of literal evaluation with use of ` character to surround mongodb connection URL instead of ' character like before. To test, type below command in a terminal and refresh Internet browser's page at 'localhost' address: $ docker-compose up .. server_1 | [02.01.2022 20:32.25.069] [LOG] { server_1 | NODE_VERSION: '17.3.0', server_1 | HOSTNAME: 'e9e18205ee72', server_1 | YARN_VERSION: '1.22.17', server_1 | SHLVL: '1', server_1 | HOME: '/root', server_1 | PATH: '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/app/node_modules/.bin', server_1 | MONGO_USER_PASSWORD: '456', server_1 | PWD: '/app', server_1 | MONGO_USER_NAME: 'tintin' server_1 | } ..","title":"Authentication"},{"location":"docker/8-compose-use/#depends-and-restart","text":"","title":"Depends and Restart"},{"location":"docker/8-compose-use/#depends","text":"Specify containers up priority order (depends_on). E.g. in our application we want that server (Node.js application) start only once database (MongoDB) container is up. docker-compose.yml: version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db volumes: mydb: external: true In a terminal, type below command and you may observe, in logs, that, first, we have database logs, then server logs: $ docker-compose up Attaching to db_1, server_1 db_1 | .. db_1 | .. .. server_1 | .. server_1 | .. ..","title":"Depends"},{"location":"docker/8-compose-use/#restart","text":"restart: - \"no\" (between quotes because without it has a yaml signification), default value, never restart automatically. - always restart if container stop from inside or Docker daemon restart, but not with a 'docker-compose stop' command. - on-failure restart container only on quit with error code. - unless-stopped always restart unless stopped manually with a 'docker-compose stop' command. To test it we add a '/err' route to the server to exit the process (process.exit(errorCode)). app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(0); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); For testing purpose (different restart modes) avoid using nodemon. Dockerfile: FROM node:alpine WORKDIR /app COPY ./package.json . RUN npm install COPY . . ENV PATH=$PATH:/app/node_modules/.bin CMD [\"node\", \"src/app.js\"] Terminal: $ docker-compose down $ docker-compose build --no-cache","title":"Restart"},{"location":"docker/8-compose-use/#no","text":"docker-compose.yml (restart: \"no\"): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: \"no\" volumes: mydb: external: true Test: $ docker-compose down $ docker-compose up Navigate in Internet browser to: http://localhost/err You may observe in logs: .. server_1 exited with code 0 .. In another terminal: $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS 63c2040a78c6 node-server_server \"docker-entrypoint.s\u2026\" About a minute ago Exited (0) About a minute ago 2d8b795bf1ed mongo \"docker-entrypoint.s\u2026\" 7 minutes ago Up About a minute And server isn't available anymore.","title":"no"},{"location":"docker/8-compose-use/#always","text":"docker-compose.yml (restart: always): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: always volumes: mydb: external: true Terminal: $ docker-compose up In an Internet browser, navigate alternatively to following addresses and observe in logs server exit and restart automatically: http://localhost/ http://localhost/err Terminal: .. server_1 | [03.01.2022 16:24.28.780] [LOG] CONNECTION DB OK! .. server_1 exited with code 0 .. server_1 | [03.01.2022 16:27.10.339] [LOG] CONNECTION DB OK! .. In another terminal: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp If we \"manually\" stop 'server' container from another terminal with below command: $ docker-compose stop server And then restart the Docker daemon, we may observe the 'server' that has restart automatically due to his 'always' restart policy and 'db' is down because, for now, he hasn't any restart policy defined in docker-compose yaml configuration file.","title":"always"},{"location":"docker/8-compose-use/#on-failure","text":"docker-compose.yml (restart: on-failure): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: on-failure volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '0' = no error, therefore container does not restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (0) Modify exit code of 'err' route to app.js with '1', app.js: require( 'console-stamp' )( console ); // to add timestamp in logs const express = require(\"express\"); const MongoClient = require('mongodb').MongoClient; let count; console.log(process.env) // to have environnement variables in logs MongoClient.connect(`mongodb://${ process.env.MONGO_USER_NAME }:${ process.env.MONGO_USER_PASSWORD }@db`, { useUnifiedTopology: true }, (err, client) => { if (err) { console.log(err); } else { console.log('CONNECTION DB OK!'); count = client.db('test').collection(\"count\"); } }); const app = express(); app.get('/err', (req, res) => { process.exit(1); }); app.get('/', (req, res) => { console.log('request url: ' + req.url); count.findOneAndUpdate({}, { $inc: { count: 1 } }, { returnNewDocument: true }).then((doc) => { const value = doc.value; res.status(200).json(value.count); }) }); app.get('*', (req, res) => { res.end(); }); app.listen(80); Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp Browse to: http://localhost/err In app.js exit code is '1' = error, therefore container restart automatically: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp","title":"on-failure"},{"location":"docker/8-compose-use/#unless-stopped","text":"Will always restart except if stopped \"manually\" with 'docker-compose stop server', then restart Docker daemon, then stopped 'server' container will not restart. docker-compose.yml (restart: unless-stopped): version: '3.8' services: db: environment: - MONGO_INITDB_ROOT_USERNAME - MONGO_INITDB_ROOT_PASSWORD image: mongo volumes: - type: volume source: mydb target: /data/db server: environment: - MONGO_USER_NAME - MONGO_USER_PASSWORD build: . ports: - 80:80 volumes: - type: bind source: ./src target: /app/src depends_on: - db restart: unless-stopped volumes: mydb: external: true Terminal: $ docker-compose down $ docker-compose up -d $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Restart Docker daemon, then: $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db exited (255) 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) We may observe that 'server' container hasn't restarted automatically due to fact it has been \"manually\" stopped before Docker daemon restart. Note that you can change the restart configuration of an already running container by doing: $ docker container update --restart unless-stopped ID","title":"unless-stopped"},{"location":"docker/8-compose-use/#other-commands","text":"First: $ docker-compose up -d","title":"Other commands"},{"location":"docker/8-compose-use/#logs","text":"View output from containers: $ docker-compose logs .. db_1 | .. server_1 | .. .. To follow -f option, to show timestamps -t options: $ docker-compose logs -f -t 'Ctrl+c' does not stop containers, stop only logs display: $ Ctrl+c $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server running 0.0.0.0:80->80/tcp","title":"logs"},{"location":"docker/8-compose-use/#top","text":"Display the running processes: $ docker-compose top","title":"top"},{"location":"docker/8-compose-use/#misc","text":"Stop a container: $ docker-compose stop server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp node-server_server_1 \"docker-entrypoint.s\u2026\" server exited (137) Remove a stopped container: $ docker-compose rm server $ docker-compose ps NAME COMMAND SERVICE STATUS PORTS node-server_db_1 \"docker-entrypoint.s\u2026\" db running 27017/tcp Remove a running container (+ -f to avoid confirm's need): $ docker-compose rm -s server Remove anonym volumes belonging to container: $ docker-compose rm -v db After removing a container, to get it back (+ -d): $ docker-compose up Port mapping information and entering ip allowed (0.0.0.0 for all entering ip address allowed): $ docker-compose port server 80 0.0.0.0:80 Means, outside port 80 is mapped to inside port 80 and all ip addresses allowed.","title":"misc"},{"location":"docker/8-compose-use/#config","text":"Let see environnement variables replaced with found values and configuration that will then be used to build the stack: $ docker-compose config services: db: environment: MONGO_INITDB_ROOT_PASSWORD: \"123\" MONGO_INITDB_ROOT_USERNAME: toto image: mongo restart: unless-stopped volumes: - type: volume source: mydb target: /data/db server: build: context: . depends_on: db: condition: service_started environment: MONGO_USER_NAME: tintin MONGO_USER_PASSWORD: \"456\" ports: - mode: ingress target: 80 published: 80 protocol: tcp restart: unless-stopped volumes: - type: bind source: /mnt/c/git/doc/test/docker/node-server/src target: /app/src volumes: mydb: name: mydb external: true","title":"config"},{"location":"docker/8-compose-use/#pull-push","text":"pull: get latest images of containers that compose the stack. push: if image has been modified with custom Dockerfile, let us push it to Docker Hub.","title":"pull push"},{"location":"docker/9-compose-dockerfile/","text":"Compose - 09 - Dockerfile Docker Compose - Dockerfile !WSL2, advised to not use a mounted volume like '/mnt/c/' for handling a project to avoid slowness and live reload issues. Instead, prefer usage of a \"native\" WSL2 folder like for e.g. '/home/user/react-nginx' Dockerfile and Docker Compose to set up a client application composed of: React NGINX Setup of client application project Node 'create-React-app' is a script to install with 'npm' will pre-configure a 'webpack' environnement and give use access to a development server and a test server and a build command for production. Role of 'NGINX' (http server) is to treat all http(s) request and return response from 'React' application to requester. In this chapter we will see two new features: Dockerfile multi staging, defined with many 'from'. Stdin_open and TTY, two new options of Docker Compose. Prerequisite, install on host machine: 'nvm' - Node Version Manager 'Node.js' Set/check installation with: // Setup project root folder mkdir react-nginx cd react-nginx // To install 'nvm' curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash // Check nvm // Get last version nvm ls-remote | tail . . v17.0.1 v17.1.0 v17.2.0 v17.3.0 // Install last version nvm install 17.3.0 node -v v17.3.0 node Welcome to Node.js v17.3.0. Type \".help\" for more information. > (To exit, press Ctrl+C again or Ctrl+D or type .exit) > React Instal 'React' with 'npx' (like npm but executed once with last script release): npx create-react-app client cd client ls README.md node_modules package-lock.json package.json public src npm start . . Compiled successfully! You can now view client in the browser. Local: http://localhost:3000 Browse to: - http://localhost:3000 Test (launch tests contained in react-nginx/client/src/App.test.js): npm run test !! Fail on WSL2 :( Build for production (add a build folder to the project, this is the folder to return via NGINX for client): npm run build All of this just to initialize the project locally on host machine. Dockerized We may now delete the 'node_modules' folder ('node_modules' folder will then be only in container initialized with dependencies through 'npm install' command in 'Dockerfile'): rm -rf node_modules/ Add a 'Dockerfile' in client project folder '/home/user/react-nginx/client': touch Dockerfile Dockerfile: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install COPY . . CMD [\"npm\", \"start\"] Build docker image: docker build -t myreact . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE myreact latest c4c1b5bb9d21 45 seconds ago 483MB docker run --rm --name react -p 3000:3000 myreact Browse to: - http://localhost:3000 Live reload It's important to launch from a terminal a based VS Code instance from root client application folder to get live reload effect that works: cd .../react-nginx/client code . For development purpose, to automatically propagate local changes to container. Bind mount project folder: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app myreact !! => FAIL!! Why? Because when bind mount it crush all what was contained in container '/app' folder with local content and in local there isn't anymore 'node_modules' folder. To avoid this unwanted behavior and keep 'node_modules' in container folder not erased by bind mount (also needed for live reload feature), we bind an anonymous volume targeted on remote container '/app/node_modules' folder. Also, to avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder we modify 'Dockerfile' as follow: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] Bind mount project folder + anonymous volume with '/app/node_modules' as target: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app --mount type=volume,target=/app/node_modules myreact It's advised to run with '--rm' option when using anonymous volume to suppress it automatically on stop in addition to container suppression. Test live reload by changing text '.. save to reload.' with e.g. 'Hello, world!\" in 'src/App.js' and then observe live effect at http://localhost:3000 in an Internet browser. Set up Docker Compose docker-compose.yml version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules Reset Docker: docker system prune -a docker volume prune Start service: docker-compose up You may observe live reload working by changing 'App.js' content and 'localhost:3000' changing accordingly. Test during developpement Note: webpack is an open-source JavaScript module bundler (wikipedia). TDD (Test Driven Development). In a devellopement process it's mostly advised to continuously test in order to check that we don't brake anything. To achieve this, we lauch two terminals in prallel, one with webpack for running application and this other one for automatic testing purpose. It's done with same container image and duplicate services in Docker Compose configuration file, only thing that will change for second duplicated service is that we override command from Dockerfile in Docker Compose configuration file to launch test server and remove also port mapping which is useless for tests. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules docker-compose up --build In logs we may observe: . . test_1 | Tests: 1 passed, 1 total . . If we duplicate one exsisting test in '.../src/App.test.js' file, we may observe live change in logs: . . test_1 | Tests: 2 passed, 2 total . . To interact with test server we need a second terminal. If we want to send command in test container when attaching to it we need to add two options to the test service in Docker Compose configuration file, 'stdin_open' and 'tty', both set to 'true'. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules stdin_open: true tty: true In first terminal: docker-compose down -v docker-compose up --build In second terminal: docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca16b44236ad client_test \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute client_test_1 4633b0999f9c client_client \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute 0.0.0.0:3000->3000/tcp client_client_1 docker attach client_test_1 . . Watch Usage \u203a Press f to run only failed tests. \u203a Press o to only run tests related to changed files. \u203a Press q to quit watch mode. \u203a Press p to filter by a filename regex pattern. \u203a Press t to filter by a test name regex pattern. \u203a Press Enter to trigger a test run. We may now send commands to test server in second terminal. Then, shutdown gracefully: docker-compose down -v Production environnement Introduction NGINX return the build. NGINX intercept http request and return by default an html file. Browse docker hub for nginx on official image page to host some simple static content . Simple test: docker run --rm -p 80:80 nginx Browse to localhost In a second terminal: docker exec -it exciting_elion sh cd usr/share/nginx/html ls 50x.html index.html cat index.html <!DOCTYPE html> <html> <head> <title>Welcome to nginx!</title> . . It's in this folder we gonna copy our application '/usr/share/nginx/html'. For more complex configuration, have a look in '/etc/nginx/conf.d' folder. Multi stage Dockerfile Reuse a preceding builded image in next build. Goal to reach here is to put React's build folder into NGINX image. ../client/Dockerfile.prod FROM node:alpine as buildstage WORKDIR /app COPY package.json . RUN npm install COPY . . RUN npm run build FROM nginx COPY --from=buildstage /app/build /usr/share/nginx/html EXPOSE 80 After second FROM above, --from=buildstage refer to first stage of image build (npm run build, output is a 'build' folder that containe production application). Build Docker image: docker build -t nginxreact -f Dockerfile.prod . . . => [stage-1 2/2] COPY --from=buildstage /app/build /usr/share/nginx/html . . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginxreact latest ee3388384541 4 minutes ago 141MB . . <none> <none> 1c9dc1e2c948 6 hours ago 483MB . . \"\\<none>\" image are produced by intermediate build stage(s). Launch a container with just built image: docker run --rm -p 80:80 nginxreact Browse to localhost to observe your production application running. Docker Compose A new Docker Compose configuration file dedicated to prodction: touch docker-compose.prod.yml docker-compose.prod.yml version: \"3.8\" services: mynginx: build: context: . dockerfile: Dockerfile.prod ports: - 80:80 Reset Docker content: docker system prune -a docker volume prune Start a fresh new production application: docker-compose -f docker-compose.prod.yml up Browse to localhost to observe your production application running.","title":"Compose - 09 - Dockerfile"},{"location":"docker/9-compose-dockerfile/#compose-09-dockerfile","text":"Docker Compose - Dockerfile !WSL2, advised to not use a mounted volume like '/mnt/c/' for handling a project to avoid slowness and live reload issues. Instead, prefer usage of a \"native\" WSL2 folder like for e.g. '/home/user/react-nginx' Dockerfile and Docker Compose to set up a client application composed of: React NGINX","title":"Compose - 09 - Dockerfile"},{"location":"docker/9-compose-dockerfile/#setup-of-client-application-project","text":"","title":"Setup of client application project"},{"location":"docker/9-compose-dockerfile/#node","text":"'create-React-app' is a script to install with 'npm' will pre-configure a 'webpack' environnement and give use access to a development server and a test server and a build command for production. Role of 'NGINX' (http server) is to treat all http(s) request and return response from 'React' application to requester. In this chapter we will see two new features: Dockerfile multi staging, defined with many 'from'. Stdin_open and TTY, two new options of Docker Compose. Prerequisite, install on host machine: 'nvm' - Node Version Manager 'Node.js' Set/check installation with: // Setup project root folder mkdir react-nginx cd react-nginx // To install 'nvm' curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash // Check nvm // Get last version nvm ls-remote | tail . . v17.0.1 v17.1.0 v17.2.0 v17.3.0 // Install last version nvm install 17.3.0 node -v v17.3.0 node Welcome to Node.js v17.3.0. Type \".help\" for more information. > (To exit, press Ctrl+C again or Ctrl+D or type .exit) >","title":"Node"},{"location":"docker/9-compose-dockerfile/#react","text":"Instal 'React' with 'npx' (like npm but executed once with last script release): npx create-react-app client cd client ls README.md node_modules package-lock.json package.json public src npm start . . Compiled successfully! You can now view client in the browser. Local: http://localhost:3000 Browse to: - http://localhost:3000 Test (launch tests contained in react-nginx/client/src/App.test.js): npm run test !! Fail on WSL2 :( Build for production (add a build folder to the project, this is the folder to return via NGINX for client): npm run build All of this just to initialize the project locally on host machine.","title":"React"},{"location":"docker/9-compose-dockerfile/#dockerized","text":"We may now delete the 'node_modules' folder ('node_modules' folder will then be only in container initialized with dependencies through 'npm install' command in 'Dockerfile'): rm -rf node_modules/ Add a 'Dockerfile' in client project folder '/home/user/react-nginx/client': touch Dockerfile Dockerfile: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install COPY . . CMD [\"npm\", \"start\"] Build docker image: docker build -t myreact . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE myreact latest c4c1b5bb9d21 45 seconds ago 483MB docker run --rm --name react -p 3000:3000 myreact Browse to: - http://localhost:3000","title":"Dockerized"},{"location":"docker/9-compose-dockerfile/#live-reload","text":"It's important to launch from a terminal a based VS Code instance from root client application folder to get live reload effect that works: cd .../react-nginx/client code . For development purpose, to automatically propagate local changes to container. Bind mount project folder: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app myreact !! => FAIL!! Why? Because when bind mount it crush all what was contained in container '/app' folder with local content and in local there isn't anymore 'node_modules' folder. To avoid this unwanted behavior and keep 'node_modules' in container folder not erased by bind mount (also needed for live reload feature), we bind an anonymous volume targeted on remote container '/app/node_modules' folder. Also, to avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder we modify 'Dockerfile' as follow: FROM node:alpine WORKDIR /app COPY package.json . RUN npm install # To avoid 'EACCES: permission denied' issue on '/app/node_modules/.cache' folder RUN mkdir -p node_modules/.cache && chmod -R 777 node_modules/.cache COPY . . CMD [\"npm\", \"start\"] Bind mount project folder + anonymous volume with '/app/node_modules' as target: docker run --rm --name react -p 3000:3000 --mount type=bind,src=\"$(pwd)\",target=/app --mount type=volume,target=/app/node_modules myreact It's advised to run with '--rm' option when using anonymous volume to suppress it automatically on stop in addition to container suppression. Test live reload by changing text '.. save to reload.' with e.g. 'Hello, world!\" in 'src/App.js' and then observe live effect at http://localhost:3000 in an Internet browser.","title":"Live reload"},{"location":"docker/9-compose-dockerfile/#set-up-docker-compose","text":"docker-compose.yml version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules Reset Docker: docker system prune -a docker volume prune Start service: docker-compose up You may observe live reload working by changing 'App.js' content and 'localhost:3000' changing accordingly.","title":"Set up Docker Compose"},{"location":"docker/9-compose-dockerfile/#test-during-developpement","text":"Note: webpack is an open-source JavaScript module bundler (wikipedia). TDD (Test Driven Development). In a devellopement process it's mostly advised to continuously test in order to check that we don't brake anything. To achieve this, we lauch two terminals in prallel, one with webpack for running application and this other one for automatic testing purpose. It's done with same container image and duplicate services in Docker Compose configuration file, only thing that will change for second duplicated service is that we override command from Dockerfile in Docker Compose configuration file to launch test server and remove also port mapping which is useless for tests. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules docker-compose up --build In logs we may observe: . . test_1 | Tests: 1 passed, 1 total . . If we duplicate one exsisting test in '.../src/App.test.js' file, we may observe live change in logs: . . test_1 | Tests: 2 passed, 2 total . . To interact with test server we need a second terminal. If we want to send command in test container when attaching to it we need to add two options to the test service in Docker Compose configuration file, 'stdin_open' and 'tty', both set to 'true'. docker-compose.yml: version: \"3.8\" services: client: build: . ports: - 3000:3000 volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules test: build: . command: [\"npm\", \"run\", \"test\"] volumes: - type: bind source: . target: /app - type: volume target: /app/node_modules stdin_open: true tty: true In first terminal: docker-compose down -v docker-compose up --build In second terminal: docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca16b44236ad client_test \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute client_test_1 4633b0999f9c client_client \"docker-entrypoint.s\u2026\" About a minute ago Up About a minute 0.0.0.0:3000->3000/tcp client_client_1 docker attach client_test_1 . . Watch Usage \u203a Press f to run only failed tests. \u203a Press o to only run tests related to changed files. \u203a Press q to quit watch mode. \u203a Press p to filter by a filename regex pattern. \u203a Press t to filter by a test name regex pattern. \u203a Press Enter to trigger a test run. We may now send commands to test server in second terminal. Then, shutdown gracefully: docker-compose down -v","title":"Test during developpement"},{"location":"docker/9-compose-dockerfile/#production-environnement","text":"","title":"Production environnement"},{"location":"docker/9-compose-dockerfile/#introduction","text":"NGINX return the build. NGINX intercept http request and return by default an html file. Browse docker hub for nginx on official image page to host some simple static content . Simple test: docker run --rm -p 80:80 nginx Browse to localhost In a second terminal: docker exec -it exciting_elion sh cd usr/share/nginx/html ls 50x.html index.html cat index.html <!DOCTYPE html> <html> <head> <title>Welcome to nginx!</title> . . It's in this folder we gonna copy our application '/usr/share/nginx/html'. For more complex configuration, have a look in '/etc/nginx/conf.d' folder.","title":"Introduction"},{"location":"docker/9-compose-dockerfile/#multi-stage-dockerfile","text":"Reuse a preceding builded image in next build. Goal to reach here is to put React's build folder into NGINX image. ../client/Dockerfile.prod FROM node:alpine as buildstage WORKDIR /app COPY package.json . RUN npm install COPY . . RUN npm run build FROM nginx COPY --from=buildstage /app/build /usr/share/nginx/html EXPOSE 80 After second FROM above, --from=buildstage refer to first stage of image build (npm run build, output is a 'build' folder that containe production application). Build Docker image: docker build -t nginxreact -f Dockerfile.prod . . . => [stage-1 2/2] COPY --from=buildstage /app/build /usr/share/nginx/html . . docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginxreact latest ee3388384541 4 minutes ago 141MB . . <none> <none> 1c9dc1e2c948 6 hours ago 483MB . . \"\\<none>\" image are produced by intermediate build stage(s). Launch a container with just built image: docker run --rm -p 80:80 nginxreact Browse to localhost to observe your production application running.","title":"Multi stage Dockerfile"},{"location":"docker/9-compose-dockerfile/#docker-compose","text":"A new Docker Compose configuration file dedicated to prodction: touch docker-compose.prod.yml docker-compose.prod.yml version: \"3.8\" services: mynginx: build: context: . dockerfile: Dockerfile.prod ports: - 80:80 Reset Docker content: docker system prune -a docker volume prune Start a fresh new production application: docker-compose -f docker-compose.prod.yml up Browse to localhost to observe your production application running.","title":"Docker Compose"},{"location":"elasticsearch/elasticsearch/","text":"ElasticSearch Update field Plugin Head Update boolean field with Chrome plugin ElasticSearch Head local: http://localhost:9200/ Other request tab URL http://localhost:9200/index/doc/id to check empty GET to update request _update POST {\"doc\":{\"deleted\":false}} Kibana 5.6 Browse to Dev Tools, Console to get: GET _index/_type/_id to update: POST _index/_type/_id/_update { \"doc\": { \"field\":\"value\" or \"field\":99 or \"field\":false } }","title":"ElasticSearch - Misc"},{"location":"elasticsearch/elasticsearch/#elasticsearch","text":"","title":"ElasticSearch"},{"location":"elasticsearch/elasticsearch/#update-field","text":"","title":"Update field"},{"location":"elasticsearch/elasticsearch/#plugin-head","text":"Update boolean field with Chrome plugin ElasticSearch Head local: http://localhost:9200/ Other request tab URL http://localhost:9200/index/doc/id to check empty GET to update request _update POST {\"doc\":{\"deleted\":false}}","title":"Plugin Head"},{"location":"elasticsearch/elasticsearch/#kibana-56","text":"Browse to Dev Tools, Console to get: GET _index/_type/_id to update: POST _index/_type/_id/_update { \"doc\": { \"field\":\"value\" or \"field\":99 or \"field\":false } }","title":"Kibana 5.6"},{"location":"git/git/","text":"Git Initialize Local settings: git config user.name \"Your Name\" git config user.email \"youremail@domain.com\" WSL Credential Manager setup SRC: microsoft git config credential.helper \"/mnt/c/Program\\ Files/Git/mingw64/libexec/git-core/git-credential-manager-core.exe\" Configuration List configuration parameters: git config --list Edit configuration parameters: git config --global --edit or git config --edit cache token to cache token (use token instead of password) (for 15 minutes, by default). SRC: github git config credential.helper cache or for 1 hour git config credential.helper 'cache --timeout=3600'","title":"Git - Misc"},{"location":"git/git/#git","text":"","title":"Git"},{"location":"git/git/#initialize","text":"Local settings: git config user.name \"Your Name\" git config user.email \"youremail@domain.com\"","title":"Initialize"},{"location":"git/git/#wsl-credential-manager-setup","text":"SRC: microsoft git config credential.helper \"/mnt/c/Program\\ Files/Git/mingw64/libexec/git-core/git-credential-manager-core.exe\"","title":"WSL Credential Manager setup"},{"location":"git/git/#configuration","text":"List configuration parameters: git config --list Edit configuration parameters: git config --global --edit or git config --edit","title":"Configuration"},{"location":"git/git/#cache-token","text":"to cache token (use token instead of password) (for 15 minutes, by default). SRC: github git config credential.helper cache or for 1 hour git config credential.helper 'cache --timeout=3600'","title":"cache token"},{"location":"intellij/1-intellij-misc/","text":"IntelliJ - 01 - Misc Setup project in WSL folder Fix EOL (LF vs CRLF) issue: git clone select root project folder menu File - File Properties - Line Separators - LF Unix git rollback entire project to reset CRLF issue SRC OR Terminal in a new \"native\" WSL folder, clone and fix CRLF issue : git clone ptoject_url git config core.eol lf git config core.autocrlf input Service window For Docker connection, maybe not opened if comes from external project. To open it manually: View | Tool Windows | Services or Alt+8 SRC Search for ; and replace with ;\\r\\n For a file where each values are separated with ';' but need each values on a new line to compare files. replace ; enable regex by ;\\r\\n To revert, do it in Notepad++ with a record sequence","title":"IntelliJ - 01 - Misc"},{"location":"intellij/1-intellij-misc/#intellij-01-misc","text":"","title":"IntelliJ - 01 - Misc"},{"location":"intellij/1-intellij-misc/#setup-project-in-wsl-folder","text":"Fix EOL (LF vs CRLF) issue: git clone select root project folder menu File - File Properties - Line Separators - LF Unix git rollback entire project to reset CRLF issue SRC OR Terminal in a new \"native\" WSL folder, clone and fix CRLF issue : git clone ptoject_url git config core.eol lf git config core.autocrlf input","title":"Setup project in WSL folder"},{"location":"intellij/1-intellij-misc/#service-window","text":"For Docker connection, maybe not opened if comes from external project. To open it manually: View | Tool Windows | Services or Alt+8 SRC","title":"Service window"},{"location":"intellij/1-intellij-misc/#search-for-and-replace-with-rn","text":"For a file where each values are separated with ';' but need each values on a new line to compare files. replace ; enable regex by ;\\r\\n To revert, do it in Notepad++ with a record sequence","title":"Search for ; and replace with ;\\r\\n"},{"location":"intellij/2-intellij-wsl/","text":"IntelliJ - 02 - WSL IntelliJ integration with a project hosted in a WSL2 native folder (not /mnt/c) Test Maven To test that maven is correctly installed and running in Linux distribution. Setup a new maven project with a simple 'hello' class to test debug/run. Firewall rules To allow IntelliJ to communicate with WSL. SRC: - set IntelliJ rules to communicate with WSL PowerShell (admin mode): New-NetFirewallRule -DisplayName \"WSL\" -Direction Inbound -InterfaceAlias \"vEthernet (WSL)\" -Action Allow Get-NetFirewallRule | where DisplayName -ILike \"idea*.exe\" | Remove-NetFirewallRule CRLF issue After cloning a git repository maybe all files are marked as modified due to CRLF miss understanding between Windows and Linux file system. SRC: - fix CRLF issue From a terminal in a native (not /mnt/c) WSL folder: git clone <url> git config core.eol lf git config core.autocrlf input IntelliJ recipe At least release \"IntelliJ IDEA 2021.3.1 (Community Edition)\" Open existing project: - set project SDK with the one from WSL - set Maven home (IDE settings, search for maven) to : \"\\\\wsl$\\<linux distribution>\\usr\\share\\maven\" - invalidate cache and restart Note: - original Maven setting for Windows = C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2021.3.1\\plugins\\maven\\lib\\maven3 Fix IntelliJ Fix IntelliJ to disable one wsl experimental feature. SRC: - fix IntelliJ - press Shift-Shift to open \"Search everywhere\" - enter \"Experimental features\" and select the action - in the dialog that appears, turn off wsl.fsd.content.loader - restart the IDE Fix Docker For Docker Compose to prepare context with Docker Desktop for Windows. Enable the Docker Compose V2 option under the experimental settings. SRC: - fix Docker Fix Logback In case project fail to start due to Logback issue, \"Failed to create parent directories\" var log. Manually create needed log folder for project and set rights accordingly: sudo mkdir /var/log/<needed project folder name for log> sudo chmod a+rwx /var/log/<needed project folder name for log>","title":"IntelliJ - 02 - WSL"},{"location":"intellij/2-intellij-wsl/#intellij-02-wsl","text":"IntelliJ integration with a project hosted in a WSL2 native folder (not /mnt/c)","title":"IntelliJ - 02 - WSL"},{"location":"intellij/2-intellij-wsl/#test-maven","text":"To test that maven is correctly installed and running in Linux distribution. Setup a new maven project with a simple 'hello' class to test debug/run.","title":"Test Maven"},{"location":"intellij/2-intellij-wsl/#firewall-rules","text":"To allow IntelliJ to communicate with WSL. SRC: - set IntelliJ rules to communicate with WSL PowerShell (admin mode): New-NetFirewallRule -DisplayName \"WSL\" -Direction Inbound -InterfaceAlias \"vEthernet (WSL)\" -Action Allow Get-NetFirewallRule | where DisplayName -ILike \"idea*.exe\" | Remove-NetFirewallRule","title":"Firewall rules"},{"location":"intellij/2-intellij-wsl/#crlf-issue","text":"After cloning a git repository maybe all files are marked as modified due to CRLF miss understanding between Windows and Linux file system. SRC: - fix CRLF issue From a terminal in a native (not /mnt/c) WSL folder: git clone <url> git config core.eol lf git config core.autocrlf input","title":"CRLF issue"},{"location":"intellij/2-intellij-wsl/#intellij-recipe","text":"At least release \"IntelliJ IDEA 2021.3.1 (Community Edition)\" Open existing project: - set project SDK with the one from WSL - set Maven home (IDE settings, search for maven) to : \"\\\\wsl$\\<linux distribution>\\usr\\share\\maven\" - invalidate cache and restart Note: - original Maven setting for Windows = C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2021.3.1\\plugins\\maven\\lib\\maven3","title":"IntelliJ recipe"},{"location":"intellij/2-intellij-wsl/#fix-intellij","text":"Fix IntelliJ to disable one wsl experimental feature. SRC: - fix IntelliJ - press Shift-Shift to open \"Search everywhere\" - enter \"Experimental features\" and select the action - in the dialog that appears, turn off wsl.fsd.content.loader - restart the IDE","title":"Fix IntelliJ"},{"location":"intellij/2-intellij-wsl/#fix-docker","text":"For Docker Compose to prepare context with Docker Desktop for Windows. Enable the Docker Compose V2 option under the experimental settings. SRC: - fix Docker","title":"Fix Docker"},{"location":"intellij/2-intellij-wsl/#fix-logback","text":"In case project fail to start due to Logback issue, \"Failed to create parent directories\" var log. Manually create needed log folder for project and set rights accordingly: sudo mkdir /var/log/<needed project folder name for log> sudo chmod a+rwx /var/log/<needed project folder name for log>","title":"Fix Logback"},{"location":"linux/linux/","text":"Linux Curl $ curl -i localhost $ curl -sb -H \"Accept: application/json\" \"http://localhost\" | json_pp Compress Decompress Compress (czf) - c compress, -z zip, -f file $ tar -czf /targetfolder/targetfile.tar.gz /sourcefolder Decompress (xzf) - x extract, -z zip, -f file $ tar -xzf targetfile.tar.gz or gzip, -k to keep original, -d to decompress: $ gzip -kd file.gz Package List installed $ apt list --installed Info $ apt-cache show packagename Remove $ sudo apt-get --purge autoremove packagename Switch user to root Switch current user to root $ sudo su - Grep lines before after match -B before -A after Stick ne lines just after option $ grep -B2 -A3 pattern infile.txt Copy files from list Copy specific files from a text list of files $ rsync -a sourcefolder --files-from=list.txt destinationfolder Get data between two patterns In error.log . . 05:59:30.024 [nioEventLoopGroup-3-5] ERROR c.l.d.c.ConnectorServerHandlerTCP.parseAndSendMessageTeltonika(177) - class java.util.concurrent.ExecutionException FOR RAW DATA : 0000017d55747fb00003f5380c1be045ce00000000000000000804ef005000c8024503034230fc430f8d440000011007e0fca600 WITH STACKTRACE : {} . . Get data between \"DATA : \" and \" WITH\" (hex raw data) $ cat error.log | sed -nr 's/.*DATA : (.*) WITH.*/\\1/p' Grep patterns from a file -f option, maybe -oF options also $ grep -f patterns_file *.log or $ grep -oFf patterns.txt *.log If result's count's not OK, check by not found pattern (-h option to hide filename in output) $ grep -hoFf patterns.txt *.log | grep -vFf - patterns.txt For list of file For list of file in current folder, do operation. Here we want to have file name, cat content and separate result with a new line $ ll *.txt 1.txt 2.txt 3.txt 4.txt 5.txt $ for f in {2..4}.txt; do echo \"$f\"; cat \"$f\"; printf \"\\n\"; done 2.txt jkl mno pqr 3.txt stu vwx yza 4.txt bcd efg hij Search between timestamp $ sed -rne '/10:50/,/11:05/ p' file Put existing time range in file (10:50 - 11:05). Highlight search result $ grep --color=always -z pattern file | less -R always to transmit color through pipe -z to show everything, not only the matching pattern -R to avoid showing esc char instead of color Delete history 1003 25-04-2016 17:54:52 echo \"Command 1\" 1004 25-04-2016 17:54:54 echo \"Command 2\" 1005 25-04-2016 17:54:57 echo \"Command 3\" 1006 25-04-2016 17:54:59 echo \"Command 4\" 1007 25-04-2016 17:55:01 echo \"Command 5\" 1008 25-04-2016 17:55:03 echo \"Command 6\" 1009 25-04-2016 17:55:07 echo \"Command 7\" 1010 25-04-2016 17:55:09 echo \"Command 8\" 1011 25-04-2016 17:55:11 echo \"Command 9\" 1012 25-04-2016 17:55:14 echo \"Command 10\" $ for h in $(seq 1006 1008); do history -d 1006; done Where is a program How to know where reside a program, e.g. ls? $ which ls /usr/bin/ls $ env $ env | grep PATH Difference Difference of 2 commands output $ diff <(ls test1) <(ls test2) Difference of sorted lists $ sort ok.txt > okSorted.txt $ sort all.txt > allSorted.txt $ diff --new-line-format=\"\" --unchanged-line-format=\"\" allSorted.txt okSorted.txt Mean of a column test.txt (warning on empty lines (maybe at the end)) 1 3 7 $ cat test.txt | awk '{ total += $1 } END { print total/NR }' 3.66667 Median of a column test.txt (warning on empty lines (maybe at the end)) 1 3 7 11 22 45 71 median.awk #/usr/bin/env awk { count[NR] = $1; } END { if (NR % 2) { print count[(NR + 1) / 2]; } else { print (count[(NR / 2)] + count[(NR / 2) + 1]) / 2.0; } } $ cat test.txt | awk -f median.awk 11 Check equal number of values below and above median $ cat test.txt | awk '{if($1 < 11) print $1}' | wc -l 3 $ cat test.txt | awk '{if($1 > 11) print $1}' | wc -l 3 Get nth column from file Get nth column from file with field separated values test.txt column 1 row 1;column 2 row 1;column 3 row 1 column 1 row 2;column 2 row 2;column 3 row 2 column 1 row 3;column 2 row 3;column 3 row 3 $ cat test.txt | awk -F ';' '{print $2}' column 2 row 1 column 2 row 2 column 2 row 3 Conditional $ cat test.txt | awk -F ';' '{if($1 == \"column 1 row 2\") print $2}' column 2 row 2 List files Sorted by sizes and human readable $ ll -S -h Uniq values in a file Uniq values in a file, sorted and counted (first sort is mandatory) test.txt 1 71 3 7 22 1 11 22 45 71 22 $ cat test.txt | sort | uniq -c 2 1 1 11 3 22 1 3 1 45 1 7 2 71 sorted output $ cat test.txt | sort | uniq -c | sort 1 11 1 3 1 45 1 7 2 1 2 71 3 22 revert sorted output $ cat test.txt | sort | uniq -c | sort -r 3 22 2 71 2 1 1 7 1 45 1 3 1 11","title":"Linux - Misc"},{"location":"linux/linux/#linux","text":"","title":"Linux"},{"location":"linux/linux/#curl","text":"$ curl -i localhost $ curl -sb -H \"Accept: application/json\" \"http://localhost\" | json_pp","title":"Curl"},{"location":"linux/linux/#compress-decompress","text":"","title":"Compress Decompress"},{"location":"linux/linux/#compress-czf","text":"- c compress, -z zip, -f file $ tar -czf /targetfolder/targetfile.tar.gz /sourcefolder","title":"Compress (czf)"},{"location":"linux/linux/#decompress-xzf","text":"- x extract, -z zip, -f file $ tar -xzf targetfile.tar.gz or gzip, -k to keep original, -d to decompress: $ gzip -kd file.gz","title":"Decompress (xzf)"},{"location":"linux/linux/#package","text":"","title":"Package"},{"location":"linux/linux/#list-installed","text":"$ apt list --installed","title":"List installed"},{"location":"linux/linux/#info","text":"$ apt-cache show packagename","title":"Info"},{"location":"linux/linux/#remove","text":"$ sudo apt-get --purge autoremove packagename","title":"Remove"},{"location":"linux/linux/#switch-user-to-root","text":"Switch current user to root $ sudo su -","title":"Switch user to root"},{"location":"linux/linux/#grep-lines-before-after-match","text":"-B before -A after Stick ne lines just after option $ grep -B2 -A3 pattern infile.txt","title":"Grep lines before after match"},{"location":"linux/linux/#copy-files-from-list","text":"Copy specific files from a text list of files $ rsync -a sourcefolder --files-from=list.txt destinationfolder","title":"Copy files from list"},{"location":"linux/linux/#get-data-between-two-patterns","text":"In error.log . . 05:59:30.024 [nioEventLoopGroup-3-5] ERROR c.l.d.c.ConnectorServerHandlerTCP.parseAndSendMessageTeltonika(177) - class java.util.concurrent.ExecutionException FOR RAW DATA : 0000017d55747fb00003f5380c1be045ce00000000000000000804ef005000c8024503034230fc430f8d440000011007e0fca600 WITH STACKTRACE : {} . . Get data between \"DATA : \" and \" WITH\" (hex raw data) $ cat error.log | sed -nr 's/.*DATA : (.*) WITH.*/\\1/p'","title":"Get data between two patterns"},{"location":"linux/linux/#grep-patterns-from-a-file","text":"-f option, maybe -oF options also $ grep -f patterns_file *.log or $ grep -oFf patterns.txt *.log If result's count's not OK, check by not found pattern (-h option to hide filename in output) $ grep -hoFf patterns.txt *.log | grep -vFf - patterns.txt","title":"Grep patterns from a file"},{"location":"linux/linux/#for-list-of-file","text":"For list of file in current folder, do operation. Here we want to have file name, cat content and separate result with a new line $ ll *.txt 1.txt 2.txt 3.txt 4.txt 5.txt $ for f in {2..4}.txt; do echo \"$f\"; cat \"$f\"; printf \"\\n\"; done 2.txt jkl mno pqr 3.txt stu vwx yza 4.txt bcd efg hij","title":"For list of file"},{"location":"linux/linux/#search-between-timestamp","text":"$ sed -rne '/10:50/,/11:05/ p' file Put existing time range in file (10:50 - 11:05).","title":"Search between timestamp"},{"location":"linux/linux/#highlight-search-result","text":"$ grep --color=always -z pattern file | less -R always to transmit color through pipe -z to show everything, not only the matching pattern -R to avoid showing esc char instead of color","title":"Highlight search result"},{"location":"linux/linux/#delete-history","text":"1003 25-04-2016 17:54:52 echo \"Command 1\" 1004 25-04-2016 17:54:54 echo \"Command 2\" 1005 25-04-2016 17:54:57 echo \"Command 3\" 1006 25-04-2016 17:54:59 echo \"Command 4\" 1007 25-04-2016 17:55:01 echo \"Command 5\" 1008 25-04-2016 17:55:03 echo \"Command 6\" 1009 25-04-2016 17:55:07 echo \"Command 7\" 1010 25-04-2016 17:55:09 echo \"Command 8\" 1011 25-04-2016 17:55:11 echo \"Command 9\" 1012 25-04-2016 17:55:14 echo \"Command 10\" $ for h in $(seq 1006 1008); do history -d 1006; done","title":"Delete history"},{"location":"linux/linux/#where-is-a-program","text":"How to know where reside a program, e.g. ls? $ which ls /usr/bin/ls $ env $ env | grep PATH","title":"Where is a program"},{"location":"linux/linux/#difference","text":"Difference of 2 commands output $ diff <(ls test1) <(ls test2) Difference of sorted lists $ sort ok.txt > okSorted.txt $ sort all.txt > allSorted.txt $ diff --new-line-format=\"\" --unchanged-line-format=\"\" allSorted.txt okSorted.txt","title":"Difference"},{"location":"linux/linux/#mean-of-a-column","text":"test.txt (warning on empty lines (maybe at the end)) 1 3 7 $ cat test.txt | awk '{ total += $1 } END { print total/NR }' 3.66667","title":"Mean of a column"},{"location":"linux/linux/#median-of-a-column","text":"test.txt (warning on empty lines (maybe at the end)) 1 3 7 11 22 45 71 median.awk #/usr/bin/env awk { count[NR] = $1; } END { if (NR % 2) { print count[(NR + 1) / 2]; } else { print (count[(NR / 2)] + count[(NR / 2) + 1]) / 2.0; } } $ cat test.txt | awk -f median.awk 11 Check equal number of values below and above median $ cat test.txt | awk '{if($1 < 11) print $1}' | wc -l 3 $ cat test.txt | awk '{if($1 > 11) print $1}' | wc -l 3","title":"Median of a column"},{"location":"linux/linux/#get-nth-column-from-file","text":"Get nth column from file with field separated values test.txt column 1 row 1;column 2 row 1;column 3 row 1 column 1 row 2;column 2 row 2;column 3 row 2 column 1 row 3;column 2 row 3;column 3 row 3 $ cat test.txt | awk -F ';' '{print $2}' column 2 row 1 column 2 row 2 column 2 row 3","title":"Get nth column from file"},{"location":"linux/linux/#conditional","text":"$ cat test.txt | awk -F ';' '{if($1 == \"column 1 row 2\") print $2}' column 2 row 2","title":"Conditional"},{"location":"linux/linux/#list-files","text":"Sorted by sizes and human readable $ ll -S -h","title":"List files"},{"location":"linux/linux/#uniq-values-in-a-file","text":"Uniq values in a file, sorted and counted (first sort is mandatory) test.txt 1 71 3 7 22 1 11 22 45 71 22 $ cat test.txt | sort | uniq -c 2 1 1 11 3 22 1 3 1 45 1 7 2 71 sorted output $ cat test.txt | sort | uniq -c | sort 1 11 1 3 1 45 1 7 2 1 2 71 3 22 revert sorted output $ cat test.txt | sort | uniq -c | sort -r 3 22 2 71 2 1 1 7 1 45 1 3 1 11","title":"Uniq values in a file"},{"location":"mkdocs/mkdocs/","text":"MkDocs Installation pip install mkdocs check mkdocs --version Initialize current folder mkdocs new . Build documentation mkdocs build Deploy to github First synchronize current folder with corresponding github repository. mkdocs gh-deploy Material for MkDocs (theme) Set up pip install mkdocs-material Configuration Simply add the following lines to mkdocs.yml to enable the theme. theme: name: material Link A double dash section title like below ## Node server project Should be referenced like below to be used in a link: #node-server-project To link this section from another markdown file: [Node server project](otherFile.md#node-server-project) VS Code Extension Usefull markdown editing VS Code extensions: Markdown All in One markdownlint Markdown All in One allow code autocompletion for inserting code block by hitting 'Ctrl+space' shortcut keys.","title":"MkDocs - Misc"},{"location":"mkdocs/mkdocs/#mkdocs","text":"","title":"MkDocs"},{"location":"mkdocs/mkdocs/#installation","text":"pip install mkdocs check mkdocs --version","title":"Installation"},{"location":"mkdocs/mkdocs/#initialize-current-folder","text":"mkdocs new .","title":"Initialize current folder"},{"location":"mkdocs/mkdocs/#build-documentation","text":"mkdocs build","title":"Build documentation"},{"location":"mkdocs/mkdocs/#deploy-to-github","text":"First synchronize current folder with corresponding github repository. mkdocs gh-deploy","title":"Deploy to github"},{"location":"mkdocs/mkdocs/#material-for-mkdocs-theme","text":"","title":"Material for MkDocs (theme)"},{"location":"mkdocs/mkdocs/#set-up","text":"pip install mkdocs-material","title":"Set up"},{"location":"mkdocs/mkdocs/#configuration","text":"Simply add the following lines to mkdocs.yml to enable the theme. theme: name: material","title":"Configuration"},{"location":"mkdocs/mkdocs/#link","text":"A double dash section title like below ## Node server project Should be referenced like below to be used in a link: #node-server-project To link this section from another markdown file: [Node server project](otherFile.md#node-server-project)","title":"Link"},{"location":"mkdocs/mkdocs/#vs-code-extension","text":"Usefull markdown editing VS Code extensions: Markdown All in One markdownlint Markdown All in One allow code autocompletion for inserting code block by hitting 'Ctrl+space' shortcut keys.","title":"VS Code Extension"},{"location":"mongodb/mongodb/","text":"MongoDB Clear console > cls","title":"MongoDB - Misc"},{"location":"mongodb/mongodb/#mongodb","text":"","title":"MongoDB"},{"location":"mongodb/mongodb/#clear-console","text":"> cls","title":"Clear console"},{"location":"vscode/vscode/","text":"VS Code Switch terminals Alt+up/down left/right arrows to switch between split terminals. Code snippet shortcut Ctrl+space Console code block in markdown file: Ctrl+space, then select fenced codeblock, then select console $ ... Move line Alt + Up/down keys Duplicate line If you want to copy the line to the line above itself, press Shift + Alt + Up Arrow Key. If you want to copy the line to the line below itself, press Shift + Alt + Down Arrow Key. Column select Mouse Shift + Alt then click and drag Keyboard Ctrl + Shift + Alt then use arrow keys","title":"VS Code - Misc"},{"location":"vscode/vscode/#vs-code","text":"","title":"VS Code"},{"location":"vscode/vscode/#switch-terminals","text":"Alt+up/down left/right arrows to switch between split terminals.","title":"Switch terminals"},{"location":"vscode/vscode/#code-snippet-shortcut","text":"Ctrl+space Console code block in markdown file: Ctrl+space, then select fenced codeblock, then select console $ ...","title":"Code snippet shortcut"},{"location":"vscode/vscode/#move-line","text":"Alt + Up/down keys","title":"Move line"},{"location":"vscode/vscode/#duplicate-line","text":"If you want to copy the line to the line above itself, press Shift + Alt + Up Arrow Key. If you want to copy the line to the line below itself, press Shift + Alt + Down Arrow Key.","title":"Duplicate line"},{"location":"vscode/vscode/#column-select","text":"Mouse Shift + Alt then click and drag Keyboard Ctrl + Shift + Alt then use arrow keys","title":"Column select"},{"location":"windows/windows/","text":"Windows find process that uses a port Open CMD prompt as admin C:\\> netstat -ano -p tcp | find \"50307\" Last column shows the PID that uses the port C:\\> netstat --help -a Displays all connections and listening ports. -n Displays addresses and port numbers in numerical form. -o Displays the owning process ID associated with each connection. In PowerShell C:\\> Get-Process -Id (Get-NetTCPConnection -LocalPort 50307).OwningProcess grep equivalent find \"50307\" or findstr 50307 C:\\> netstat -ano -p tcp | findstr 50307 kill process C:\\> taskkill /F /PID pid_number","title":"Windows - Misc"},{"location":"windows/windows/#windows","text":"","title":"Windows"},{"location":"windows/windows/#find-process-that-uses-a-port","text":"Open CMD prompt as admin C:\\> netstat -ano -p tcp | find \"50307\" Last column shows the PID that uses the port C:\\> netstat --help -a Displays all connections and listening ports. -n Displays addresses and port numbers in numerical form. -o Displays the owning process ID associated with each connection. In PowerShell C:\\> Get-Process -Id (Get-NetTCPConnection -LocalPort 50307).OwningProcess","title":"find process that uses a port"},{"location":"windows/windows/#grep-equivalent","text":"find \"50307\" or findstr 50307 C:\\> netstat -ano -p tcp | findstr 50307","title":"grep equivalent"},{"location":"windows/windows/#kill-process","text":"C:\\> taskkill /F /PID pid_number","title":"kill process"}]}